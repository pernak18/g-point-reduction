{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By-Band _g_-Point Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "\n",
    "`numpy` is installed in the Python environment at NERSC (`module load python`), but `xarray` is not, so the user must install the package on their own. `PIPPATH` is the assumed location. This notebook depends heavily on `xarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "# \"standard\" install\n",
    "import numpy as np\n",
    "\n",
    "# directory in which libraries installed with conda are saved\n",
    "PIPPATH = '{}/.local/'.format(os.path.expanduser('~')) + \\\n",
    "    'cori/3.7-anaconda-2019.10/lib/python3.7/site-packages'\n",
    "PATHS = ['common', PIPPATH]\n",
    "for path in PATHS: sys.path.append(path)\n",
    "\n",
    "# user must do `pip install xarray` on cori (or other NERSC machines)\n",
    "import xarray as XA\n",
    "\n",
    "# common submodule\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function and Class Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathCheck(path, mkdir=False):\n",
    "    \"\"\"\n",
    "    Determine if file exists. If not, throw an Assertion Exception\n",
    "    \"\"\"\n",
    "\n",
    "    if mkdir:\n",
    "        # mkdir -p -- create dir tree\n",
    "        if not os.path.exists(path): os.makedirs(path)\n",
    "    else:\n",
    "        assert os.path.exists(path), 'Could not find {}'.format(path)\n",
    "    # endif mkdir\n",
    "# end pathCheck\n",
    "\n",
    "def costFuncComp(tst_file, ref_file, levs=[0, 10000, 102000], iRecord=0, \n",
    "                 ncVars=['net_flux', 'heating_rate', 'band_flux_net']):\n",
    "    \"\"\"\n",
    "    Calculate same cost functions as `cost_function_components`, but allow \n",
    "    for many more terms, yielding a more flexible cost function\n",
    "    \n",
    "    No forcing yet\n",
    "\n",
    "    Inputs\n",
    "        tst_file -- string, RRTMGP (test model) netCDF file with fluxes\n",
    "        ref_file -- string, LBLRTM (reference model) netCDF file with fluxes\n",
    "\n",
    "    Output\n",
    "        outParams -- list of cost function arrays (RMS test-ref differences \n",
    "          averaged over columns); 1 element per input variable (ncVars)\n",
    "\n",
    "    Keywords\n",
    "        levs -- list of floats; pressure levels of interest in Pa\n",
    "        iRecord -- int; index for forcing scenario (default 0 is no forcing)\n",
    "        ncVars -- list of strings; netCDF variable names of the arrays to \n",
    "          include in the cost function\n",
    "    \"\"\"\n",
    "\n",
    "    outParams = []\n",
    "    with xr.open_dataset(tst_file) as tst, xr.open_dataset(ref_file) as ref:\n",
    "        # Compute differences in all variables in datasets at levels \n",
    "        # closest to user-provided pressure levels\n",
    "        # TODO: confirm this is doing what we expect it to\n",
    "        subsetErr = (tst-ref).sel(lev=levs, method='nearest')\n",
    "        for ncVar in ncVars:\n",
    "            # pressure dimension will depend on parameter\n",
    "            # layer for HR, level for everything else\n",
    "            pStr = 'lay' if 'heating_rate' in ncVar else 'lev'\n",
    "\n",
    "            # get array for variable, then compute its test-ref RMS \n",
    "            # over all columns and given pressure levels for a given \n",
    "            # forcing scenario\n",
    "            ncParam = getattr(subsetErr, ncVar)\n",
    "            outParams.append(\n",
    "                (ncParam.isel(record=iRecord)**2).mean(dim=('col', pStr)))\n",
    "            \n",
    "    return outParams\n",
    "# end costFuncComp\n",
    "    \n",
    "def normCost(tst_file, ref_file, norm, \n",
    "             ncVars=['net_flux', 'heating_rate', 'band_flux_net'], \n",
    "             levs=[0, 10000, 102000], ):\n",
    "    \"\"\"    \n",
    "    Returns the summary terms in the cost function\n",
    "      Each element in each term is normalized (normally by the error at i\n",
    "      teration 0)\n",
    "\n",
    "    Inputs\n",
    "        tst_file -- string, RRTMGP (test model) netCDF file with fluxes\n",
    "        ref_file -- string, LBLRTM (reference model) netCDF file with fluxes\n",
    "        norm -- list of floats with RMS error for a given \n",
    "          cost function component\n",
    "\n",
    "    Output\n",
    "        list of floats that are the RMS error (RRTMGP-LBLRTM)\n",
    "        for each cost function component normalized by the input \n",
    "        `norm` parameter\n",
    "\n",
    "    Keywords\n",
    "        levs -- list of floats; pressure levels of interest in Pa\n",
    "        iRecord -- int; index for whatever the 'record' dimension is in \n",
    "          the input netCDF files \n",
    "        ncVars -- list of strings; netCDF variable names of the arrays to \n",
    "          include in the cost function\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    tst_cost = costFuncComp(tst_file, ref_file, ncVars=ncVars, levs=levs)\n",
    "\n",
    "    # Each scalar term in the cost function is the RMS across the\n",
    "    #   normalized error in each component. cost_function_components() returns\n",
    "    #   the squared error\n",
    "    return [np.sqrt((c/n).mean()) for (c, n) in zip(tst_cost, norm)]\n",
    "# end normCost\n",
    "\n",
    "def recordDimRename(inNC, outNC):\n",
    "    \"\"\"\n",
    "    Rename \"record\" dimension in given netCDF file\n",
    "    \"\"\"\n",
    "    \n",
    "    outDS = xa.Dataset()\n",
    "\n",
    "    with xa.open_dataset(inNC) as inObj:\n",
    "        # save global attributes for later -- will stuff into buffer, unedited\n",
    "        globalAtt = inObj.attrs\n",
    "\n",
    "        # write buffer netCDF, complete with global attributes\n",
    "        ncVars = list(inObj.keys())\n",
    "\n",
    "        for ncVar in ncVars: \n",
    "            ncDat = inObj[ncVar]\n",
    "\n",
    "            if 'record' in ncDat.dims:\n",
    "                # which dimension corresponds to `record`?\n",
    "                dims = list(ncDat.dims)\n",
    "                iRec = dims.index('record')\n",
    "                dims[iRec] = 'forcing'\n",
    "\n",
    "                # save variable with new dimensions\n",
    "                outDS[ncVar] = xa.DataArray(ncDat, dims=dims)\n",
    "            else:\n",
    "                # retain any variables without a record dimension\n",
    "                outDS[ncVar] = xa.DataArray(ncDat)\n",
    "            # endif record\n",
    "        # end ncVar loop\n",
    "    # endwith\n",
    "\n",
    "    # stuff the global attributes into the new dataset\n",
    "    for att in globalAtt: outDS.attrs[att] = globalAtt[att]\n",
    "    outDS.to_netcdf(outNC, mode='w')\n",
    "    print('Completed {}'.format(outNC))\n",
    "# end recordDimRename()\n",
    "\n",
    "def kDistBandSplit(kFileNC, outDir='band_k_dist'):\n",
    "    \"\"\"\n",
    "    Split a full k-distribution into separate files for each band\n",
    "    \"\"\"\n",
    "\n",
    "    pathCheck(outDir, mkdir=True)\n",
    "\n",
    "    weights = [\n",
    "        0.1527534276, 0.1491729617, 0.1420961469, 0.1316886544, \n",
    "        0.1181945205, 0.1019300893, 0.0832767040, 0.0626720116, \n",
    "        0.0424925000, 0.0046269894, 0.0038279891, 0.0030260086, \n",
    "        0.0022199750, 0.0014140010, 0.0005330000, 0.0000750000\n",
    "    ]\n",
    "    xaWeights = XA.DataArray(\n",
    "        weights, dims={'gpt': range(len(weights))}, name='gpt_weights')\n",
    "\n",
    "    bandFiles = []\n",
    "    with XA.open_dataset(kFileNC) as kAllObj:\n",
    "        gLims = kAllObj.bnd_limits_gpt\n",
    "        ncVars = list(kAllObj.keys())\n",
    "        dimStr = 'gpt'\n",
    "\n",
    "        for iBand in kAllObj.bnd.values:\n",
    "            # make a separate netCDF for each band\n",
    "            outNC = '{}/coefficients_lw_band{:02d}.nc'.format(outDir, iBand+1)\n",
    "\n",
    "            # Dataset that will be written to netCDF with new variables and \n",
    "            # unedited global attribues\n",
    "            outDS = XA.Dataset()\n",
    "\n",
    "            # determine which variables need to be parsed\n",
    "            for ncVar in ncVars:\n",
    "                ncDat = kAllObj[ncVar]\n",
    "\n",
    "                if dimStr in kAllObj[ncVar].dims:\n",
    "                    # grab only the g-point information for this band\n",
    "                    # and convert to zero-offset\n",
    "                    i1, i2 = gLims[iBand].values-1\n",
    "                    ncDat = ncDat.isel(gpt=slice(i1, i2+1))\n",
    "                # endif\n",
    "\n",
    "                # write variable to output dataset\n",
    "                outDS[ncVar] = XA.DataArray(ncDat)\n",
    "            # end ncVar loop\n",
    "\n",
    "            # write weights to output file\n",
    "            outDS['gpt_weights'] = xaWeights\n",
    "\n",
    "            outDS.to_netcdf(outNC, mode='w')\n",
    "            #print('Completed {}'.format(outNC))\n",
    "            bandFiles.append(outNC)\n",
    "        # end band loop\n",
    "    # endwith\n",
    "\n",
    "    return bandFiles\n",
    "# end kDistBandSplit()\n",
    "\n",
    "class kDistOptBand:\n",
    "    def __init__(self, inFile, band, lw, idxForce):\n",
    "        \"\"\"\n",
    "        - Run a RRTMGP executable that performs computations for a single band\n",
    "        - Loop over bands and the possible g-point combinations within each \n",
    "            band, creating k-distribution and band-wise flux files for each \n",
    "            possible combination\n",
    "        - Compute broadband fluxes and heating rates\n",
    "        - Compute cost function from broadband parameters and determine \n",
    "            optimal combination of g-points\n",
    "\n",
    "        Input\n",
    "          inFile -- string, netCF created with kDistBandSplit() method\n",
    "          band -- int, band number that is being processed with object\n",
    "          lw -- boolean, do longwave domain (otherwise shortwave)\n",
    "          idxForce -- int, index of forcing scenario\n",
    "\n",
    "        Keywords\n",
    "        \"\"\"\n",
    "\n",
    "        self.inNC = str(inFile)\n",
    "        self.iBand = int(band)\n",
    "        self.domain = 'LW' if lw else 'SW'\n",
    "        self.iForce = int(idxForce)\n",
    "\n",
    "        # directory where model will be run for each g-point \n",
    "        # combination\n",
    "        self.workDir = '{}/workdir_band_{}'.format(os.getcwd(), self.iBand)\n",
    "        pathCheck(self.workDir, mkdir=True)\n",
    "\n",
    "        # attributes that will get re-assigned in class\n",
    "        self.gCombine = []\n",
    "        self.wCombine = []\n",
    "        self.trialNC = []\n",
    "    # end constructor\n",
    "\n",
    "    def gPointCombine(self):\n",
    "        \"\"\"\n",
    "        Combine g-points in a given band with adjacent g-point\n",
    "\n",
    "        TODO: will probably have to modify other variables in \n",
    "        self.inNC like Ben does in combine_gpoints_fn.py\n",
    "        \"\"\"\n",
    "\n",
    "        with XA.open_dataset(self.inNC) as kDS:\n",
    "            kVal = kDS.kmajor\n",
    "            weights = kDS.gpt_weights\n",
    "\n",
    "            # combine nearest neighbor g-point indices \n",
    "            # and associated weights\n",
    "            nGpt = kDS.dims['gpt']\n",
    "            self.gCombine = [[x, x+1] for x in range(nGpt-1)]\n",
    "            self.wCombine = [weights[np.array(gc)] for gc in self.gCombine]\n",
    "\n",
    "            for gc, wc in zip(self.gCombine, self.wCombine):\n",
    "                outNC = '{}/coefficients_{}_g{}-{}.nc'.format(\n",
    "                    self.workDir, self.domain, gc[0], gc[1])\n",
    "                self.trialNC.append(outNC)\n",
    "            # end combination loop\n",
    "        # endwith\n",
    "    # end gPointCombine()\n",
    "\n",
    "    def runBandRRTMGP(self):\n",
    "        \"\"\"\n",
    "        Run the RRTMGP executable for a single band\n",
    "        \"\"\"\n",
    "    # end runBandRRTMGP()\n",
    "    \n",
    "# end kDistOptBand\n",
    "\n",
    "def computeBB():\n",
    "    \"\"\"\n",
    "    Compute broadband fluxes after g-points have been combined\n",
    "    \"\"\"\n",
    "# end computeBB()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = '/global/project/projectdirs/e3sm/' + \\\n",
    "    'pernak18/reference_netCDF/g-point-reduce'\n",
    "kFullNC = '{}/rrtmgp-data-lw-g256-2018-12-04.nc'.format(PROJECT)\n",
    "pathCheck(kFullNC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only do one domain or the other\n",
    "doLW = True\n",
    "doSW = False if doLW else True\n",
    "\n",
    "# forcing scenario (0 is no forcing...need a more comprehensive list)\n",
    "IFORCING = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide full k-distribution into subsets for each band\n",
    "print('Band splitting commenced')\n",
    "kFiles = kDistBandSplit(kFullNC)\n",
    "print('Band splitting completed')\n",
    "\n",
    "# loop over bands and instantiate a band optimization object\n",
    "# optimizing each band\n",
    "for iBand, kFile in enumerate(kFiles):\n",
    "    kObj = kDistOptBand(kFile, iBand+1, doLW, IFORCING)\n",
    "    kObj.gPointCombine()\n",
    "    for outNC in kObj.trialNC: print(outNC)\n",
    "# end kFile loop\n",
    "\n",
    "# small edit to flux file -- rename the `record` dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
