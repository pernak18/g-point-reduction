{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By-Band _g_-Point Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "\n",
    "`numpy` is installed in the Python environment at NERSC (`module load python`), but `xarray` is not, so the user must install the package on their own. `PIPPATH` is the assumed location. This notebook depends heavily on `xarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil, glob\n",
    "\n",
    "# \"standard\" install\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# directory in which libraries installed with conda are saved\n",
    "PIPPATH = '{}/.local/'.format(os.path.expanduser('~')) + \\\n",
    "    'cori/3.7-anaconda-2019.10/lib/python3.7/site-packages'\n",
    "PATHS = ['common', PIPPATH]\n",
    "for path in PATHS: sys.path.append(path)\n",
    "\n",
    "# needed at AER unless i update `pandas`\n",
    "import warnings\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# user must do `pip install xarray` on cori (or other NERSC machines)\n",
    "import xarray as xa\n",
    "\n",
    "# local module\n",
    "import by_band_lib as BYBAND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = '/global/project/projectdirs/e3sm/pernak18/'\n",
    "EXE = '{}/g-point-reduction/garand_atmos/rrtmgp_garand_atmos'.format(\n",
    "    PROJECT)\n",
    "REFDIR = '{}/reference_netCDF/g-point-reduce'.format(PROJECT)\n",
    "\n",
    "KFULLNC = '{}/rrtmgp-data-lw-g256-2018-12-04.nc'.format(REFDIR)\n",
    "GARAND = '{}/multi_garand_template_single_band.nc'.format(REFDIR)\n",
    "\n",
    "# test (RRTMGP) and reference (LBL) flux netCDF files\n",
    "TESTNC = '{}/rrtmgp-lw-flux-inputs-outputs-garandANDpreind.nc'.format(REFDIR)\n",
    "REFNC = '{}/lblrtm-lw-flux-inputs-outputs-garandANDpreind.nc'.format(REFDIR)\n",
    "PATHS = [KFULLNC, EXE, TESTNC, REFNC, GARAND]\n",
    "\n",
    "BANDSPLITDIR = 'band_k_dist'\n",
    "FULLBANDFLUXDIR = 'full_band_flux'\n",
    "\n",
    "for PATH in PATHS: BYBAND.pathCheck(PATH)\n",
    "\n",
    "CWD = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only do one domain or the other\n",
    "DOLW = True\n",
    "DOSW = not DOLW\n",
    "DOMAIN = 'LW' if DOLW else 'SW'\n",
    "NBANDS = 16 if DOLW else 14\n",
    "\n",
    "# does band-splitting need to be done, or are there existing files \n",
    "# that have divided up the full k-distribution?\n",
    "BANDSPLIT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Band Splitting\n",
    "\n",
    "Break up full _k_-distribution file into separate distributions for each band, then calculate the corresponding fluxes. This should only need to be run once.\n",
    "\n",
    "After some clarifications from Robert (30-Nov-2020), I believe the plan of action is:\n",
    "\n",
    "1. create Nbands k-distribution files\n",
    "2. drive the Fortran executable Nbands times to produce Nbands flux results\n",
    "3. the trial g-point combinations then loop over bands and the possible g-point combinations within each band, creating k-distribution and band-wise flux files for each possible combination\n",
    "4. The Python code assembles broadband fluxes from the band-wise flux files in order to compute the cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band splitting commenced\n",
      "Band splitting completed\n"
     ]
    }
   ],
   "source": [
    "if BANDSPLIT:\n",
    "    print('Band splitting commenced')\n",
    "    BYBAND.pathCheck(BANDSPLITDIR, mkdir=True)\n",
    "    BYBAND.pathCheck(FULLBANDFLUXDIR, mkdir=True)\n",
    "    kFiles, fullBandFluxes = [], []\n",
    "    for iBand in range(NBANDS):\n",
    "        # divide full k-distribution into subsets for each band\n",
    "        kObj = BYBAND.gCombine_kDist(KFULLNC, iBand, DOLW, 1, \n",
    "            fullBandKDir=BANDSPLITDIR, fullBandFluxDir=FULLBANDFLUXDIR)\n",
    "        kFiles.append(kObj.kBandNC)\n",
    "        kObj.kDistBand()\n",
    "\n",
    "        # quick, non-parallelized flux calculations (because the \n",
    "        # executable is run in one directory)\n",
    "        # TO DO: HAVEN'T TESTED THIS SINCE IT HAS BEEN MOVED OUT OF THE CLASS\n",
    "        BYBAND.fluxCompute(kObj.kBandNC, kObj.profiles, kObj.exe, \n",
    "                           kObj.fullBandFluxDir, kObj.fluxBandNC)\n",
    "        fullBandFluxes.append(kObj.fluxBandNC)\n",
    "    # end band loop\n",
    "    print('Band splitting completed')\n",
    "else:\n",
    "    kFiles = sorted(glob.glob('{}/coefficients_{}_band??.nc'.format(\n",
    "        BANDSPLITDIR, DOMAIN)))\n",
    "    fullBandFluxes = sorted(glob.glob('{}/flux_{}_band??.nc'.format(\n",
    "        FULLBANDFLUXDIR, DOMAIN)))\n",
    "\n",
    "    if len(kFiles) == 0 or len(fullBandFluxes) == 0:\n",
    "        print('WARNING: set `BANDSPLIT` to `True` and run this cell again')\n",
    "# endif BANDSPLIT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _g_-Point Combining\n",
    "\n",
    "Combine _g_-point reduced for bands with full-band fluxes from other bands, find optimal _g_-point combination for given iteration, proceed to next iteration.\n",
    "\n",
    "First, find all _g_-point combinations for each band. Store the band object in a dictionary for use in flux computation. This cell only needs to be run once, and to save time in development, the dictionary is saved in a `pickle` file and can be loaded in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band 1 complete\n",
      "Band 2 complete\n",
      "Band 3 complete\n",
      "Band 4 complete\n",
      "Band 5 complete\n",
      "Band 6 complete\n",
      "Band 7 complete\n",
      "Band 8 complete\n",
      "Band 9 complete\n",
      "Band 10 complete\n",
      "Band 11 complete\n",
      "Band 12 complete\n",
      "Band 13 complete\n",
      "Band 14 complete\n",
      "Band 15 complete\n",
      "Band 16 complete\n"
     ]
    }
   ],
   "source": [
    "# this should be parallelized; also is part of preprocessing so we \n",
    "# shouldn't have to run it multiple times\n",
    "kBandDict = {}\n",
    "for iBand, kFile in enumerate(kFiles):\n",
    "    #if iBand != 0: continue\n",
    "    band = iBand + 1\n",
    "    kObj = BYBAND.gCombine_kDist(kFile, iBand, DOLW, 1, \n",
    "        fullBandKDir=BANDSPLITDIR, \n",
    "        fullBandFluxDir=FULLBANDFLUXDIR)\n",
    "    kObj.gPointCombine()\n",
    "    kBandDict['band{:02d}'.format(band)] = kObj\n",
    "\n",
    "    print('Band {} complete'.format(band))\n",
    "# end kFile loop\n",
    "\n",
    "import pickle\n",
    "with open('temp.pickle', 'wb') as fp: pickle.dump(kBandDict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute fluxes in parallel for every _g_-point combination -- merging occurs in each band, and these combinations in a given band are used with broadband fluxes from other bands. These concatenations each have an associated `xarray` dataset assigned to it. Cost function components are then calculated based for each dataset, and the one that minimizes the error in the cost function will have its associated netCDF saved to disk.\n",
    "\n",
    "Uncomment pickling block to restore dictionary from previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling for developement purposes so this dictionary doesn't need \n",
    "# to be regenerated for every code change.\n",
    "import pickle, time\n",
    "with open('temp.pickle', 'rb') as fp: kBandDict = pickle.load(fp)\n",
    "\n",
    "# cost function variables\n",
    "CFCOMPS = ['band_flux_dn', 'band_flux_up']\n",
    "CFLEVS = [0, 10000, 102000] # pressure levels of interest in Pa\n",
    "CFWGT = [0.5, 0.5]\n",
    "\n",
    "# forcing scenario (0 is no forcing...need a more comprehensive list)\n",
    "IFORCING = 0\n",
    "\n",
    "# instantiate object for computing cost\n",
    "coObj = BYBAND.gCombine_Cost(\n",
    "    kBandDict, fullBandFluxes, REFNC, TESTNC, \n",
    "    IFORCING, 1, profilesNC=GARAND, exeRRTMGP=EXE, \n",
    "    costFuncComp=CFCOMPS, costFuncLevs=CFLEVS, \n",
    "    costWeights=CFWGT)\n",
    "\n",
    "# number of iterations for the optimization\n",
    "NITER = 17\n",
    "\n",
    "for i in range(1, NITER+1):\n",
    "    t1 = time.process_time()\n",
    "\n",
    "    print('Iteration {}'.format(i))\n",
    "    temp = time.process_time()\n",
    "    coObj.kMap()\n",
    "    print('kMap: {:.4f}'.format(time.process_time()-temp))\n",
    "\n",
    "    temp = time.process_time()\n",
    "    coObj.fluxComputePool()\n",
    "    print('Flux Compute: {:.4f}'.format(time.process_time()-temp))\n",
    "\n",
    "    temp = time.process_time()\n",
    "    coObj.fluxCombine()\n",
    "    print('Flux Combine: {:.4f}'.format(time.process_time()-temp))\n",
    "\n",
    "    temp = time.process_time()\n",
    "    coObj.costFuncComp()\n",
    "    print('Cost function computation: {:.4f}'.format(time.process_time()-temp))\n",
    "\n",
    "    temp = time.process_time()\n",
    "    coObj.findOptimal()\n",
    "    print('findOptimal: {:.4f}'.format(time.process_time()-temp))\n",
    "\n",
    "    if coObj.optimized: break\n",
    "\n",
    "    coObj.setupNextIter()\n",
    "\n",
    "    print('Full iteration: {:.4f}'.format(time.process_time()-t1))\n",
    "# end iteration loop\n",
    "\n",
    "t1 = time.process_time()\n",
    "coObj.calcOptFlux(KFULLNC)\n",
    "print('New k-file {:.4f}'.format(time.process_time()-t1))\n",
    "\n",
    "print('Optimization complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
