{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By-Band _g_-Point Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "\n",
    "`numpy` is installed in the Python environment at NERSC (`module load python`), but `xarray` is not, so the user must install the package on their own. `PIPPATH` is the assumed location. This notebook depends heavily on `xarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil\n",
    "\n",
    "# \"standard\" install\n",
    "import numpy as np\n",
    "\n",
    "# directory in which libraries installed with conda are saved\n",
    "PIPPATH = '{}/.local/'.format(os.path.expanduser('~')) + \\\n",
    "    'cori/3.7-anaconda-2019.10/lib/python3.7/site-packages'\n",
    "PATHS = ['common', PIPPATH]\n",
    "for path in PATHS: sys.path.append(path)\n",
    "\n",
    "# user must do `pip install xarray` on cori (or other NERSC machines)\n",
    "import xarray as XA\n",
    "\n",
    "# common submodule\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function and Class Definitions\n",
    "\n",
    "This cell will eventually go into its own module and be imported in the previous cell, but first I wanna finish developing and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def pathCheck(path, mkdir=False):\n",
    "    \"\"\"\n",
    "    Determine if file exists. If not, throw an Assertion Exception\n",
    "    \"\"\"\n",
    "\n",
    "    if mkdir:\n",
    "        # mkdir -p -- create dir tree\n",
    "        if not os.path.exists(path): os.makedirs(path)\n",
    "    else:\n",
    "        assert os.path.exists(path), 'Could not find {}'.format(path)\n",
    "    # endif mkdir\n",
    "# end pathCheck\n",
    "\n",
    "def kDistBandSplit(kFileNC, outDir='band_k_dist'):\n",
    "    \"\"\"\n",
    "    Split a full k-distribution into separate files for each band\n",
    "    \"\"\"\n",
    "\n",
    "    pathCheck(outDir, mkdir=True)\n",
    "\n",
    "    weights = [\n",
    "        0.1527534276, 0.1491729617, 0.1420961469, 0.1316886544, \n",
    "        0.1181945205, 0.1019300893, 0.0832767040, 0.0626720116, \n",
    "        0.0424925000, 0.0046269894, 0.0038279891, 0.0030260086, \n",
    "        0.0022199750, 0.0014140010, 0.0005330000, 0.0000750000\n",
    "    ]\n",
    "    xaWeights = XA.DataArray(\n",
    "        weights, dims={'gpt': range(len(weights))}, name='gpt_weights')\n",
    "\n",
    "    bandFiles = []\n",
    "    with XA.open_dataset(kFileNC) as kAllObj:\n",
    "        gLims = kAllObj.bnd_limits_gpt\n",
    "        ncVars = list(kAllObj.keys())\n",
    "        dimStr = 'gpt'\n",
    "\n",
    "        for iBand in kAllObj.bnd.values:\n",
    "            # make a separate netCDF for each band\n",
    "            outNC = '{}/coefficients_lw_band{:02d}.nc'.format(outDir, iBand+1)\n",
    "\n",
    "            # Dataset that will be written to netCDF with new variables and \n",
    "            # unedited global attribues\n",
    "            outDS = XA.Dataset()\n",
    "\n",
    "            # determine which variables need to be parsed\n",
    "            for ncVar in ncVars:\n",
    "                ncDat = kAllObj[ncVar]\n",
    "\n",
    "                if dimStr in kAllObj[ncVar].dims:\n",
    "                    # grab only the g-point information for this band\n",
    "                    # and convert to zero-offset\n",
    "                    i1, i2 = gLims[iBand].values-1\n",
    "                    ncDat = ncDat.isel(gpt=slice(i1, i2+1))\n",
    "                # endif\n",
    "\n",
    "                # write variable to output dataset\n",
    "                outDS[ncVar] = XA.DataArray(ncDat)\n",
    "            # end ncVar loop\n",
    "\n",
    "            # write weights to output file\n",
    "            outDS['gpt_weights'] = xaWeights\n",
    "\n",
    "            outDS.to_netcdf(outNC, mode='w')\n",
    "            #print('Completed {}'.format(outNC))\n",
    "            bandFiles.append(outNC)\n",
    "        # end band loop\n",
    "    # endwith\n",
    "\n",
    "    return bandFiles\n",
    "# end kDistBandSplit()\n",
    "\n",
    "def costFuncComp(tst_file, ref_file, levs=[0, 10000, 102000], iRecord=0, \n",
    "                 ncVars=['net_flux', 'heating_rate', 'band_flux_net']):\n",
    "    \"\"\"\n",
    "    Calculate flexible cost function where RRTMGP-LBLRTM RMS error for \n",
    "    any number of allowed parameters (usually just flux or HR) over many \n",
    "    levels is computed\n",
    "    \n",
    "    Inputs\n",
    "        tst_file -- string, RRTMGP (test model) netCDF file with fluxes\n",
    "        ref_file -- string, LBLRTM (reference model) netCDF file with fluxes\n",
    "\n",
    "    Output\n",
    "        outParams -- list of cost function arrays (RMS test-ref differences \n",
    "          averaged over columns); 1 element per input variable (ncVars)\n",
    "\n",
    "    Keywords\n",
    "        levs -- list of floats; pressure levels of interest in Pa\n",
    "        iRecord -- int; index for forcing scenario (default 0 is no forcing)\n",
    "        ncVars -- list of strings; netCDF variable names of the arrays to \n",
    "          include in the cost function\n",
    "    \"\"\"\n",
    "\n",
    "    outParams = []\n",
    "    with xr.open_dataset(tst_file) as tst, xr.open_dataset(ref_file) as ref:\n",
    "        # Compute differences in all variables in datasets at levels \n",
    "        # closest to user-provided pressure levels\n",
    "        # TODO: confirm this is doing what we expect it to\n",
    "        subsetErr = (tst-ref).sel(lev=levs, method='nearest')\n",
    "        for ncVar in ncVars:\n",
    "            # pressure dimension will depend on parameter\n",
    "            # layer for HR, level for everything else\n",
    "            pStr = 'lay' if 'heating_rate' in ncVar else 'lev'\n",
    "\n",
    "            # get array for variable, then compute its test-ref RMS \n",
    "            # over all columns and given pressure levels for a given \n",
    "            # forcing scenario\n",
    "            ncParam = getattr(subsetErr, ncVar)\n",
    "            outParams.append(\n",
    "                (ncParam.isel(record=iRecord)**2).mean(dim=('col', pStr)))\n",
    "        # end ncVar loop\n",
    "    # endwith\n",
    "\n",
    "    return outParams\n",
    "# end costFuncComp\n",
    "    \n",
    "def normCost(tst_file, ref_file, norm, \n",
    "             ncVars=['net_flux', 'heating_rate', 'band_flux_net'], \n",
    "             levs=[0, 10000, 102000], ):\n",
    "    \"\"\"    \n",
    "    Returns the summary terms in the cost function\n",
    "      Each element in each term is normalized (normally by the error at i\n",
    "      teration 0)\n",
    "\n",
    "    Inputs\n",
    "        tst_file -- string, RRTMGP (test model) netCDF file with fluxes\n",
    "        ref_file -- string, LBLRTM (reference model) netCDF file with fluxes\n",
    "        norm -- list of floats with RMS error for a given \n",
    "          cost function component\n",
    "\n",
    "    Output\n",
    "        list of floats that are the RMS error (RRTMGP-LBLRTM)\n",
    "        for each cost function component normalized by the input \n",
    "        `norm` parameter\n",
    "\n",
    "    Keywords\n",
    "        levs -- list of floats; pressure levels of interest in Pa\n",
    "        iRecord -- int; index for whatever the 'record' dimension is in \n",
    "          the input netCDF files \n",
    "        ncVars -- list of strings; netCDF variable names of the arrays to \n",
    "          include in the cost function\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    tst_cost = costFuncComp(tst_file, ref_file, ncVars=ncVars, levs=levs)\n",
    "\n",
    "    # Each scalar term in the cost function is the RMS across the\n",
    "    #   normalized error in each component. cost_function_components() returns\n",
    "    #   the squared error\n",
    "    return [np.sqrt((c/n).mean()) for (c, n) in zip(tst_cost, norm)]\n",
    "# end normCost\n",
    "\n",
    "def recordDimRename(inNC, outNC):\n",
    "    \"\"\"\n",
    "    Rename \"record\" dimension in given netCDF file\n",
    "    \"\"\"\n",
    "    \n",
    "    outDS = xa.Dataset()\n",
    "\n",
    "    with xa.open_dataset(inNC) as inObj:\n",
    "        # save global attributes for later -- will stuff into buffer, unedited\n",
    "        globalAtt = inObj.attrs\n",
    "\n",
    "        # write buffer netCDF, complete with global attributes\n",
    "        ncVars = list(inObj.keys())\n",
    "\n",
    "        for ncVar in ncVars: \n",
    "            ncDat = inObj[ncVar]\n",
    "\n",
    "            if 'record' in ncDat.dims:\n",
    "                # which dimension corresponds to `record`?\n",
    "                dims = list(ncDat.dims)\n",
    "                iRec = dims.index('record')\n",
    "                dims[iRec] = 'forcing'\n",
    "\n",
    "                # save variable with new dimensions\n",
    "                outDS[ncVar] = xa.DataArray(ncDat, dims=dims)\n",
    "            else:\n",
    "                # retain any variables without a record dimension\n",
    "                outDS[ncVar] = xa.DataArray(ncDat)\n",
    "            # endif record\n",
    "        # end ncVar loop\n",
    "    # endwith\n",
    "\n",
    "    # stuff the global attributes into the new dataset\n",
    "    for att in globalAtt: outDS.attrs[att] = globalAtt[att]\n",
    "    outDS.to_netcdf(outNC, mode='w')\n",
    "    print('Completed {}'.format(outNC))\n",
    "# end recordDimRename()\n",
    "\n",
    "class kDistOptBand:\n",
    "    def __init__(self, inFile, band, lw, idxForce, iCombine):\n",
    "        \"\"\"\n",
    "        - For a given band, loop over possible g-point combinations within \n",
    "            each band, creating k-distribution and band-wise flux files for \n",
    "            each possible combination\n",
    "        - Run a RRTMGP executable that performs computations for a single band\n",
    "        - Compute broadband fluxes and heating rates\n",
    "        - Compute cost function from broadband parameters and determine \n",
    "            optimal combination of g-points\n",
    "\n",
    "        Input\n",
    "          inFile -- string, netCF created with kDistBandSplit() method\n",
    "          band -- int, band number that is being processed with object\n",
    "          lw -- boolean, do longwave domain (otherwise shortwave)\n",
    "          idxForce -- int, index of forcing scenario\n",
    "          iCombine -- int, index for what iteration of g-point combining is \n",
    "              underway\n",
    "\n",
    "        Keywords\n",
    "        \"\"\"\n",
    "\n",
    "        # see constructor doc\n",
    "        self.inNC = str(inFile)\n",
    "        self.iBand = int(band)\n",
    "        self.doLW = bool(lw)\n",
    "        self.domainStr = 'LW' if lw else 'SW'\n",
    "        self.iForce = int(idxForce)\n",
    "        self.iCombine = int(iCombine)\n",
    "\n",
    "        # directory where model will be run for each g-point \n",
    "        # combination\n",
    "        self.workDir = '{}/workdir_band_{}'.format(os.getcwd(), self.iBand)\n",
    "        pathCheck(self.workDir, mkdir=True)\n",
    "\n",
    "        # directory to store optimal netCDFs for each iteration and band\n",
    "        self.optDir = '{}/band_{}_opt'.format(os.getcwd(), self.iBand)\n",
    "        pathCheck(self.optDir, mkdir=True)\n",
    "\n",
    "        # metadata for keeping track of how g-points were \n",
    "        # combined; we will keep appending after each iteration\n",
    "        self.gCombine = {}\n",
    "\n",
    "        # what netCDF variables have a g-point dimension and will thus \n",
    "        # need to be modified in the combination iterations?\n",
    "        self.gptVars = ['kmajor', 'gpt_weights']\n",
    "        if self.doLW:\n",
    "            self.gptVars.append('plank_fraction')\n",
    "        else:\n",
    "            self.gptVars += ['rayl_lower', 'rayl_upper', \n",
    "                            'solar_source_facular' , \n",
    "                            'solar_source_sunspot', 'solar_source_quiet']\n",
    "        # endif doLW\n",
    "\n",
    "        # ATTRIBUTES THAT WILL GET RE-ASSIGNED IN CLASS\n",
    "\n",
    "        # list of netCDFs for each g-point combination in a given band \n",
    "        # and combination iteration\n",
    "        self.trialNC = []\n",
    "\n",
    "        # the trialNC that optimizes cost function for given comb iter\n",
    "        # starts off as input file\n",
    "        self.optNC = str(self.inNC)\n",
    "\n",
    "        # the number of g-points in a given comb iter\n",
    "        self.nGpt = 16\n",
    "\n",
    "        # original g-point IDs for a given band\n",
    "        # TO DO: have not started trying to preserve these guys\n",
    "        self.gOrigID = range(1, self.nGpt+1)\n",
    "    # end constructor\n",
    "\n",
    "    def gPointCombine(self):\n",
    "        \"\"\"\n",
    "        Combine g-points in a given band with adjacent g-point\n",
    "\n",
    "        TOcDO: will probably have to modify other variables in \n",
    "        self.inNC like Ben does in combine_gpoints_fn.py\n",
    "        \"\"\"\n",
    "\n",
    "        with XA.open_dataset(self.inNC) as kDS:\n",
    "            kVal = kDS.kmajor\n",
    "            weights = kDS.gpt_weights\n",
    "            ncVars = list(kDS.keys())\n",
    "\n",
    "            # combine all nearest neighbor g-point indices \n",
    "            # and associated weights for given band\n",
    "            self.nGpt = kDS.dims['gpt']\n",
    "            gCombine = [[x, x+1] for x in range(self.nGpt-1)]\n",
    "            wCombine = [weights[np.array(gc)] for gc in gCombine]\n",
    "\n",
    "            for gc, wc in zip(gCombine, wCombine):\n",
    "                # loop over each g-point combination and create \n",
    "                # a k-distribution netCDF for each\n",
    "                outNC='{}/coefficients_{}_g{:02d}-{:02d}_iter{:02d}.nc'.format(\n",
    "                    self.workDir, self.domainStr, gc[0], gc[1], self.iCombine)\n",
    "                self.trialNC.append(outNC)\n",
    "\n",
    "                g1, g2 = gc\n",
    "                w1, w2 = wc\n",
    "\n",
    "                outDS = XA.Dataset()\n",
    "\n",
    "                # each trial netCDF has its own set of g-points \n",
    "                # that we will save for metadata purposes -- \n",
    "                # the combination that optimizes the cost function\n",
    "                # will have its `g_combine` attribute perpetuated\n",
    "                # append g-point combinations metadata for given \n",
    "                # band and iteration in given band\n",
    "                outDS.attrs['g_combine'] = '{}+{}'.format(g1, g2)\n",
    "\n",
    "                for ncVar in ncVars:\n",
    "                    ncDat = kDS[ncVar]\n",
    "                    if ncVar in self.gptVars:\n",
    "                        kg1, kg2 = ncDat.sel(gpt=g1), ncDat.isel(gpt=g2)\n",
    "\n",
    "                        if ncVar == 'gpt_weights':\n",
    "                            # replace g1' weight with integrated weight at \n",
    "                            # g1 and g2\n",
    "                            ncDat = XA.where(\n",
    "                                ncDat.gpt == g1, w1 + w2, ncDat)\n",
    "                        else:\n",
    "                            pass\n",
    "                            # replace g1' slice with weighted average of \n",
    "                            # g1 and g2; TO DO: make sure this is how \n",
    "                            # other params in addition to k are treated\n",
    "                            ncDat = XA.where(ncDat.gpt == g1, \n",
    "                                (kg1*w1 + kg2*w2) / (w1 + w2), ncDat)\n",
    "                        # endif ncVar\n",
    "\n",
    "                        # remove the g2 slice; weird logic:\n",
    "                        # http://xarray.pydata.org/en/stable/generated/\n",
    "                        # xarray.DataArray.where.html#xarray.DataArray.where\n",
    "                        ncDat = ncDat.where(ncDat.gpt != g2, drop=True)\n",
    "                    else:\n",
    "                        # retain any variables without a gpt dimension\n",
    "                        pass\n",
    "                    # endif ncVar\n",
    "\n",
    "                    # stuff new dataset with combined or unaltered data\n",
    "                    outDS[ncVar] = XA.DataArray(ncDat)\n",
    "                # end ncVar loop\n",
    "\n",
    "                outDS.to_netcdf(outNC, 'w')\n",
    "            # end combination loop\n",
    "        # endwith kDS\n",
    "    # end gPointCombine()\n",
    "\n",
    "    def findOptimal(self, iCombine):\n",
    "        \"\"\"\n",
    "        Determine which g-point combination for a given iteration in a band\n",
    "        optimized the cost function\n",
    "\n",
    "        Input\n",
    "            iCombine -- int, iteration number for g-point combinations \n",
    "                in a given band\n",
    "        \"\"\"\n",
    "\n",
    "        # TO DO: loop through trial netCDFs, calculate their normalized \n",
    "        # cost function components, then determine what is the optimal solution\n",
    "        iOpt = 0\n",
    "        self.optNC = self.trialNC[iOpt]\n",
    "\n",
    "        # determine optimal combination and grab g-point combination attribute\n",
    "        with XA.open_dataset(self.optNC) as optDS:\n",
    "            self.gCombine['iter{:02d}'.format(iCombine)] = \\\n",
    "              optDS.attrs['g_combine']\n",
    "\n",
    "        for i in self.gCombine.keys(): print(self.gCombine[i])\n",
    "    # end findOptimal()\n",
    "    \n",
    "    def runBandRRTMGP(self):\n",
    "        \"\"\"\n",
    "        Run the RRTMGP executable for a single band\n",
    "        \"\"\"\n",
    "    # end runBandRRTMGP()\n",
    "# end kDistOptBand\n",
    "\n",
    "def computeBB():\n",
    "    \"\"\"\n",
    "    Compute broadband fluxes after g-points have been combined\n",
    "    \"\"\"\n",
    "# end computeBB()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only do one domain or the other\n",
    "DOLW = True\n",
    "DOSW = not DOLW\n",
    "NBANDS = 16 if DOLW else 14\n",
    "\n",
    "# forcing scenario (0 is no forcing...need a more comprehensive list)\n",
    "IFORCING = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths\n",
    "\n",
    "Robert: change the `EXE` and `GARAND` global variables to whatever path you have for your by-band executable and Garand profile specs, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = '/global/project/projectdirs/e3sm/pernak18/'\n",
    "KFULLNC = '{}/reference_netCDF/g-point-reduce/'.format(PROJECT) + \\\n",
    "  'rrtmgp-data-lw-g256-2018-12-04.nc'\n",
    "EXE = '{}/g-point-reduction/k-distribution-opt/rrtmgp_garand_atmos'.format(\n",
    "    PROJECT)\n",
    "GARAND = '{}/reference_netCDF/g-point-reduce/'.format(PROJECT) + \\\n",
    "  'lblrtm-lw-flux-inputs-outputs-garandANDpreind.nc'\n",
    "PATHS = [KFULLNC, EXE]\n",
    "for PATH in PATHS: pathCheck(PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executable Test\n",
    "\n",
    "This cell is meant to do a simple staging of the by-band _k_-distribution files and RRTMGP inputs (i.e., Garand profile specifications) and run a modified RRTMGP executable that works with single bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band splitting commenced\n",
      "Band splitting completed\n"
     ]
    }
   ],
   "source": [
    "import subprocess as SUB\n",
    "\n",
    "# divide full k-distribution into subsets for each band\n",
    "print('Band splitting commenced')\n",
    "kFiles = kDistBandSplit(KFULLNC)\n",
    "print('Band splitting completed')\n",
    "\n",
    "testDir = 'exe_test'\n",
    "pathCheck(testDir, mkdir=True)\n",
    "\n",
    "topDir = os.getcwd()\n",
    "os.chdir(testDir)\n",
    "\n",
    "# so we don't overwrite the LBL results\n",
    "inRRTMGP = 'rrtmgp-inputs-outputs.nc'\n",
    "shutil.copyfile(GARAND, inRRTMGP)\n",
    "\n",
    "# only doing one band for now\n",
    "for kFile in kFiles:\n",
    "    base = os.path.basename(kFile)\n",
    "    kAbsPath = '{}/{}'.format(topDir, kFile)\n",
    "    if os.path.islink(base): os.unlink(base)\n",
    "    os.symlink(kAbsPath, base)\n",
    "    \n",
    "    #SUB.call([EXE, inRRTMGP, base])\n",
    "    break\n",
    "# end kFile loop\n",
    "\n",
    "os.chdir(topDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band splitting commenced\n",
      "Band splitting completed\n",
      "band_k_dist/coefficients_lw_band01.nc\n",
      "0+1\n",
      "/global/u1/p/pernak18/RRTMGP/g-point-reduction/workdir_band_1/coefficients_LW_g00-01_iter01.nc\n",
      "0+1\n",
      "/global/u1/p/pernak18/RRTMGP/g-point-reduction/workdir_band_1/coefficients_LW_g00-01_iter02.nc\n",
      "0+1\n",
      "/global/u1/p/pernak18/RRTMGP/g-point-reduction/workdir_band_1/coefficients_LW_g00-01_iter03.nc\n",
      "0+1\n",
      "/global/u1/p/pernak18/RRTMGP/g-point-reduction/workdir_band_1/coefficients_LW_g00-01_iter04.nc\n",
      "0+1\n",
      "/global/u1/p/pernak18/RRTMGP/g-point-reduction/workdir_band_1/coefficients_LW_g00-01_iter05.nc\n",
      "0+1\n",
      "/global/u1/p/pernak18/RRTMGP/g-point-reduction/workdir_band_1/coefficients_LW_g00-01_iter06.nc\n",
      "0+1\n",
      "/global/u1/p/pernak18/RRTMGP/g-point-reduction/workdir_band_1/coefficients_LW_g00-01_iter07.nc\n",
      "0+1\n",
      "/global/u1/p/pernak18/RRTMGP/g-point-reduction/workdir_band_1/coefficients_LW_g00-01_iter08.nc\n",
      "0+1\n",
      "/global/u1/p/pernak18/RRTMGP/g-point-reduction/workdir_band_1/coefficients_LW_g00-01_iter09.nc\n",
      "0+1\n",
      "/global/u1/p/pernak18/RRTMGP/g-point-reduction/workdir_band_1/coefficients_LW_g00-01_iter10.nc\n",
      "0+1\n",
      "/global/u1/p/pernak18/RRTMGP/g-point-reduction/workdir_band_1/coefficients_LW_g00-01_iter11.nc\n",
      "0+1\n",
      "/global/u1/p/pernak18/RRTMGP/g-point-reduction/workdir_band_1/coefficients_LW_g00-01_iter12.nc\n",
      "0+1\n",
      "/global/u1/p/pernak18/RRTMGP/g-point-reduction/workdir_band_1/coefficients_LW_g00-01_iter13.nc\n",
      "0+1\n",
      "/global/u1/p/pernak18/RRTMGP/g-point-reduction/workdir_band_1/coefficients_LW_g00-01_iter14.nc\n",
      "0+1\n",
      "/global/u1/p/pernak18/RRTMGP/g-point-reduction/workdir_band_1/coefficients_LW_g00-01_iter15.nc\n",
      "Band 1 complete\n"
     ]
    }
   ],
   "source": [
    "# divide full k-distribution into subsets for each band\n",
    "print('Band splitting commenced')\n",
    "kFiles = kDistBandSplit(KFULLNC)\n",
    "print('Band splitting completed')\n",
    "\n",
    "# leave `bands` empty if all bands should be processed\n",
    "bands = [1]\n",
    "if not bands: bands = range(1, NBANDS+1)\n",
    "\n",
    "# loop over bands and instantiate a band optimization object\n",
    "# optimizing each band\n",
    "for iBand, kFile in enumerate(kFiles):\n",
    "    band = iBand + 1\n",
    "    if band not in bands: continue\n",
    "\n",
    "    iComb = 1\n",
    "\n",
    "    while True:\n",
    "        print(kFile)\n",
    "\n",
    "        # start with `kFile` with no g-point combinations for a given band\n",
    "        kObj = kDistOptBand(kFile, band, DOLW, IFORCING, iComb)\n",
    "\n",
    "        kObj.gPointCombine()\n",
    "\n",
    "        # if there are not enough g-points to combine, stop iterating\n",
    "        if kObj.nGpt == 1: break\n",
    "\n",
    "        # run RRTMGP on all files self.trialNC (each g-point combination)\n",
    "        #kObj.runBandRRTMGP()\n",
    "\n",
    "        # determine optimal combination\n",
    "        kObj.findOptimal(kObj.iCombine)\n",
    "\n",
    "        # keep a copy of the optimal netCDF\n",
    "        shutil.copy2(kObj.optNC, '{}/{}'.format(\n",
    "            kObj.optDir, os.path.basename(kObj.optNC)))\n",
    "        \n",
    "        # replace `kFile` with netCDF that corresponds to g-point combination\n",
    "        # that minimizes the cost function\n",
    "        kFile = kObj.optNC\n",
    "\n",
    "        # next iteration\n",
    "        iComb += 1\n",
    "    # end while\n",
    "\n",
    "    print('Band {} complete'.format(band))\n",
    "\n",
    "    # cleanup\n",
    "    shutil.rmtree(kObj.workDir)\n",
    "# end kFile loop\n",
    "\n",
    "# small edit to flux file -- rename the `record` dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
