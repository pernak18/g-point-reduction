{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By-Band _g_-Point Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "\n",
    "`numpy` is installed in the Python environment at NERSC (`module load python`), but `xarray` is not, so the user must install the package on their own. `PIPPATH` is the assumed location. This notebook depends heavily on `xarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil, glob\n",
    "\n",
    "# \"standard\" install\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# directory in which libraries installed with conda are saved\n",
    "PIPPATH = '{}/.local/'.format(os.path.expanduser('~')) + \\\n",
    "    'cori/3.7-anaconda-2019.10/lib/python3.7/site-packages'\n",
    "# PIPPATH = '/global/homes/e/emlawer/.local/cori/3.8-anaconda-2020.11/' + \\\n",
    "#     'lib/python3.8/site-packages'\n",
    "PATHS = ['common', PIPPATH]\n",
    "for path in PATHS: sys.path.append(path)\n",
    "\n",
    "# needed at AER unless i update `pandas`\n",
    "import warnings\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# user must do `pip install xarray` on cori (or other NERSC machines)\n",
    "import xarray as xa\n",
    "\n",
    "# local module\n",
    "import by_band_lib as BYBAND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only do one domain or the other\n",
    "DOLW = True\n",
    "DOMAIN = 'LW' if DOLW else 'SW'\n",
    "NBANDS = 16 if DOLW else 14\n",
    "\n",
    "# does band-splitting need to be done, or are there existing files \n",
    "# that have divided up the full k-distribution?\n",
    "BANDSPLIT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = '/global/project/projectdirs/e3sm/pernak18/'\n",
    "EXE = '{}/g-point-reduction/garand_atmos/rrtmgp_garand_atmos'.format(\n",
    "    PROJECT)\n",
    "REFDIR = '{}/reference_netCDF/g-point-reduce'.format(PROJECT)\n",
    "\n",
    "# test (RRTMGP) and reference (LBL) flux netCDF files, full k-distributions, \n",
    "# and by-band Garand input file\n",
    "fluxSuffix = 'flux-inputs-outputs-garandANDpreind.nc'\n",
    "if DOLW:\n",
    "    GARAND = '{}/multi_garand_template_single_band.nc'.format(REFDIR)\n",
    "    KFULLNC = '{}/rrtmgp-data-lw-g256-2018-12-04.nc'.format(REFDIR)\n",
    "    KFULLNC = '{}/rrtmgp-data-lw-g256-jen-xs.nc'.format(REFDIR)\n",
    "    REFNC = '{}/lblrtm-lw-{}'.format(REFDIR, fluxSuffix)\n",
    "    TESTNC = '{}/rrtmgp-lw-{}'.format(REFDIR, fluxSuffix)\n",
    "    #TESTNC = 'rrtmgp-lw-flux-inputs-outputs-garand-all.nc'\n",
    "else:\n",
    "    GARAND = '{}/charts_multi_garand_template_single_band.nc'.format(REFDIR)\n",
    "    KFULLNC = '{}/rrtmgp-data-sw-g224-2018-12-04.nc'.format(REFDIR)\n",
    "    REFNC = '{}/charts-sw-{}'.format(REFDIR, fluxSuffix)\n",
    "    TESTNC = '{}/rrtmgp-sw-{}'.format(REFDIR, fluxSuffix)\n",
    "# endif LW\n",
    "\n",
    "BANDSPLITDIR = 'band_k_dist'\n",
    "FULLBANDFLUXDIR = 'full_band_flux'\n",
    "\n",
    "for PATH in PATHS: BYBAND.pathCheck(PATH)\n",
    "\n",
    "CWD = os.getcwd()\n",
    "\n",
    "KPICKLE = '{}_k-dist.pickle'.format(DOMAIN)\n",
    "pickleCost = '{}_cost-optimize.pickle'.format(DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Band Splitting\n",
    "\n",
    "Break up full _k_-distribution file into separate distributions for each band, then calculate the corresponding fluxes. This should only need to be run once.\n",
    "\n",
    "After some clarifications from Robert (30-Nov-2020), I believe the plan of action is:\n",
    "\n",
    "1. create Nbands k-distribution files\n",
    "2. drive the Fortran executable Nbands times to produce Nbands flux results\n",
    "3. the trial g-point combinations then loop over bands and the possible g-point combinations within each band, creating k-distribution and band-wise flux files for each possible combination\n",
    "4. The Python code assembles broadband fluxes from the band-wise flux files in order to compute the cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BANDSPLIT:\n",
    "    print('Band splitting commenced')\n",
    "    BYBAND.pathCheck(BANDSPLITDIR, mkdir=True)\n",
    "    BYBAND.pathCheck(FULLBANDFLUXDIR, mkdir=True)\n",
    "    kFiles, fullBandFluxes = [], []\n",
    "    for iBand in range(NBANDS):\n",
    "        # divide full k-distribution into subsets for each band\n",
    "        kObj = BYBAND.gCombine_kDist(KFULLNC, iBand, DOLW, 1, \n",
    "            fullBandKDir=BANDSPLITDIR, fullBandFluxDir=FULLBANDFLUXDIR, \n",
    "            profilesNC=GARAND)\n",
    "        kFiles.append(kObj.kBandNC)\n",
    "        kObj.kDistBand()\n",
    "\n",
    "        # quick, non-parallelized flux calculations (because the \n",
    "        # executable is run in one directory)\n",
    "        # TO DO: HAVEN'T TESTED THIS SINCE IT HAS BEEN MOVED OUT OF THE CLASS\n",
    "        BYBAND.fluxCompute(kObj.kBandNC, kObj.profiles, kObj.exe, \n",
    "                           kObj.fullBandFluxDir, kObj.fluxBandNC)\n",
    "        fullBandFluxes.append(kObj.fluxBandNC)\n",
    "    # end band loop\n",
    "    print('Band splitting completed')\n",
    "else:\n",
    "    kFiles = sorted(glob.glob('{}/coefficients_{}_band??.nc'.format(\n",
    "        BANDSPLITDIR, DOMAIN)))\n",
    "    fullBandFluxes = sorted(glob.glob('{}/flux_{}_band??.nc'.format(\n",
    "        FULLBANDFLUXDIR, DOMAIN)))\n",
    "\n",
    "    if len(kFiles) == 0 or len(fullBandFluxes) == 0:\n",
    "        print('WARNING: set `BANDSPLIT` to `True` and run this cell again')\n",
    "# endif BANDSPLIT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pressure Levels for Cost Function\n",
    "\n",
    "Pressure levels [Pa] for the Garand atmospheres are printed to standard output with indices that can be used in the cost function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xa.open_dataset(REFNC) as refDS:\n",
    "    pLev = refDS['p_lev'].isel(record=0)\n",
    "for iLev, pLev in enumerate(pLev.isel(col=0).values): print(iLev, pLev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _g_-Point Combining\n",
    "\n",
    "Combine _g_-point reduced for bands with full-band fluxes from other bands, find optimal _g_-point combination for given iteration, proceed to next iteration.\n",
    "\n",
    "First, find all _g_-point combinations for each band. Store the band object in a dictionary for use in flux computation. This cell only needs to be run once, and to save time in development, the dictionary is saved in a `pickle` file and can be loaded in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band 1 complete\n",
      "Band 2 complete\n",
      "Band 3 complete\n",
      "Band 4 complete\n",
      "Band 5 complete\n",
      "Band 6 complete\n",
      "Band 7 complete\n",
      "Band 8 complete\n",
      "Band 9 complete\n",
      "Band 10 complete\n",
      "Band 11 complete\n",
      "Band 12 complete\n",
      "Band 13 complete\n",
      "Band 14 complete\n",
      "Band 15 complete\n",
      "Band 16 complete\n"
     ]
    }
   ],
   "source": [
    "# this should be parallelized; also is part of preprocessing so we \n",
    "# shouldn't have to run it multiple times\n",
    "kBandDict = {}\n",
    "for iBand, kFile in enumerate(kFiles):\n",
    "    #if iBand != 0: continue\n",
    "    band = iBand + 1\n",
    "    kObj = BYBAND.gCombine_kDist(kFile, iBand, DOLW, 1, \n",
    "        fullBandKDir=BANDSPLITDIR, \n",
    "        fullBandFluxDir=FULLBANDFLUXDIR)\n",
    "    kObj.gPointCombine()\n",
    "    kBandDict['band{:02d}'.format(band)] = kObj\n",
    "\n",
    "    print('Band {} complete'.format(band))\n",
    "# end kFile loop\n",
    "\n",
    "import pickle\n",
    "with open(KPICKLE, 'wb') as fp: pickle.dump(kBandDict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute fluxes in parallel for every _g_-point combination -- merging occurs in each band, and these combinations in a given band are used with broadband fluxes from other bands. These concatenations each have an associated `xarray` dataset assigned to it. Cost function components are then calculated based for each dataset, and the one that minimizes the error in the cost function will have its associated netCDF saved to disk.\n",
    "\n",
    "Uncomment pickling block to restore dictionary from previous cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction and Optimization\n",
    "\n",
    "Test and reference netCDF files have flux and heating rate arrays of dimension `record` x `col` x `lay`/`lev` and `band` if the array is broken down by band. `record` represents atmospheric specifications that can be used in [forcing scenarios](https://github.com/pernak18/g-point-reduction/wiki/LW-Forcing-Number-Convention#g-point-reduction-convention-).\n",
    "\n",
    "Alternatively, the atmospheric specifications from any scenario can also be used. \"Bare\" parameters like `heating_rate` and `flux_net` will be treated as PD specifications, so the user will have to specify explicitly if they want the fluxes or heating rates from other scenarios by using the `flux_*_N` and `heating_rate_N` convention, where `N` is the scenario index as listed in the above list. The same convention applies to band fluxes and HRs. `N` = 0 will work just like `heating_rate` and `flux_net`.\n",
    "\n",
    "Forcing for this exercise is defined as PI subtracted from scenario (2-6). The convention for these quantities is `*_forcing_N`, where `*` is the typical flux or heating rate (band or broadband) string, and `N` again is the forcing scenario (`N` of 2 would be forcing due to doubling methane)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring LW_cost-optimize.pickle\n",
      "Iteration 149\n",
      "band03_coefficients_LW_g08-09_iter149.nc, Trial: 29, Cost: 214.952548, Delta-Cost: 8.6163\n",
      "\tflux_net, band_flux_net, heating_rate, heating_rate_7, flux_net_forcing_5, flux_net_forcing_6, flux_net_forcing_7, flux_net_forcing_9, flux_net_forcing_10, flux_net_forcing_11, flux_net_forcing_12, flux_net_forcing_13, flux_net_forcing_14, flux_net_forcing_15, flux_net_forcing_16, flux_net_forcing_17, flux_net_forcing_18 = 214.4308, 97.6706, 375.8930, 194.1914, 106.4553, 94.3048, 156.5859, 103.6859, 71.0538, 94.4397, 52.7584, 105.2136, 97.8608, 109.2890, 115.1773, 103.2599, 99.8609\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arguments without labels along dimension 'trial' cannot be aligned because they have different dimension sizes: {91, 92}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b8ae13b2c9e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mcoObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindOptimal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcoObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimized\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mDIAGNOSTICS\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcoObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcostDiagnostics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mcoObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetupNextIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleCost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoObj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/u1/p/pernak18/RRTMGP/g-point-reduction/by_band_lib.py\u001b[0m in \u001b[0;36mcostDiagnostics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutDS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m         \u001b[0moutDS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trial_total_cost'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mxa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotalCost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/cori/3.7-anaconda-2019.10/lib/python3.7/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1290\u001b[0m             )\n\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/cori/3.7-anaconda-2019.10/lib/python3.7/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, other, inplace)\u001b[0m\n\u001b[1;32m   3636\u001b[0m         \"\"\"\n\u001b[1;32m   3637\u001b[0m         \u001b[0m_check_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3638\u001b[0;31m         \u001b[0mmerge_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_update_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3639\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmerge_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/cori/3.7-anaconda-2019.10/lib/python3.7/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mdataset_update_method\u001b[0;34m(dataset, other)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \u001b[0mpriority_arg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mcombine_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"override\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m     )\n",
      "\u001b[0;32m~/.local/cori/3.7-anaconda-2019.10/lib/python3.7/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mmerge_core\u001b[0;34m(objects, compat, join, combine_attrs, priority_arg, explicit_coords, indexes, fill_value)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[0mcoerced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoerce_pandas_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m     aligned = deep_align(\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0mcoerced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m     )\n\u001b[1;32m    594\u001b[0m     \u001b[0mcollected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_variables_and_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maligned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/cori/3.7-anaconda-2019.10/lib/python3.7/site-packages/xarray/core/alignment.py\u001b[0m in \u001b[0;36mdeep_align\u001b[0;34m(objects, join, copy, indexes, exclude, raise_on_invalid, fill_value)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m     )\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/cori/3.7-anaconda-2019.10/lib/python3.7/site-packages/xarray/core/alignment.py\u001b[0m in \u001b[0;36malign\u001b[0;34m(join, copy, indexes, exclude, fill_value, *objects)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0;34m\"arguments without labels along dimension %r cannot be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0;34m\"aligned because they have different dimension sizes: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                     \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m                 )\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arguments without labels along dimension 'trial' cannot be aligned because they have different dimension sizes: {91, 92}"
     ]
    }
   ],
   "source": [
    "# pickling for developement purposes so this dictionary doesn't need \n",
    "# to be regenerated for every code change.\n",
    "import pickle\n",
    "with open(KPICKLE, 'rb') as fp: kBandDict = pickle.load(fp)\n",
    "\n",
    "# components used in cost function computation\n",
    "# variable names in RRTMGP and LBL flux netCDF file, except for \n",
    "# forcing, which has to be specifed with \"_forcing\" appended to \n",
    "# the appropriate array. e.g., \"flux_net_forcing\" for net flux forcing\n",
    "# netCDF arrays ('heating_rate', 'flux_net', 'band_flux_net', etc.)\n",
    "# or forcing scenarios: convention is  ('flux_net_forcing_3') for \n",
    "CFCOMPS = ['flux_dif_net', 'flux_dir_dn', 'heating_rate']\n",
    "CFCOMPS = ['flux_net', 'band_flux_net', 'heating_rate',\n",
    "  'heating_rate_7', 'flux_net_forcing_5', 'flux_net_forcing_6',\n",
    "  'flux_net_forcing_7', 'flux_net_forcing_9', 'flux_net_forcing_10',\n",
    "  'flux_net_forcing_11', 'flux_net_forcing_12', 'flux_net_forcing_13',\n",
    "  'flux_net_forcing_14', 'flux_net_forcing_15', 'flux_net_forcing_16',\n",
    "  'flux_net_forcing_17', 'flux_net_forcing_18']\n",
    "\n",
    "# level indices for each component \n",
    "# (e.g., 0 for surface, 41 for Garand TOA)\n",
    "# one dictionary key per component so each component\n",
    "# can have its own set of level indices\n",
    "CFLEVS = {}\n",
    "LEVELS = {}\n",
    "LEVELS['flux_net'] = [0, 26, 42]\n",
    "LEVELS['band_flux_net'] = [42]\n",
    "LEVELS['heating_rate'] = range(42)\n",
    "LEVELS['heating_rate_7'] = range(42)\n",
    "LEVELS['flux_net_forcing_5'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_6'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_7'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_9'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_10'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_11'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_12'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_13'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_14'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_15'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_16'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_17'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_18'] = [0, 26, 42]\n",
    "CFLEVS = dict(LEVELS)\n",
    "\n",
    "# weights for each cost function component\n",
    "CFWGT = [0.6, 0.04, 0.12, 0.12, 0.01, 0.02, 0.04, 0.005,\n",
    "        0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005,\n",
    "        0.005]\n",
    "\n",
    "# directory under which to store k-distribution files that optimize \n",
    "# the cost function for each iteration and diagnistics (if necessary)\n",
    "CFDIR = 'xsecs-test'\n",
    "BYBAND.pathCheck(CFDIR, mkdir=True)\n",
    "\n",
    "# write diagnostic netCDFs with cost function components\n",
    "DIAGNOSTICS = True\n",
    "\n",
    "RESTORE = True\n",
    "\n",
    "if RESTORE:\n",
    "    assert os.path.exists(pickleCost), 'Cannot find {}'.format(pickleCost)\n",
    "    print('Restoring {}'.format(pickleCost))\n",
    "    with open(pickleCost, 'rb') as fp: coObj = pickle.load(fp)\n",
    "else:\n",
    "    # instantiate object for computing cost\n",
    "    coObj = BYBAND.gCombine_Cost(\n",
    "        kBandDict, fullBandFluxes, REFNC, TESTNC, 1, \n",
    "        DOLW, profilesNC=GARAND, exeRRTMGP=EXE, \n",
    "        costFuncComp=CFCOMPS, costFuncLevs=CFLEVS, \n",
    "        costWeights=CFWGT, optDir='./{}'.format(CFDIR))\n",
    "# endif RESTORE\n",
    "\n",
    "# number of iterations for the optimization\n",
    "NITER = 149\n",
    "\n",
    "for i in range(coObj.iCombine, NITER+1):\n",
    "    wgtInfo = ['{:.2f} ({})'.format(\n",
    "        wgt, comp) for wgt, comp in zip(CFWGT, CFCOMPS)]\n",
    "    wgtInfo = ' '.join(wgtInfo)\n",
    "\n",
    "    print('Iteration {}'.format(i))\n",
    "    coObj.kMap()\n",
    "    coObj.fluxComputePool()\n",
    "    coObj.fluxCombine()\n",
    "    coObj.costFuncComp(init=True)\n",
    "    coObj.costFuncComp()\n",
    "    coObj.findOptimal()\n",
    "    if coObj.optimized: break\n",
    "    if DIAGNOSTICS: coObj.costDiagnostics()\n",
    "    coObj.setupNextIter()\n",
    "    with open(pickleCost, 'wb') as fp: pickle.dump(coObj, fp)\n",
    "    coObj.calcOptFlux(\n",
    "        fluxOutNC='optimized_{}_fluxes_iter{:03d}.nc'.format(DOMAIN, i))\n",
    "# end iteration loop\n",
    "\n",
    "KOUTNC = 'rrtmgp-data-{}-g-red.nc'.format(DOMAIN)\n",
    "coObj.kDistOpt(KFULLNC, kOutNC=KOUTNC)\n",
    "coObj.calcOptFlux(fluxOutNC='optimized_{}_fluxes.nc'.format(DOMAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
