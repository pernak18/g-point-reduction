{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By-Band _g_-Point Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "\n",
    "`numpy` is installed in the Python environment at NERSC (`module load python`), but `xarray` is not, so the user must install the package on their own. `PIPPATH` is the assumed location. This notebook depends heavily on `xarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil, glob\n",
    "\n",
    "# \"standard\" install\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# directory in which libraries installed with conda are saved\n",
    "PIPPATH = '{}/.local/'.format(os.path.expanduser('~')) + \\\n",
    "    'cori/3.7-anaconda-2019.10/lib/python3.7/site-packages'\n",
    "# PIPPATH = '/global/homes/e/emlawer/.local/cori/3.8-anaconda-2020.11/' + \\\n",
    "#      'lib/python3.8/site-packages'\n",
    "PATHS = ['common', PIPPATH]\n",
    "for path in PATHS: sys.path.append(path)\n",
    "\n",
    "# needed at AER unless i update `pandas`\n",
    "import warnings\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# user must do `pip install xarray` on cori (or other NERSC machines)\n",
    "import xarray as xa\n",
    "\n",
    "# local modules\n",
    "import g_point_reduction as REDUX\n",
    "import flux_cost_compute as FCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only do one domain or the other\n",
    "DOLW = True\n",
    "DOMAIN = 'LW' if DOLW else 'SW'\n",
    "NBANDS = 16 if DOLW else 14\n",
    "\n",
    "# does band-splitting need to be done, or are there existing files \n",
    "# that have divided up the full k-distribution?\n",
    "BANDSPLIT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = '/global/project/projectdirs/e3sm/pernak18/'\n",
    "EXE = '{}/g-point-reduction/garand_atmos/rrtmgp_garand_atmos'.format(\n",
    "    PROJECT)\n",
    "REFDIR = '{}/reference_netCDF/g-point-reduce'.format(PROJECT)\n",
    "\n",
    "# test (RRTMGP) and reference (LBL) flux netCDF files, full k-distributions, \n",
    "# and by-band Garand input file\n",
    "fluxSuffix = 'flux-inputs-outputs-garandANDpreind.nc'\n",
    "if DOLW:\n",
    "    GARAND = '{}/multi_garand_template_single_band.nc'.format(REFDIR)\n",
    "    KFULLNC = '{}/rrtmgp-data-lw-g256-2018-12-04.nc'.format(REFDIR)\n",
    "    KFULLNC = '{}/rrtmgp-data-lw-g256-jen-xs.nc'.format(REFDIR)\n",
    "    REFNC = '{}/lblrtm-lw-{}'.format(REFDIR, fluxSuffix)\n",
    "    TESTNC = '{}/rrtmgp-lw-{}'.format(REFDIR, fluxSuffix)\n",
    "    #TESTNC = 'rrtmgp-lw-flux-inputs-outputs-garand-all.nc'\n",
    "else:\n",
    "    GARAND = '{}/charts_multi_garand_template_single_band.nc'.format(REFDIR)\n",
    "    KFULLNC = '{}/rrtmgp-data-sw-g224-2018-12-04.nc'.format(REFDIR)\n",
    "    REFNC = '{}/charts-sw-{}'.format(REFDIR, fluxSuffix)\n",
    "    TESTNC = '{}/rrtmgp-sw-{}'.format(REFDIR, fluxSuffix)\n",
    "# endif LW\n",
    "\n",
    "BANDSPLITDIR = 'band_k_dist'\n",
    "FULLBANDFLUXDIR = 'full_band_flux'\n",
    "\n",
    "for PATH in PATHS: FCC.pathCheck(PATH)\n",
    "\n",
    "CWD = os.getcwd()\n",
    "\n",
    "KPICKLE = '{}_k-dist.pickle'.format(DOMAIN)\n",
    "pickleCost = '{}_cost-optimize.pickle'.format(DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Band Splitting\n",
    "\n",
    "Break up full _k_-distribution file into separate distributions for each band, then calculate the corresponding fluxes. This should only need to be run once.\n",
    "\n",
    "After some clarifications from Robert (30-Nov-2020), I believe the plan of action is:\n",
    "\n",
    "1. create Nbands k-distribution files\n",
    "2. drive the Fortran executable Nbands times to produce Nbands flux results\n",
    "3. the trial g-point combinations then loop over bands and the possible g-point combinations within each band, creating k-distribution and band-wise flux files for each possible combination\n",
    "4. The Python code assembles broadband fluxes from the band-wise flux files in order to compute the cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BANDSPLIT:\n",
    "    print('Band splitting commenced')\n",
    "    FCC.pathCheck(BANDSPLITDIR, mkdir=True)\n",
    "    FCC.pathCheck(FULLBANDFLUXDIR, mkdir=True)\n",
    "    kFiles, fullBandFluxes = [], []\n",
    "    for iBand in tqdm(range(NBANDS)):\n",
    "        # divide full k-distribution into subsets for each band\n",
    "        kObj = REDUX.gCombine_kDist(KFULLNC, iBand, DOLW, 1, \n",
    "            fullBandKDir=BANDSPLITDIR, fullBandFluxDir=FULLBANDFLUXDIR, \n",
    "            profilesNC=GARAND)\n",
    "        kFiles.append(kObj.kBandNC)\n",
    "        kObj.kDistBand()\n",
    "\n",
    "        # quick, non-parallelized flux calculations (because the \n",
    "        # executable is run in one directory)\n",
    "        FCC.fluxCompute(kObj.kBandNC, kObj.profiles, kObj.exe, \n",
    "                           kObj.fullBandFluxDir, kObj.fluxBandNC)\n",
    "        fullBandFluxes.append(kObj.fluxBandNC)\n",
    "    # end band loop\n",
    "    print('Band splitting completed')\n",
    "else:\n",
    "    kFiles = sorted(glob.glob('{}/coefficients_{}_band??.nc'.format(\n",
    "        BANDSPLITDIR, DOMAIN)))\n",
    "    fullBandFluxes = sorted(glob.glob('{}/flux_{}_band??.nc'.format(\n",
    "        FULLBANDFLUXDIR, DOMAIN)))\n",
    "\n",
    "    if len(kFiles) == 0 or len(fullBandFluxes) == 0:\n",
    "        print('WARNING: set `BANDSPLIT` to `True` and run this cell again')\n",
    "# endif BANDSPLIT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pressure Levels for Cost Function\n",
    "\n",
    "Pressure levels [Pa] for the Garand atmospheres are printed to standard output with indices that can be used in the cost function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xa.open_dataset(REFNC) as refDS:\n",
    "    pLev = refDS['p_lev'].isel(record=0)\n",
    "for iLev, pLev in enumerate(pLev.isel(col=0).values): print(iLev, pLev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _g_-Point Combining\n",
    "\n",
    "Combine _g_-point reduced for bands with full-band fluxes from other bands, find optimal _g_-point combination for given iteration, proceed to next iteration.\n",
    "\n",
    "First, find all _g_-point combinations for each band. Store the band object in a dictionary for use in flux computation. This cell only needs to be run once, and to save time in development, the dictionary is saved in a `pickle` file and can be loaded in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should be parallelized; also is part of preprocessing so we \n",
    "# shouldn't have to run it multiple times\n",
    "kBandDict = {}\n",
    "for iBand, kFile in tqdm(enumerate(kFiles)):\n",
    "    #if iBand != 0: continue\n",
    "    band = iBand + 1\n",
    "    kObj = REDUX.gCombine_kDist(kFile, iBand, DOLW, 1, \n",
    "        fullBandKDir=BANDSPLITDIR, \n",
    "        fullBandFluxDir=FULLBANDFLUXDIR)\n",
    "    kObj.gPointCombine()\n",
    "    kBandDict['band{:02d}'.format(band)] = kObj\n",
    "\n",
    "    print('Band {} complete'.format(band))\n",
    "# end kFile loop\n",
    "\n",
    "import pickle\n",
    "with open(KPICKLE, 'wb') as fp: pickle.dump(kBandDict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute fluxes in parallel for every _g_-point combination -- merging occurs in each band, and these combinations in a given band are used with broadband fluxes from other bands. These concatenations each have an associated `xarray` dataset assigned to it. Cost function components are then calculated based for each dataset, and the one that minimizes the error in the cost function will have its associated netCDF saved to disk.\n",
    "\n",
    "Uncomment pickling block to restore dictionary from previous cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction and Optimization\n",
    "\n",
    "Test and reference netCDF files have flux and heating rate arrays of dimension `record` x `col` x `lay`/`lev` and `band` if the array is broken down by band. `record` represents atmospheric specifications that can be used in [forcing scenarios](https://github.com/pernak18/g-point-reduction/wiki/LW-Forcing-Number-Convention#g-point-reduction-convention-).\n",
    "\n",
    "Alternatively, the atmospheric specifications from any scenario can also be used. \"Bare\" parameters like `heating_rate` and `flux_net` will be treated as PD specifications, so the user will have to specify explicitly if they want the fluxes or heating rates from other scenarios by using the `flux_*_N` and `heating_rate_N` convention, where `N` is the scenario index as listed in the above list. The same convention applies to band fluxes and HRs. `N` = 0 will work just like `heating_rate` and `flux_net`.\n",
    "\n",
    "Forcing for this exercise is defined as PI subtracted from scenario (2-6). The convention for these quantities is `*_forcing_N`, where `*` is the typical flux or heating rate (band or broadband) string, and `N` again is the forcing scenario (`N` of 2 would be forcing due to doubling methane)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling for developement purposes so this dictionary doesn't need \n",
    "# to be regenerated for every code change.\n",
    "import pathlib as PL\n",
    "import copy\n",
    "import pickle\n",
    "with open(KPICKLE, 'rb') as fp: kBandDict = pickle.load(fp)\n",
    "\n",
    "# components used in cost function computation\n",
    "# variable names in RRTMGP and LBL flux netCDF file, except for \n",
    "# forcing, which has to be specifed with \"_forcing\" appended to \n",
    "# the appropriate array. e.g., \"flux_net_forcing\" for net flux forcing\n",
    "# netCDF arrays ('heating_rate', 'flux_net', 'band_flux_net', etc.)\n",
    "# or forcing scenarios: convention is  ('flux_net_forcing_3') for \n",
    "#CFCOMPS = ['flux_dif_net', 'flux_dir_dn', 'heating_rate']\n",
    "CFCOMPS = ['flux_net','band_flux_net','heating_rate','heating_rate_7',\n",
    "           'flux_net_forcing_5','flux_net_forcing_6','flux_net_forcing_7',\n",
    "           'flux_net_forcing_9','flux_net_forcing_10','flux_net_forcing_11',\n",
    "           'flux_net_forcing_12','flux_net_forcing_13','flux_net_forcing_14',\n",
    "           'flux_net_forcing_15','flux_net_forcing_16','flux_net_forcing_17',\n",
    "           'flux_net_forcing_18']\n",
    "# level indices for each component \n",
    "# (e.g., 0 for surface, 41 for Garand TOA)\n",
    "# one dictionary key per component so each component\n",
    "# can have its own set of level indices\n",
    "CFLEVS = {}\n",
    "CFLEVS['flux_net'] = [0, 26, 42]\n",
    "CFLEVS['band_flux_net'] = [42]\n",
    "CFLEVS['heating_rate'] = range(42)\n",
    "CFLEVS['heating_rate_7'] = range(42)\n",
    "CFLEVS['flux_net_forcing_5'] = [0, 26, 42]\n",
    "CFLEVS['flux_net_forcing_6'] = [0, 26, 42]\n",
    "CFLEVS['flux_net_forcing_7'] = [0, 26, 42]\n",
    "CFLEVS['flux_net_forcing_9'] = [0, 26, 42]\n",
    "CFLEVS['flux_net_forcing_10'] = [0, 26, 42]\n",
    "CFLEVS['flux_net_forcing_11'] = [0, 26, 42]\n",
    "CFLEVS['flux_net_forcing_12'] = [0, 26, 42]\n",
    "CFLEVS['flux_net_forcing_13'] = [0, 26, 42]\n",
    "CFLEVS['flux_net_forcing_14'] = [0, 26, 42]\n",
    "CFLEVS['flux_net_forcing_15'] = [0, 26, 42]\n",
    "CFLEVS['flux_net_forcing_16'] = [0, 26, 42]\n",
    "CFLEVS['flux_net_forcing_17'] = [0, 26, 42]\n",
    "CFLEVS['flux_net_forcing_18'] = [0, 26, 42]\n",
    "\n",
    "# weights for each cost function component\n",
    "CFWGT = [0.6, 0.04, 0.12, 0.12,\n",
    "         0.01, 0.02, 0.04,\n",
    "        0.005, 0.005, 0.005,\n",
    "        0.005, 0.005, 0.005, \n",
    "        0.005, 0.005, 0.005,\n",
    "        0.005]\n",
    "\n",
    "# directory under which to store k-distribution files that optimize \n",
    "# the cost function for each iteration and diagnistics (if necessary)\n",
    "CFDIR = 'fullCF_top-layer_redo_abs_parabola'\n",
    "FCC.pathCheck(CFDIR, mkdir=True)\n",
    "\n",
    "# write diagnostic netCDFs with cost function components\n",
    "DIAGNOSTICS = True\n",
    "\n",
    "RESTORE = False\n",
    "\n",
    "if RESTORE:\n",
    "    assert os.path.exists(pickleCost), 'Cannot find {}'.format(pickleCost)\n",
    "    print('Restoring {}'.format(pickleCost))\n",
    "    with open(pickleCost, 'rb') as fp: coObj = pickle.load(fp)\n",
    "else:\n",
    "    # instantiate object for computing cost\n",
    "    coObj = REDUX.gCombine_Cost(\n",
    "        kBandDict, fullBandFluxes, REFNC, TESTNC, 1, \n",
    "        DOLW, profilesNC=GARAND, exeRRTMGP=EXE, \n",
    "        costFuncComp=CFCOMPS, costFuncLevs=CFLEVS, \n",
    "        costWeights=CFWGT, optDir='./{}'.format(CFDIR))\n",
    "# endif RESTORE\n",
    "\n",
    "# number of iterations for the optimization\n",
    "NITER = 1\n",
    "\n",
    "for i in range(coObj.iCombine, NITER+1):\n",
    "    wgtInfo = ['{:.2f} ({})'.format(\n",
    "        wgt, comp) for wgt, comp in zip(CFWGT, CFCOMPS)]\n",
    "    wgtInfo = ' '.join(wgtInfo)\n",
    "\n",
    "    print('Iteration {}'.format(i))\n",
    "    coObj.kMap()\n",
    "    coObj.fluxComputePool()\n",
    "    coObj.fluxCombine()\n",
    "    coObj.costFuncComp(init=True)\n",
    "    coObj.costFuncComp()\n",
    "    coObj.findOptimal()\n",
    "    if coObj.optimized: break\n",
    "    if DIAGNOSTICS: coObj.costDiagnostics()\n",
    "\n",
    "    # Karen's additions to `flux_compute.py` for parabola\n",
    "\n",
    "    import copy\n",
    "\n",
    " # Start of special g-point combination branch\n",
    "    if coObj.dCost[coObj.iOpt]-coObj.deltaCost0 > 0.1:\n",
    "    #if coObj.dCost[coObj.iOpt]-coObj.deltaCost0 > -2.01:\n",
    "       print ('will change here')\n",
    "       xWeight = 0.05\n",
    "       delta0 = coObj.dCost[coObj.iOpt]-coObj.deltaCost0\n",
    "       bandObj = coObj.distBands\n",
    "       if (coObj.optBand+1) < 10:\n",
    "           bandKey='band0{}'.format(coObj.optBand+1)\n",
    "       else:\n",
    "           bandKey='band{}'.format(coObj.optBand+1)\n",
    "       #sys.exit() \n",
    "        \n",
    "       newObj = REDUX.gCombine_kDist(bandObj[bandKey].kInNC, coObj.optBand, DOLW,\n",
    "            i, fullBandKDir=BANDSPLITDIR,\n",
    "            fullBandFluxDir=FULLBANDFLUXDIR)\n",
    "       curkFile = os.path.basename(coObj.optNC)\n",
    "       ind = curkFile.find('_g')\n",
    "       g1 = int(curkFile[ind+2:ind+4])\n",
    "       g2 = int(curkFile[ind+5:ind+7])\n",
    "       gCombine =[[g1-1,g2-1]]\n",
    "\n",
    "       #print (newObj.workDir)\n",
    "       ind = curkFile.find('coeff')\n",
    "       #print (curkFile)\n",
    "       fluxPath = PL.Path(curkFile[ind:]).with_suffix('')\n",
    "       fluxDir = '{}/{}'.format(newObj.workDir,fluxPath)\n",
    "\n",
    "       parr =['plus','2plus']\n",
    "       for pmFlag in parr:\n",
    "           coCopy = copy.deepcopy(coObj)\n",
    "           #print (\"  \")\n",
    "           print (pmFlag)\n",
    "           newObj.gPointCombineSglPair(pmFlag,gCombine,xWeight)\n",
    "           newCoefFile = '{}/{}_{}.nc'.format(newObj.workDir,fluxPath,pmFlag)\n",
    "           fluxFile = os.path.basename(newCoefFile).replace('coefficients', 'flux')\n",
    "           #print (fluxFile)\n",
    "           #print (newCoefFile)\n",
    "           FCC.fluxCompute(newCoefFile,GARAND,EXE,fluxDir,fluxFile)\n",
    "\n",
    "           trialNC = '{}/{}'.format(fluxDir,fluxFile)\n",
    "           coCopy.combinedNC[coObj.iOpt] = combineBandsSgl( \n",
    "                   coObj.optBand, coObj.fullBandFluxes,trialNC,DOLW)\n",
    "           coCopy.costFuncCompSgl(coCopy.combinedNC[coObj.iOpt])\n",
    "           #coCopy.findOptimal()\n",
    "        \n",
    "           if DIAGNOSTICS: coCopy.costDiagnostics()\n",
    "           if(pmFlag == '2plus'):\n",
    "               delta2Plus = coCopy.dCost[coObj.iOpt]-coCopy.deltaCost0\n",
    "           if(pmFlag == 'plus'):\n",
    "               deltaPlus = coCopy.dCost[coObj.iOpt]-coCopy.deltaCost0\n",
    "\n",
    "# Fit change in cost of three g-point options to a parabola and find minimum weight if parabola is concave;\n",
    "#  if that weight is outside the (-0.1,0.1) range or the parabola is convex use the weight that leads to \n",
    "# the smallest increase or largest decrease in the  cost function;\n",
    "\n",
    "       #print (\"  \")\n",
    "       print (\"New weight calculation\")\n",
    "       #xArr = [-xWeight,0.,xWeight]\n",
    "       xArr = [0.,xWeight,2.*xWeight]\n",
    "       #yArr = [deltaMinus,delta0,deltaPlus]\n",
    "       yArr = [delta0,deltaPlus,delta2Plus]\n",
    "       print (yArr)\n",
    "       ymin = min(yArr)\n",
    "       imin = yArr.index(ymin)\n",
    "       coeff = np.polyfit(xArr,yArr,2)\n",
    "       #print (coeff[0])\n",
    "       xMin = -coeff[1]/(2.*coeff[0])\n",
    "       if (yArr[imin] < 0):\n",
    "          xWeightNew = xArr[imin] - xArr[imin] * yArr[imin] / (yArr[imin]-yArr[0])\n",
    "       else:       \n",
    "          if (coeff[0] >0.):\n",
    "             print (\"concave parabola \",xMin)\n",
    "             if (xMin < -xWeight or xMin > xWeight):\n",
    "                xWeightNew = xArr[imin]\n",
    "             else:\n",
    "                xWeightNew = xMin\n",
    "          else:\n",
    "             xWeightNew = xArr[imin]\n",
    "       print (xWeightNew)\n",
    "\n",
    "# Define newest g-point combination\n",
    "       coCopy = copy.deepcopy(coObj)\n",
    "       pmFlag = 'mod'\n",
    "       #print (\"  \")\n",
    "       print (pmFlag)\n",
    "       newObj.gPointCombineSglPair(pmFlag,gCombine,xWeightNew)\n",
    "       newCoefFile = '{}/{}_{}.nc'.format(newObj.workDir,fluxPath,pmFlag)\n",
    "       fluxFile = os.path.basename(newCoefFile).replace('coefficients', 'flux')\n",
    "       #print (newCoefFile)\n",
    "       print (newCoefFile,file=open('new_weight_diag.txt','a'))\n",
    "       print (coeff[0],xMin,yArr,xWeightNew,file=open('new_weight_diag.txt','a'))\n",
    "       print (\"  \",file=open('new_weight_diag.txt','a'))\n",
    "       FCC.fluxCompute(newCoefFile,GARAND,EXE,fluxDir,fluxFile)\n",
    "\n",
    "       trialNC = '{}/{}'.format(fluxDir,fluxFile)\n",
    "       coCopy.combinedNC[coObj.iOpt] = combineBandsSgl( \n",
    "               coObj.optBand, coObj.fullBandFluxes,trialNC,DOLW,)\n",
    "       coCopy.costFuncCompSgl(coCopy.combinedNC[coObj.iOpt])\n",
    "       coCopy.fluxInputsAll[coObj.iOpt]['fluxNC'] = str(trialNC)\n",
    "       #coCopy.findOptimal()\n",
    "    \n",
    "       if DIAGNOSTICS: coCopy.costDiagnostics()\n",
    "       print (\"delta cost\")\n",
    "       print(coCopy.dCost[coObj.iOpt]-coCopy.deltaCost0)\n",
    "       coObj = copy.deepcopy(coCopy)\n",
    "       del coCopy\n",
    "# End of special g-point combination branch\n",
    "\n",
    "    # end of Karen's additions to `flux_compute.py` for parabola\n",
    "\n",
    "    coObj.setupNextIter()\n",
    "    with open(pickleCost, 'wb') as fp: pickle.dump(coObj, fp)\n",
    "    coObj.calcOptFlux(\n",
    "        fluxOutNC='optimized_{}_fluxes_iter{:03d}.nc'.format(DOMAIN, i))\n",
    "# end iteration loop\n",
    "\n",
    "KOUTNC = 'rrtmgp-data-{}-g-red.nc'.format(DOMAIN)\n",
    "coObj.kDistOpt(KFULLNC, kOutNC=KOUTNC)\n",
    "coObj.calcOptFlux(fluxOutNC='optimized_{}_fluxes.nc'.format(DOMAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
