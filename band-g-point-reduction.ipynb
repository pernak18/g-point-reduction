{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By-Band _g_-Point Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "\n",
    "`numpy` is installed in the Python environment at NERSC (`module load python`), but `xarray` is not, so the user must install the package on their own. `PIPPATH` is the assumed location. This notebook depends heavily on `xarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil, glob\n",
    "\n",
    "# \"standard\" install\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# directory in which libraries installed with conda are saved\n",
    "PIPPATH = '/global/homes/k/kcadyper/.local/lib/python3.8/site-packages/'\n",
    "# PIPPATH = '/global/homes/e/emlawer/.local/cori/3.8-anaconda-2020.11/' + \\\n",
    "#     'lib/python3.8/site-packages'\n",
    "PATHS = ['common', PIPPATH]\n",
    "for path in PATHS: sys.path.append(path)\n",
    "\n",
    "# needed at AER unless i update `pandas`\n",
    "import warnings\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# user must do `pip install xarray` on cori (or other NERSC machines)\n",
    "import xarray as xa\n",
    "\n",
    "# local module\n",
    "import by_band_lib as BYBAND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only do one domain or the other\n",
    "DOLW = True\n",
    "DOMAIN = 'LW' if DOLW else 'SW'\n",
    "NBANDS = 16 if DOLW else 14\n",
    "\n",
    "# does band-splitting need to be done, or are there existing files \n",
    "# that have divided up the full k-distribution?\n",
    "BANDSPLIT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = '/global/project/projectdirs/e3sm/pernak18/'\n",
    "EXE = '{}/g-point-reduction/garand_atmos/rrtmgp_garand_atmos'.format(\n",
    "    PROJECT)\n",
    "REFDIR = '{}/reference_netCDF/g-point-reduce'.format(PROJECT)\n",
    "\n",
    "# test (RRTMGP) and reference (LBL) flux netCDF files, full k-distributions, \n",
    "# and by-band Garand input file\n",
    "fluxSuffix = 'flux-inputs-outputs-garandANDpreind.nc'\n",
    "if DOLW:\n",
    "    GARAND = '{}/multi_garand_template_single_band.nc'.format(REFDIR)\n",
    "    KFULLNC = '{}/rrtmgp-data-lw-g256-2018-12-04.nc'.format(REFDIR)\n",
    "    KFULLNC = '{}/rrtmgp-data-lw-g256-jen-xs.nc'.format(REFDIR)\n",
    "    REFNC = '{}/lblrtm-lw-{}'.format(REFDIR, fluxSuffix)\n",
    "    TESTNC = '{}/rrtmgp-lw-{}'.format(REFDIR, fluxSuffix)\n",
    "    #TESTNC = 'rrtmgp-lw-flux-inputs-outputs-garand-all.nc'\n",
    "else:\n",
    "    GARAND = '{}/charts_multi_garand_template_single_band.nc'.format(REFDIR)\n",
    "    KFULLNC = '{}/rrtmgp-data-sw-g224-2018-12-04.nc'.format(REFDIR)\n",
    "    REFNC = '{}/charts-sw-{}'.format(REFDIR, fluxSuffix)\n",
    "    TESTNC = '{}/rrtmgp-sw-{}'.format(REFDIR, fluxSuffix)\n",
    "# endif LW\n",
    "\n",
    "BANDSPLITDIR = 'band_k_dist'\n",
    "FULLBANDFLUXDIR = 'full_band_flux'\n",
    "\n",
    "for PATH in PATHS: BYBAND.pathCheck(PATH)\n",
    "\n",
    "CWD = os.getcwd()\n",
    "\n",
    "KPICKLE = '{}_k-dist.pickle'.format(DOMAIN)\n",
    "pickleCost = '{}_cost-optimize.pickle'.format(DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Band Splitting\n",
    "\n",
    "Break up full _k_-distribution file into separate distributions for each band, then calculate the corresponding fluxes. This should only need to be run once.\n",
    "\n",
    "After some clarifications from Robert (30-Nov-2020), I believe the plan of action is:\n",
    "\n",
    "1. create Nbands k-distribution files\n",
    "2. drive the Fortran executable Nbands times to produce Nbands flux results\n",
    "3. the trial g-point combinations then loop over bands and the possible g-point combinations within each band, creating k-distribution and band-wise flux files for each possible combination\n",
    "4. The Python code assembles broadband fluxes from the band-wise flux files in order to compute the cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band splitting commenced\n",
      "Band splitting completed\n"
     ]
    }
   ],
   "source": [
    "if BANDSPLIT:\n",
    "    print('Band splitting commenced')\n",
    "    BYBAND.pathCheck(BANDSPLITDIR, mkdir=True)\n",
    "    BYBAND.pathCheck(FULLBANDFLUXDIR, mkdir=True)\n",
    "    kFiles, fullBandFluxes = [], []\n",
    "    for iBand in range(NBANDS):\n",
    "        # divide full k-distribution into subsets for each band\n",
    "        kObj = BYBAND.gCombine_kDist(KFULLNC, iBand, DOLW, 1, \n",
    "            fullBandKDir=BANDSPLITDIR, fullBandFluxDir=FULLBANDFLUXDIR, \n",
    "            profilesNC=GARAND)\n",
    "        kFiles.append(kObj.kBandNC)\n",
    "        kObj.kDistBand()\n",
    "\n",
    "        # quick, non-parallelized flux calculations (because the \n",
    "        # executable is run in one directory)\n",
    "        # TO DO: HAVEN'T TESTED THIS SINCE IT HAS BEEN MOVED OUT OF THE CLASS\n",
    "        BYBAND.fluxCompute(kObj.kBandNC, kObj.profiles, kObj.exe, \n",
    "                           kObj.fullBandFluxDir, kObj.fluxBandNC)\n",
    "        fullBandFluxes.append(kObj.fluxBandNC)\n",
    "    # end band loop\n",
    "    print('Band splitting completed')\n",
    "else:\n",
    "    kFiles = sorted(glob.glob('{}/coefficients_{}_band??.nc'.format(\n",
    "        BANDSPLITDIR, DOMAIN)))\n",
    "    fullBandFluxes = sorted(glob.glob('{}/flux_{}_band??.nc'.format(\n",
    "        FULLBANDFLUXDIR, DOMAIN)))\n",
    "\n",
    "    if len(kFiles) == 0 or len(fullBandFluxes) == 0:\n",
    "        print('WARNING: set `BANDSPLIT` to `True` and run this cell again')\n",
    "# endif BANDSPLIT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pressure Levels for Cost Function\n",
    "\n",
    "Pressure levels [Pa] for the Garand atmospheres are printed to standard output with indices that can be used in the cost function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with xa.open_dataset(REFNC) as refDS:\n",
    "    pLev = refDS['p_lev'].isel(record=0)\n",
    "for iLev, pLev in enumerate(pLev.isel(col=0).values): print(iLev, pLev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _g_-Point Combining\n",
    "\n",
    "Combine _g_-point reduced for bands with full-band fluxes from other bands, find optimal _g_-point combination for given iteration, proceed to next iteration.\n",
    "\n",
    "First, find all _g_-point combinations for each band. Store the band object in a dictionary for use in flux computation. This cell only needs to be run once, and to save time in development, the dictionary is saved in a `pickle` file and can be loaded in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band 1 complete\n",
      "Band 2 complete\n",
      "Band 3 complete\n",
      "Band 4 complete\n",
      "Band 5 complete\n",
      "Band 6 complete\n",
      "Band 7 complete\n",
      "Band 8 complete\n",
      "Band 9 complete\n",
      "Band 10 complete\n",
      "Band 11 complete\n",
      "Band 12 complete\n",
      "Band 13 complete\n",
      "Band 14 complete\n",
      "Band 15 complete\n",
      "Band 16 complete\n"
     ]
    }
   ],
   "source": [
    "# this should be parallelized; also is part of preprocessing so we \n",
    "# shouldn't have to run it multiple times\n",
    "kBandDict = {}\n",
    "for iBand, kFile in enumerate(kFiles):\n",
    "    #if iBand != 0: continue\n",
    "    band = iBand + 1\n",
    "    kObj = BYBAND.gCombine_kDist(kFile, iBand, DOLW, 1, \n",
    "        fullBandKDir=BANDSPLITDIR, \n",
    "        fullBandFluxDir=FULLBANDFLUXDIR)\n",
    "    kObj.gPointCombine()\n",
    "    kBandDict['band{:02d}'.format(band)] = kObj\n",
    "\n",
    "    print('Band {} complete'.format(band))\n",
    "# end kFile loop\n",
    "\n",
    "import pickle\n",
    "with open(KPICKLE, 'wb') as fp: pickle.dump(kBandDict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute fluxes in parallel for every _g_-point combination -- merging occurs in each band, and these combinations in a given band are used with broadband fluxes from other bands. These concatenations each have an associated `xarray` dataset assigned to it. Cost function components are then calculated based for each dataset, and the one that minimizes the error in the cost function will have its associated netCDF saved to disk.\n",
    "\n",
    "Uncomment pickling block to restore dictionary from previous cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction and Optimization\n",
    "\n",
    "Test and reference netCDF files have flux and heating rate arrays of dimension `record` x `col` x `lay`/`lev` and `band` if the array is broken down by band. `record` represents atmospheric specifications that can be used in [forcing scenarios](https://github.com/pernak18/g-point-reduction/wiki/LW-Forcing-Number-Convention#g-point-reduction-convention-).\n",
    "\n",
    "Alternatively, the atmospheric specifications from any scenario can also be used. \"Bare\" parameters like `heating_rate` and `flux_net` will be treated as PD specifications, so the user will have to specify explicitly if they want the fluxes or heating rates from other scenarios by using the `flux_*_N` and `heating_rate_N` convention, where `N` is the scenario index as listed in the above list. The same convention applies to band fluxes and HRs. `N` = 0 will work just like `heating_rate` and `flux_net`.\n",
    "\n",
    "Forcing for this exercise is defined as PI subtracted from scenario (2-6). The convention for these quantities is `*_forcing_N`, where `*` is the typical flux or heating rate (band or broadband) string, and `N` again is the forcing scenario (`N` of 2 would be forcing due to doubling methane)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling for developement purposes so this dictionary doesn't need \n",
    "# to be regenerated for every code change.\n",
    "import pickle\n",
    "with open(KPICKLE, 'rb') as fp: kBandDict = pickle.load(fp)\n",
    "\n",
    "# components used in cost function computation\n",
    "# variable names in RRTMGP and LBL flux netCDF file, except for \n",
    "# forcing, which has to be specifed with \"_forcing\" appended to \n",
    "# the appropriate array. e.g., \"flux_net_forcing\" for net flux forcing\n",
    "# netCDF arrays ('heating_rate', 'flux_net', 'band_flux_net', etc.)\n",
    "# or forcing scenarios: convention is  ('flux_net_forcing_3') for \n",
    "CFCOMPS = ['flux_dif_net', 'flux_dir_dn', 'heating_rate']\n",
    "CFCOMPS = ['flux_net', 'band_flux_net', 'heating_rate',\n",
    "  'heating_rate_7', 'flux_net_forcing_5', 'flux_net_forcing_6',\n",
    "  'flux_net_forcing_7', 'flux_net_forcing_9', 'flux_net_forcing_10',\n",
    "  'flux_net_forcing_11', 'flux_net_forcing_12', 'flux_net_forcing_13',\n",
    "  'flux_net_forcing_14', 'flux_net_forcing_15', 'flux_net_forcing_16',\n",
    "  'flux_net_forcing_17', 'flux_net_forcing_18']\n",
    "\n",
    "# level indices for each component \n",
    "# (e.g., 0 for surface, 41 for Garand TOA)\n",
    "# one dictionary key per component so each component\n",
    "# can have its own set of level indices\n",
    "CFLEVS = {}\n",
    "LEVELS = {}\n",
    "LEVELS['flux_net'] = [0, 26, 42]\n",
    "LEVELS['band_flux_net'] = [42]\n",
    "LEVELS['heating_rate'] = range(42)\n",
    "LEVELS['heating_rate_7'] = range(42)\n",
    "LEVELS['flux_net_forcing_5'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_6'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_7'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_9'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_10'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_11'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_12'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_13'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_14'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_15'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_16'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_17'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_18'] = [0, 26, 42]\n",
    "CFLEVS = dict(LEVELS)\n",
    "\n",
    "# weights for each cost function component\n",
    "CFWGT = [0.6, 0.04, 0.12, 0.12, 0.01, 0.02, 0.04, 0.005,\n",
    "        0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005,\n",
    "        0.005]\n",
    "\n",
    "# directory under which to store k-distribution files that optimize \n",
    "# the cost function for each iteration and diagnistics (if necessary)\n",
    "CFDIR = 'xsecs-test'\n",
    "BYBAND.pathCheck(CFDIR, mkdir=True)\n",
    "\n",
    "# write diagnostic netCDFs with cost function components\n",
    "DIAGNOSTICS = True\n",
    "\n",
    "RESTORE = True\n",
    "\n",
    "if RESTORE:\n",
    "    assert os.path.exists(pickleCost), 'Cannot find {}'.format(pickleCost)\n",
    "    print('Restoring {}'.format(pickleCost))\n",
    "    with open(pickleCost, 'rb') as fp: coObj = pickle.load(fp)\n",
    "else:\n",
    "    # instantiate object for computing cost\n",
    "    coObj = BYBAND.gCombine_Cost(\n",
    "        kBandDict, fullBandFluxes, REFNC, TESTNC, 1, \n",
    "        DOLW, profilesNC=GARAND, exeRRTMGP=EXE, \n",
    "        costFuncComp=CFCOMPS, costFuncLevs=CFLEVS, \n",
    "        costWeights=CFWGT, optDir='./{}'.format(CFDIR))\n",
    "# endif RESTORE\n",
    "\n",
    "# number of iterations for the optimization\n",
    "NITER = 149\n",
    "\n",
    "for i in range(coObj.iCombine, NITER+1):\n",
    "    wgtInfo = ['{:.2f} ({})'.format(\n",
    "        wgt, comp) for wgt, comp in zip(CFWGT, CFCOMPS)]\n",
    "    wgtInfo = ' '.join(wgtInfo)\n",
    "\n",
    "    print('Iteration {}'.format(i))\n",
    "    coObj.kMap()\n",
    "    coObj.fluxComputePool()\n",
    "    coObj.fluxCombine()\n",
    "    coObj.costFuncComp(init=True)\n",
    "    coObj.costFuncComp()\n",
    "    coObj.findOptimal()\n",
    "    if coObj.optimized: break\n",
    "    if DIAGNOSTICS: coObj.costDiagnostics()\n",
    "    coObj.setupNextIter()\n",
    "    with open(pickleCost, 'wb') as fp: pickle.dump(coObj, fp)\n",
    "    coObj.calcOptFlux(\n",
    "        fluxOutNC='optimized_{}_fluxes_iter{:03d}.nc'.format(DOMAIN, i))\n",
    "# end iteration loop\n",
    "\n",
    "KOUTNC = 'rrtmgp-data-{}-g-red.nc'.format(DOMAIN)\n",
    "coObj.kDistOpt(KFULLNC, kOutNC=KOUTNC)\n",
    "coObj.calcOptFlux(fluxOutNC='optimized_{}_fluxes.nc'.format(DOMAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "Iter = []\n",
    "CostMin = []\n",
    "ncfiles = glob.glob(\"xsecs-test/diagnostics/cost_components_iter*.nc\")\n",
    "ncfiles.sort\n",
    "\n",
    "for id in ncfiles:\n",
    "    ipos = id.find('iter')\n",
    "    Iter.append(id[ipos+4:ipos+7])\n",
    "    with xa.open_dataset(id) as ds:\n",
    "        cost= ds.trial_total_cost.values\n",
    "        CostMin.append(min(cost))\n",
    "    \n",
    "\n",
    "#print (\"here\")\n",
    "npIter = np.array(Iter)\n",
    "npCostMin = np.array(CostMin)\n",
    "iSort = np.argsort(npIter)\n",
    "npIter = npIter[iSort]\n",
    "npCostMin = npCostMin[iSort]\n",
    "  \n",
    "#for ip in range(len(Iter)):\n",
    " #   print (ip,npIter[ip],npCostMin[ip])\n",
    "    \n",
    "    \n",
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.set_ylim(80.,100.)\n",
    "ax.plot(npIter,npCostMin,marker='.')\n",
    "ax.set_xticks([0,20,40,60,80,100,120,140,160])\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Cost Function\")\n",
    "#plt.plot(npIter,npCostMin,marker='.')\n",
    "plt.show\n",
    "    \n",
    "fig2 = plt.figure()\n",
    "ax2=fig2.add_axes([0,0,1,1])\n",
    "len = npCostMin.shape\n",
    "\n",
    "diff = npCostMin[1:]-npCostMin[0:len[0]-1]\n",
    "ax2.plot(npIter[1:],diff,marker='.')\n",
    "ax2.set_xticks([0,20,40,60,80,100,120,140,160])\n",
    "ax2.set_xlabel(\"Iteration\")\n",
    "ax2.set_ylabel(\"Cost Function Delta\")\n",
    "\n",
    "zeroX = np.array([0.,len[0]])\n",
    "zeroY =np.array([0.,0.])\n",
    "ax2.plot(zeroX,zeroY,linestyle='dashed')\n",
    "#plt.plot(npIter,npCostMin,marker='.')\n",
    "plt.show\n",
    "\n",
    "for ip in range(len[0]-1):\n",
    "    print (ip,npIter[ip+1],diff[ip])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iter = []\n",
    "CostMin = []\n",
    "for id in glob.glob(\"xsecs-test/diagnostics/cost_components_iter*.nc\"):\n",
    "    ipos = id.find('iter')\n",
    "    Iter.append(id[ipos+4:ipos+7])\n",
    "    with xa.open_dataset(id) as ds:\n",
    "        cost= ds.trial_total_cost.values\n",
    "        CostMin.append(min(cost))\n",
    "\n",
    "\n",
    "for ip in Iter :\n",
    "    print(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring LW_cost-optimize.pickle\n"
     ]
    }
   ],
   "source": [
    "# pickling for developement purposes so this dictionary doesn't need \n",
    "# to be regenerated for every code change.\n",
    "import pickle\n",
    "with open(KPICKLE, 'rb') as fp: kBandDict = pickle.load(fp)\n",
    "\n",
    "# components used in cost function computation\n",
    "# variable names in RRTMGP and LBL flux netCDF file, except for \n",
    "# forcing, which has to be specifed with \"_forcing\" appended to \n",
    "# the appropriate array. e.g., \"flux_net_forcing\" for net flux forcing\n",
    "# netCDF arrays ('heating_rate', 'flux_net', 'band_flux_net', etc.)\n",
    "# or forcing scenarios: convention is  ('flux_net_forcing_3') for \n",
    "CFCOMPS = ['flux_dif_net', 'flux_dir_dn', 'heating_rate']\n",
    "CFCOMPS = ['flux_net', 'band_flux_net', 'heating_rate',\n",
    "  'heating_rate_7', 'flux_net_forcing_5', 'flux_net_forcing_6',\n",
    "  'flux_net_forcing_7', 'flux_net_forcing_9', 'flux_net_forcing_10',\n",
    "  'flux_net_forcing_11', 'flux_net_forcing_12', 'flux_net_forcing_13',\n",
    "  'flux_net_forcing_14', 'flux_net_forcing_15', 'flux_net_forcing_16',\n",
    "  'flux_net_forcing_17', 'flux_net_forcing_18']\n",
    "\n",
    "# level indices for each component \n",
    "# (e.g., 0 for surface, 41 for Garand TOA)\n",
    "# one dictionary key per component so each component\n",
    "# can have its own set of level indices\n",
    "CFLEVS = {}\n",
    "LEVELS = {}\n",
    "LEVELS['flux_net'] = [0, 26, 42]\n",
    "LEVELS['band_flux_net'] = [42]\n",
    "LEVELS['heating_rate'] = range(42)\n",
    "LEVELS['heating_rate_7'] = range(42)\n",
    "LEVELS['flux_net_forcing_5'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_6'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_7'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_9'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_10'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_11'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_12'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_13'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_14'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_15'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_16'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_17'] = [0, 26, 42]\n",
    "LEVELS['flux_net_forcing_18'] = [0, 26, 42]\n",
    "CFLEVS = dict(LEVELS)\n",
    "\n",
    "# weights for each cost function component\n",
    "CFWGT = [0.6, 0.04, 0.12, 0.12, 0.01, 0.02, 0.04, 0.005,\n",
    "        0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005,\n",
    "        0.005]\n",
    "\n",
    "# directory under which to store k-distribution files that optimize \n",
    "# the cost function for each iteration and diagnistics (if necessary)\n",
    "CFDIR = 'xsecs-test'\n",
    "BYBAND.pathCheck(CFDIR, mkdir=True)\n",
    "\n",
    "# write diagnostic netCDFs with cost function components\n",
    "DIAGNOSTICS = True\n",
    "\n",
    "RESTORE = True\n",
    "\n",
    "if RESTORE:\n",
    "    assert os.path.exists(pickleCost), 'Cannot find {}'.format(pickleCost)\n",
    "    print('Restoring {}'.format(pickleCost))\n",
    "    with open(pickleCost, 'rb') as fp: coObj = pickle.load(fp)\n",
    "else:\n",
    "    # instantiate object for computing cost\n",
    "    coObj = BYBAND.gCombine_Cost(\n",
    "        kBandDict, fullBandFluxes, REFNC, TESTNC, 1, \n",
    "        DOLW, profilesNC=GARAND, exeRRTMGP=EXE, \n",
    "        costFuncComp=CFCOMPS, costFuncLevs=CFLEVS, \n",
    "        costWeights=CFWGT, optDir='./{}'.format(CFDIR))\n",
    "# endif RESTORE\n",
    "\n",
    "# number of iterations for the optimization\n",
    "NITER = 100\n",
    "\n",
    "for i in range(coObj.iCombine, NITER+1):\n",
    "    wgtInfo = ['{:.2f} ({})'.format(\n",
    "        wgt, comp) for wgt, comp in zip(CFWGT, CFCOMPS)]\n",
    "    wgtInfo = ' '.join(wgtInfo)\n",
    "\n",
    "    print('Iteration {}'.format(i))\n",
    "    coObj.kMap()\n",
    "    coObj.fluxComputePool()\n",
    "    coObj.fluxCombine()\n",
    "    coObj.costFuncComp(init=True)\n",
    "    coObj.costFuncComp()\n",
    "    coObj.findOptimal()\n",
    "    print (coObj.dCost)\n",
    "    if (coObj.dcost > 0.1): \n",
    "        print (i,coObj.dcost)\n",
    "    if coObj.optimized: break\n",
    "    if DIAGNOSTICS: coObj.costDiagnostics()\n",
    "    coObj.setupNextIter()\n",
    "    with open(pickleCost, 'wb') as fp: pickle.dump(coObj, fp)\n",
    "    coObj.calcOptFlux(\n",
    "        fluxOutNC='optimized_{}_fluxes_iter{:03d}.nc'.format(DOMAIN, i))\n",
    "# end iteration loop\n",
    "\n",
    "KOUTNC = 'rrtmgp-data-{}-g-red.nc'.format(DOMAIN)\n",
    "coObj.kDistOpt(KFULLNC, kOutNC=KOUTNC)\n",
    "coObj.calcOptFlux(fluxOutNC='optimized_{}_fluxes.nc'.format(DOMAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
