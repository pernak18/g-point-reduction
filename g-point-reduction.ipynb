{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RRTMGP _g_-Point Reduction With Cost Function Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard modules\n",
    "import os, sys, shutil, subprocess, time, multiprocessing\n",
    "\n",
    "# pip installs\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "\n",
    "# local module paths\n",
    "HOME = '/global/homes/p/pernak18'\n",
    "GPTHOME = '{}/RRTMGP/g-point-reduction'.format(HOME)\n",
    "PINCUSPATH = '{}/pincus_k-distribution-opt'.format(GPTHOME)\n",
    "LIBPATHS = [PINCUSPATH, \n",
    "            '{}/k-distribution-opt'.format(GPTHOME), \n",
    "            '{}/.local/'.format(HOME) + \\\n",
    "            'cori/3.7-anaconda-2019.10/lib/python3.7/site-packages']\n",
    "for path in LIBPATHS: sys.path.append(path)\n",
    "\n",
    "# submodules from Robert Pincus/Ben Hillman\n",
    "# Menno also has functions with the same name\n",
    "# https://github.com/RobertPincus/k-distribution-opt/tree/brhillman/dev\n",
    "from combine_gpoints_fn import combine_gpoints_fn\n",
    "import cost_function as CF\n",
    "\n",
    "# https://github.com/MennoVeerman/k-distribution-opt\n",
    "#from prepare_cpp_input import prepare_input\n",
    "#import ref_values as RV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first cell of function definitions was, with the exception of `pathCheck`, extracted from [Menno's `optimizer.py`](https://github.com/MennoVeerman/k-distribution-opt/blob/master/optimizer.py) and slightly modified. Currently, these are not used because we are starting with Ben's code. However, once we start incorporating Menno's cost function flexibility and diagnostic plotting, we may need his functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathCheck(path):\n",
    "    \"\"\"\n",
    "    Determine if file exists. If not, throw an Assertion Exception\n",
    "    \"\"\"\n",
    "\n",
    "    assert os.path.exists(path), 'Could not find {}'.format(path)\n",
    "    \n",
    "def link_rrtmgp(rrtmgpPath=\"{}/rte-rrtmgp-cpp\".format(GPTHOME), \n",
    "                exe='./test_garand', \n",
    "                coeffSW='rrtmgp-data-sw-g224-2018-12-04.nc', \n",
    "                coeffLW='rrtmgp-data-lw-g256-2018-12-04.nc', \n",
    "                cloudSW='rrtmgp-cloud-optics-coeffs-sw.nc', \n",
    "                cloudLW='rrtmgp-cloud-optics-coeffs-lw.nc'):\n",
    "\n",
    "    \"\"\"\n",
    "    File staging for RRTMGP\n",
    "    \n",
    "    Call\n",
    "        \n",
    "    Inputs\n",
    "        fThermal -- int, optimize LW k-distribution\n",
    "    \n",
    "    Outputs\n",
    "        None\n",
    "\n",
    "    Keywords\n",
    "        rrtmgpPath -- string, top-level directory with RRTMGP code\n",
    "        exe -- string, \n",
    "            absolete path to RRTMGP LW/SW solver (flux calulation) executable\n",
    "        coeffSW -- string, \n",
    "            basename of file with SW absorption coefficients for clear skies\n",
    "        coeffLW -- string, \n",
    "            basename of file with LW absorption coefficients for clear skies\n",
    "        cloudSW -- string, \n",
    "            basename of file with SW absorption coefficients with clouds\n",
    "        cloudLW -- string,\n",
    "            basename of file with LW absorption coefficients with clouds\n",
    "    \"\"\"\n",
    "    \n",
    "    #buildDir = '{}/build'.format(rrtmgpPath)\n",
    "    coeffDir = '{}/rte-rrtmgp/rrtmgp/data'.format(rrtmgpPath)\n",
    "    cloudDir = '{}/rte-rrtmgp/extensions/cloud_optics'.format(rrtmgpPath)\n",
    "\n",
    "    paths = [exe, coeffDir, cloudDir, \n",
    "             '{}/{}'.format(coeffDir, coeffSW), \n",
    "             '{}/{}'.format(coeffDir, coeffLW), \n",
    "             '{}/{}'.format(cloudDir, cloudSW), \n",
    "             '{}/{}'.format(cloudDir, cloudLW)]\n",
    "    for path in paths: pathCheck(path)\n",
    "\n",
    "    exeBase = os.path.basename(exe)\n",
    "    if not os.path.exists(exeBase): os.symlink(exe, exeBase)\n",
    "\n",
    "    swTarget = 'coefficients_sw.nc'\n",
    "    # Pernak: reverse the logic here? done\n",
    "    if not os.path.exists(swTarget) and not THERMAL:\n",
    "        os.symlink('{}/{}'.format(coeffDir, coeffSW), swTarget)\n",
    "\n",
    "    lwTarget = 'coefficients_lw.nc'\n",
    "    # Pernak: reverse the logic here? done\n",
    "    if not os.path.exists(lwTarget) and THERMAL: \n",
    "        os.symlink('{}/{}'.format(coeffDir, coeffLW), lwTarget)\n",
    "\n",
    "    swTarget = 'cloud_coefficients_sw.nc'\n",
    "    if not os.path.exists(swTarget):\n",
    "        os.symlink('{}/{}'.format(cloudDir, cloudSW), swTarget)\n",
    "\n",
    "    lwTarget = 'cloud_coefficients_lw.nc'\n",
    "    if not os.path.exists(lwTarget):\n",
    "        os.symlink('{}/{}'.format(cloudDir, cloudLW), lwTarget)\n",
    "\n",
    "def process_costs(components):\n",
    "    totCost = CF.total_cost(components)\n",
    "    print(\"Total cost: {}\".format(totCost))\n",
    "    return np.append(components, totCost)\n",
    "\n",
    "def append_errors(idx, errorDict, errWin, errOld):\n",
    "    data = [errorDict[idx][0] + errWin[0] - errOld[0], \n",
    "            errorDict[idx][1] + errWin[1] - errOld[1]]\n",
    "    errorDict[idx] = list(data)\n",
    "    return([0]) \n",
    "\n",
    "def modify_wt_gpt(gOut, wt, bandID, nGpt, gptArr):\n",
    "    wt[gOut-1] = wt[gOut-1]+wt[gOut]\n",
    "    wt = np.delete(wt, gOut)\n",
    "    bandID = np.delete(bandID, gOut)\n",
    "    return wt, bandID, nGpt-1, gptArr.copy()\n",
    "\n",
    "def remove_temp_files(dirRes):\n",
    "    for d in ['{}/coeffs'.format(dirRes), '{}/fluxes'.format(dirRes)]:\n",
    "        for f in os.listdir(d): \n",
    "            if not f.startswith(\"temp\"):\n",
    "                os.remove(os.path.join(d, f))\n",
    "\n",
    "def write_cost_nc(dirOut, allBands, allGpts, allCosts, names, \n",
    "                  icost=2, f_thermal=False, f_errtype=5):\n",
    "\n",
    "    ncFile = \"{}/optimisation_output.{}.cost{:02d}.norm{:01d}.bnd{:02d}.nc\".format(\n",
    "        dirOut, 'lw' if f_thermal else 'sw', icost, f_errtype, bands[0])\n",
    "    os.makedirs(os.path.dirname(ncFile), exist_ok=True)\n",
    "    dataOut = nc.Dataset(ncFile, 'w')\n",
    "    \n",
    "    dataOut.createDimension(\"n_name\", len(names))\n",
    "    dataOut.createDimension(\"pair\", 2)\n",
    "    dataOut.createDimension(\"n_iter\", allGpts.shape[1])\n",
    "    dataOut.createDimension(\"t_iter\", allGpts.shape[1]+1)\n",
    "\n",
    "    gptsOut  = data_out.createVariable(\n",
    "        \"combined_gpt_pair\", \"f4\", (\"pair\", \"n_iter\"))\n",
    "    bandOut  = data_out.createVariable(\n",
    "        \"combined_band\", \"f4\", (\"n_iter\"))\n",
    "    costOut  = data_out.createVariable(\n",
    "        \"cost_components\", \"f4\", (\"n_name\", \"t_iter\"))\n",
    "    ctotOut  = data_out.createVariable(\n",
    "        \"total_cost\", \"f4\", (\"t_iter\"))\n",
    "    nameOut  = data_out.createVariable(\n",
    "        \"names\", str, (\"n_name\"))\n",
    "    \n",
    "    gptsOut[:] = all_gpts\n",
    "    bandOut[:] = all_bands\n",
    "    costOut[:] = all_costs[:-1]\n",
    "    ctotOut[:] = all_costs[-1]\n",
    "    for i in range(len(names)): nameOut[i] = names[i]\n",
    "    \n",
    "    dataOut.close()\n",
    "\n",
    "def make_name_variant(iterNum, gpts):\n",
    "    # Return string of form iterNNN.GGG.GGG,\n",
    "    #   iterNum is a scalar int, gpts is list of ints of length 2\n",
    "    return('iter{0:03d}.{1[0]:03d}.{1[1]:03d}'.format(iterNum, gpts))\n",
    "\n",
    "def menno_trial_cost_function(iterNum, dirRes, dirData, \n",
    "                        start_kdist_file, gpts, wts, \n",
    "                        ref_flux_file, cf_norm, flux_data, \n",
    "                        f_thermal=False, f_forcing=False, \n",
    "                        exe='./rrtmgp_garand_atmos'):\n",
    "\n",
    "    # Return the terms in the cost function for a proposed \n",
    "    # combination of two gpoints from an initial set\n",
    "    trial_kdist_file = '{}/coeffs/coefficients_{}.nc'.format(\n",
    "        dirRes, make_name_variant(iterNum, gpts))\n",
    "    trial_flux_file  = '{}/fluxes/fluxes.all.{}.nc'.format(\n",
    "        dirRes, make_name_variant(iterNum, gpts))\n",
    "    \n",
    "    # Make sure directories exist\n",
    "    os.makedirs(os.path.dirname(trial_kdist_file), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(trial_flux_file), exist_ok=True)\n",
    "\n",
    "    # Combine the pair of g-points specified in gpts(2) with weights wts(2)\n",
    "    combine_gpoints_fn(start_kdist_file, trial_kdist_file, gpts, wts)\n",
    "    \n",
    "    # create and go to temporary dir\n",
    "    output_path = '{}/fluxes/temp_{}/'.format(\n",
    "        dirRes, make_name_variant(iterNum, gpts))\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    os.chdir(output_path)\n",
    "\n",
    "    # stage trial coefficient files\n",
    "    domain = 'lw' if f_thermal else 'sw'\n",
    "    link_rrtmgp(exe=EXE)\n",
    "    file_rrtmgp_output = \"rte_rrtmgp_output_{}.nc\".format(domain)\n",
    "    file_rrtmgp_input = \"{}/input/rte_rrtmgp_input_{}.nc\".format(\n",
    "        dirData, domain)\n",
    "    coeffStage = \"coefficients_{}.nc\".format(domain)\n",
    "    shutil.copy2(trial_kdist_file, coeffStage)\n",
    "\n",
    "    # link input files\n",
    "    for icase in FRANGE: shutil.copy2(file_rrtmgp_input.format(icase), './')\n",
    "    \n",
    "    # run and combine fluxes\n",
    "    subprocess.run([exe, file_rrtmgp_input, coeffStage])\n",
    "    os.rename(file_rrtmgp_input, trial_flux_file)\n",
    "    subprocess.run([\"./test_garand\", \n",
    "                    \"--no-{}\".format('shortwave' if f_thermal else 'longwave'), \n",
    "                    \"--output-bnd-fluxes\"] + \\\n",
    "                   (['--forcing'] if f_forcing else []))\n",
    "\n",
    "    subprocess.run(['/global/common/sw/cray/cnl7/haswell/nco/' + \\\n",
    "                    '4.7.9/gcc/8.3.0/bz3muff/bin/ncecat'] + \\\n",
    "                   [file_rrtmgp_output.format(i) for i in fRange] + \\\n",
    "                   [\"-u\", \"record\", \"-O\", trial_flux_file])\n",
    "\n",
    "    os.chdir(kDistOptPath)\n",
    "    shutil.rmtree(output_path)\n",
    "    \n",
    "    # Return the cost function components normalized by error at iteration 0\n",
    "    flux_data[gpts[0]] = CF.cost_function_components(trial_flux_file, ref_flux_file)\n",
    "    return([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell contains functions that are compatible with Ben Hillman's [optimizerLW.py](https://github.com/RobertPincus/k-distribution-opt/blob/brhillman/dev/optimizeLW.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial_cost_function(iterNum, start_kdist_file, gpts, wts, ref_flux_file, cf_norm):\n",
    "    #\n",
    "    # Return the terms in the cost function (flux, heating rate, etc.) for a proposed\n",
    "    #   combination of two gpoints from an initial set. Hillman version\n",
    "    #\n",
    "    trial_kdist_file = 'results/coeffs/coefficients_{0}.nc'.format(make_name_variant(iterNum, gpts))\n",
    "    trial_flux_file  = 'results/fluxes/fluxes.all.{0}.nc'.format(  make_name_variant(iterNum, gpts))\n",
    "    #\n",
    "    # Make sure directories exist\n",
    "    #\n",
    "    os.makedirs(os.path.dirname(trial_kdist_file), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(trial_flux_file), exist_ok=True)\n",
    "    #\n",
    "    # Combine the pair of g-points specified in gpts(2) with weights wts(2)\n",
    "    #\n",
    "    combine_gpoints_fn(start_kdist_file, trial_kdist_file, gpts, wts)\n",
    "    #\n",
    "    # Compute fluxes; note we copy the template flux file first because the driver overwrites\n",
    "    # fluxes in the original file rather than writing a new file\n",
    "    #\n",
    "    shutil.copy2(ref_flux_file, trial_flux_file)\n",
    "    subprocess.run(['./rrtmgp_garand_atmos', trial_flux_file, trial_kdist_file], check=True)\n",
    "    #\n",
    "    # Return the cost function components normalized by error at iteration 0\n",
    "    #\n",
    "    error_components = CF.normalized_cost_terms(trial_flux_file, ref_flux_file, cf_norm)\n",
    "    assert all([np.isfinite(e) for e in error_components])\n",
    "    return(error_components)\n",
    "\n",
    "def writeCostNC(iteration, inCost, gCombine):\n",
    "\n",
    "    # Save terms of the cost function (inCost) for every possible \n",
    "    # g-point combination (gCombine) for a given iteration\n",
    "\n",
    "    ncFile = 'data/cost_function_terms.lw.iter{:03d}.nc'.format(iteration)\n",
    "    with nc.Dataset(ncFile, 'w') as dataOUT:\n",
    "        dataOUT.createDimension(\"Gpt_combination\", 2)\n",
    "        dataOUT.createDimension(\"Case\", len(gCombine))\n",
    "        H_norm = dataOUT.createVariable(\"H_norm\", \"f4\", (\"Case\"))\n",
    "        F_norm = dataOUT.createVariable(\"F_norm\", \"f4\", (\"Case\"))\n",
    "        FO_norm = dataOUT.createVariable(\"FO_norm\", \"f4\", (\"Case\"))\n",
    "        S_norm = dataOUT.createVariable(\"S_norm\", \"f4\", (\"Case\"))\n",
    "        gPtsOut = dataOUT.createVariable(\n",
    "            \"Gpt_pair\", \"f4\", (\"Case\",\"Gpt_combination\"))\n",
    "        cstfnc  = dataOUT.createVariable(\"cost_function\", \"f4\", (\"Case\"))\n",
    "\n",
    "        # Store data in netCDF arrays\n",
    "        for i in np.arange(len(gCombine)):\n",
    "            F_norm[i] = inCost[i][0]\n",
    "            H_norm[i] = inCost[i][1]\n",
    "            FO_norm[i] = inCost[i][2]\n",
    "            S_norm[i] = inCost[i][3]\n",
    "            gPtsOut[i,:] = gpt_list[i]\n",
    "            cstfnc[i] = CF.total_cost(inCost[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell will be expanded when Menno's implementation is...implemented.\n",
    "\n",
    "Currently, there are 8 different cost functions that can be minimized. The default is 5, but other options for `icost` (type `int`) are:\n",
    "  1. \n",
    "  2. \n",
    "  3. \n",
    "  4. \n",
    "  5. \n",
    "  6. \n",
    "  7. \n",
    "  8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables in cost function: sfc_flux\n"
     ]
    }
   ],
   "source": [
    "# Global variable definition of the cost function type\n",
    "ICOST = 5\n",
    "\n",
    "if ICOST == 1: \n",
    "    names = ['dn_bnd_lwr', 'up_bnd_lwr', 'nt_bnd_lw', 'dn_tot_lwr', 'up_tot_lwr', 'nt_tot_lwr', 'heat_lwr', \n",
    "             'dn_bnd_upr', 'up_bnd_upr', 'nt_bnd_up', 'dn_tot_upr', 'up_tot_upr', 'nt_tot_upr', 'heat_upr']\n",
    "elif ICOST == 2:\n",
    "    names = ['nt_bnd_lw', 'nt_tot_lwr', 'heat_lwr', 'nt_bnd_up', 'nt_tot_upr', 'heat_upr']\n",
    "elif ICOST == 3:\n",
    "    names = ['nt_bnd_lwr', 'nt_tot_lwr', 'heat_lwr']\n",
    "elif ICOST == 4:\n",
    "    names = ['nt_bnd_upr', 'nt_tot_upr', 'heat_upr']\n",
    "elif ICOST == 5:\n",
    "    names = ['sfc_flux']\n",
    "elif ICOST == 6:\n",
    "    names = ['heat_lwr', 'heat_upr', 'sfc_flux']\n",
    "elif ICOST == 7:\n",
    "    names = ['sfc_flux_dn', 'trp_flx_dn', 'trp_flx_up', 'toa_flx_up']\n",
    "elif ICOST == 8:\n",
    "    names = ['heat_thermo']\n",
    "else:\n",
    "    print('INVALID COST FUNCTION')\n",
    "    \n",
    "print('Variables in cost function: {}'.format(', '.join(names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Global Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define what kind of normalization `f_errtype` (type `int`) will be applied to the cost function:\n",
    "\n",
    "  0. absolute error (RMSE)\n",
    "  1. change in RMSE with respect to RMSE at iteration 0\n",
    "  2. error w.r.t. LBLRTM (normalized rmse)\n",
    "\n",
    "Whether the _k_-distribution optimization is done in the longwave or shortwave domain is specified with `f_thermal` (type `bool`). This is important for filename specifications. Forcing has not been implemented in this notebook, so it should **always** be set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERRTYPE = 2\n",
    "THERMAL = True\n",
    "FORCING = False\n",
    "FRANGE = range(1+6*(THERMAL and FORCING))\n",
    "DOMAIN = 'lw' if THERMAL else 'sw'\n",
    "DOMAINL = 'longwave' if THERMAL else 'shortwave'\n",
    "EXE = '{}/rrtmgp_garand_atmos'.format(PINCUSPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the executable is the [FORTRAN-based](https://github.com/RobertPincus/k-distribution-opt/blob/brhillman/dev/rrtmgp_garand_atmos.F90) `rrtmgp_garand_atmos` rather than the [C++-based](https://github.com/MennoVeerman/k-distribution-opt/blob/master/test_garand.cpp) `test_garand`. The latter was yielding `Segmentation Faults` at runtime on the NERSC `cori` machine and thus was not producing the results that were needed for the rest of the optimization. Because of these errors, we pursue the \"Hillman\" method in the rest of this notebook, while attempting to fold in the enhancements from Menno, which include cost function flexibility and diagnostics plotting. Hillman and Pincus also have more transparent cost function calculation, which we will try to extend to the Menno cost functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kDistOptPath = LIBPATHS[0] # path of k-distribution directory (originally `bpath`)\n",
    "pathCheck(kDistOptPath)\n",
    "\n",
    "# where to save coeff and temporary flux files (originally `dpath`)\n",
    "outDatPath = '{}/intermediate_files'.format(GPTHOME)\n",
    "if not os.path.isdir(outDatPath): os.makedirs(outDatPath)\n",
    "\n",
    "#file_LBLRTM = '{}/lbl_reference_{}.nc'.format(kDistOptPath, DOMAINL)\n",
    "# newest reference file provided by Robert (with `record` dimension)\n",
    "projectDir = '/project/projectdirs/e3sm/pernak18/inputs/g-point-reduce'\n",
    "file_LBLRTM = '{}/lblrtm-{}-flux-inputs-outputs-garandANDpreind.nc'.format(\n",
    "    projectDir, DOMAIN)\n",
    "\n",
    "# RRTMGP coefficient file\n",
    "coeffInit = 'rrtmgp-data-lw-g256-2018-12-04.nc' if THERMAL else \\\n",
    "    'rrtmgp-data-sw-g224-2018-12-04.nc'\n",
    "dirCoeffInit = '{}/rte-rrtmgp/rrtmgp/data/'.format(GPTHOME)\n",
    "pathCheck(dirCoeffInit)\n",
    "\n",
    "# Directory where new fluxes and coefficient files are stored.\n",
    "dirOut  = '{}/outputs_bnd2'.format(outDatPath)\n",
    "dirRes  = \"{}/results_bnd2/{}.cost{:02d}.norm{:01d}/\".format(\n",
    "    outDatPath, DOMAIN, ICOST, ERRTYPE)\n",
    "dirData = \"{}/data_bnd2/{}.cost{:02d}.norm{:01d}/\".format(\n",
    "    outDatPath, DOMAIN, ICOST, ERRTYPE)\n",
    "PATHS = [dirOut, dirRes, dirData]\n",
    "for path in PATHS:\n",
    "    if not os.path.isdir(path): os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime Variables Definition, Extract Information from LBLRTM Reference Results\n",
    "\n",
    "We will use the pressures that were input into LBLRTM. `p_lev` is a (1 x 43 x 42) array, so we are extracting the entire pressure profile of the first Garand atmosphere (in descending order, so surface-to-TOA).\n",
    "\n",
    "The number of _g_-points can be extracted from the LBL netCDF as well. The weights associated with each _g_-point are the same for each band, so we effectively produce an `nGpt`x`nBnds` array, then flatten it to a 1-D vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pressures (1D)\n",
    "p_lev = nc.Dataset(file_LBLRTM).variables['p_lev'][0,:,0]\n",
    "\n",
    "# Initial settings.\n",
    "# Todo: generalize, read values from coefficient file\n",
    "# Number of bands\n",
    "nBnds = len(nc.Dataset(file_LBLRTM).variables['band'][:])\n",
    "\n",
    "# Number of G-points in each band.\n",
    "nGptsPerBandOrg = 16\n",
    "\n",
    "# Number of G-points\n",
    "nGpt = nBnds * nGptsPerBandOrg\n",
    "\n",
    "# optimization iterations\n",
    "nOptIt = 210\n",
    "nOptIt = 3\n",
    "\n",
    "# variables in the optimization\n",
    "varsCF = ['F_', 'H_', 'FO_', 'S_']\n",
    "\n",
    "# Band ID for each G-point\n",
    "bandID = range(1, nBnds+1)\n",
    "bandID = np.repeat(bandID, nGptsPerBandOrg)\n",
    "\n",
    "# G-point weights (same for all bands)\n",
    "# expand weights for one band to the rest of the bands with np.tile\n",
    "# so weights are an (nGpt x nBnds)-element vector\n",
    "wgtBnd = [0.1527534276, 0.1491729617, 0.1420961469, 0.1316886544, \n",
    "         0.1181945205, 0.1019300893, 0.0832767040, 0.0626720116, \n",
    "         0.0424925000, 0.0046269894, 0.0038279891, 0.0030260086, \n",
    "         0.0022199750, 0.0014140010, 0.0005330000, 0.0000750000]\n",
    "wt = np.tile(wgtBnd, nBnds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RRTMGP File Staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/global/homes/p/pernak18/RRTMGP/g-point-reduction/intermediate_files/data_bnd2/lw.cost05.norm2//rrtmgp-data-lw-g256-2018-12-04.nc'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare input file\n",
    "file_rrtmgp_input = \"{}/input/rte_rrtmgp_input_{}.nc\".format(\n",
    "    dirData, DOMAIN)\n",
    "os.makedirs(os.path.dirname(file_rrtmgp_input), exist_ok=True)\n",
    "#prepare_input(file_LBLRTM, file_rrtmgp_input)\n",
    "\n",
    "# Create output directory\n",
    "file_rrtmgp_output = \"{}/fluxes/rte_rrtmgp_output_{}.nc\".format(\n",
    "    dirData, DOMAIN)\n",
    "os.makedirs(os.path.dirname(file_rrtmgp_output), exist_ok=True)\n",
    "\n",
    "# copy original k-dist file\n",
    "shutil.copy2('{}/{}'.format(dirCoeffInit, coeffInit), \n",
    "             '{}/{}'.format(dirData, coeffInit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial RRTMGP Fluxes (With Original _k_-distribution)/Reference Fluxes\n",
    "\n",
    "Stage some more files into a working directory (where the model is run over many iterations), then perform an initial run of RRTMGP over all Garand atmospheres. `returncode` of 0 means success. Be leery of other return codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial RRTMGP fluxes calculation complete\n"
     ]
    }
   ],
   "source": [
    "os.chdir(dirRes)\n",
    "\n",
    "# copy k-distribution and profile information files to working dir\n",
    "# we are using Robert's LBL reference file for the latter\n",
    "# https://github.com/RobertPincus/k-distribution-opt/blob/master/lblrtm-lw-flux-inputs-outputs-garandANDpreind.nc\n",
    "coeffNC = 'coefficients_{}.nc'.format(DOMAIN)\n",
    "shutil.copy2('{}/{}'.format(dirData, coeffInit), coeffNC)\n",
    "inNC = 'rte_rrtmgp_input-output_0.nc'\n",
    "shutil.copy2(file_LBLRTM, './{}'.format(inNC))\n",
    "\n",
    "# run Robert's version of `test_garand`\n",
    "args = [EXE, inNC, coeffNC]\n",
    "status = subprocess.run(args)\n",
    "if status.returncode != 0:\n",
    "    print('WARNING! {} did not complete.'.format(' '.join(args)))\n",
    "    print('This is likely because of a segmentation fault.')\n",
    "else:\n",
    "    print('Initial RRTMGP fluxes calculation complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the RRTMGP fluxes from initial run so that they can be used to determine the normalization factor that is use in the optimization iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Staging\n",
    "file_rrtmgp_ref = '{}/fluxes/reference_kdist_fluxes.nc'.format(dirRes)\n",
    "if not os.path.isdir('{}/fluxes'.format(dirRes)):\n",
    "    os.makedirs('{}/fluxes'.format(dirRes))\n",
    "os.rename(inNC, file_rrtmgp_ref)\n",
    "\n",
    "# normalization factor\n",
    "cf_norm = CF.cost_function_components(file_rrtmgp_ref, file_LBLRTM)\n",
    "\n",
    "# back to \"top-level directory\"\n",
    "os.chdir(kDistOptPath)\n",
    "\n",
    "# Menno code block\n",
    "# if ERRTYPE == 1:\n",
    "#     cf_norm = CF.cost_function_from_error(\n",
    "#         CF.flux_heat_errors(file_rrtmgp_ref, file_LBLRTM), p_lev, ICOST)\n",
    "#     cf_norm_norm = CF.normalized_costs(cf_norm, cf_norm, ERRTYPE)\n",
    "# elif ERRTYPE == 2 or ERRTYPE == 0:\n",
    "#     cf_norm = RV.reference_values(\n",
    "#         RV.get_fluxes(file_LBLRTM), p_lev, ICOST)\n",
    "#     cf_frst = CF.cost_function_from_error(\n",
    "#         CF.flux_heat_errors(file_rrtmgp_ref, file_LBLRTM), p_lev, ICOST)\n",
    "#     cf_norm_norm = CF.normalized_costs(cf_frst, cf_norm, ERRTYPE)\n",
    "# winner_err_old = CF.flux_heat_errors(file_rrtmgp_ref, file_LBLRTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Initialization for Greedy Optimization of Cost Function\n",
    "\n",
    "Need to make the calculations more transparent for Eli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hillman Version\n",
    "\n",
    "Now the computationally-extensive part. First, some additional file staging is performed, most important being the gathering of the initial _k_-distribution for the first iteration. Then, a loop over a user-specified number of iterations (`nOptIt`) is executed, where the following steps are followed:\n",
    "\n",
    "1. _k_-distribution is defined\n",
    "2. determine all _g_-point and associated weight combinations for the iteration\n",
    "3. cost function for all possible _g_-point and weight pairs is calculated -- these pairs are distributed over many CPU threads; also calculate new coefficients and write them to their own _k_-distribution file\n",
    "4. the pair that minimized the errors is determined\n",
    "5. a new _k_-distribution, which was generated in step 3., is defined for the next iteration\n",
    "6. clean up of unnecessary files\n",
    "7. summary of optimization is printed to notebook\n",
    "8. modify weights according the optimal _g_-point combination, to be used in step 2. of the next iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining g-point pairs 3 times...\n",
      "For iteration 001, combining g-points 104 and 105 in band 07\n",
      "\n",
      "F_     : 0.99959987\n",
      "H_     : 0.96116579\n",
      "FO_    : 0.99949145\n",
      "S_     : 1.00481772\n",
      "Total Cost: 0.98949512\n",
      "New coefficient file: coefficients_iter001.104.105.nc\n",
      "For iteration 002, combining g-points 076 and 077 in band 05\n",
      "\n",
      "F_     : 0.99747723\n",
      "H_     : 0.95867687\n",
      "FO_    : 0.99467427\n",
      "S_     : 1.00533259\n",
      "Total Cost: 0.98687761\n",
      "New coefficient file: coefficients_iter002.076.077.nc\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# On first iteration, coefficients file is the original one\n",
    "shutil.copy2('{}/{}'.format(dirCoeffInit, coeffInit), \n",
    "             'data/{}'.format(coeffInit))\n",
    "coeffPrev = str(coeffInit)\n",
    "\n",
    "print(f'Combining g-point pairs {nOptIt} times...'); sys.stdout.flush()\n",
    "\n",
    "for iMain in range(1, nOptIt):\n",
    "    # Which coefficient file to use? \n",
    "    coeffIter = 'data/{}'.format(coeffPrev)\n",
    "    pathCheck(coeffIter)\n",
    "\n",
    "    # Create list of all adjacent g-point and weight pairs in each band\n",
    "    gpt_list = [[x, x+1] for x in range(1, nGpt) if \n",
    "                bandID[x-1] == bandID[x]]\n",
    "    wgt_list = [(wt[gpt_pair[0]-1], wt[gpt_pair[1]-1]) for \n",
    "                gpt_pair in gpt_list]\n",
    "\n",
    "    # Compute error terms for each combination of adjacent g-points pairs\n",
    "    # parallelize the calculations over all CPUs\n",
    "    # THIS NEEDS TO BE ADJUSTED FOR NERSC!\n",
    "    with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n",
    "        # separate processes, each with their own arguments\n",
    "        results = [pool.apply_async(trial_cost_function, \n",
    "                                   args=(iMain, coeffIter, gpt_pair, \n",
    "                                         wgt_pair, file_LBLRTM, cf_norm))\n",
    "                   for gpt_pair, wgt_pair in zip(gpt_list, wgt_list)]\n",
    "        cfn_list = [r.get() for r in results]\n",
    "\n",
    "    # Greedy optimization\n",
    "    # Of all the g-point combinations in this iteration, \n",
    "    # which had the smallest error?\n",
    "    winner = np.argmin([CF.total_cost(x) for x in cfn_list])\n",
    "\n",
    "    # Set the new coefficent file for the next iteration.\n",
    "    coeffPrev = 'coefficients_{0}.nc'.format(\n",
    "        make_name_variant(iMain, gpt_list[winner]))\n",
    "    shutil.copy2('results/coeffs/{}'.format(coeffPrev), \n",
    "                 'data/{}'.format(coeffPrev))\n",
    "\n",
    "    # Remove temporary files\n",
    "    for d in ['results/coeffs', 'results/fluxes']:\n",
    "        for f in os.listdir(d): os.remove(os.path.join(d, f))\n",
    "\n",
    "    g1out = int(gpt_list[winner][0])\n",
    "    g2out = int(gpt_list[winner][1])\n",
    "\n",
    "    # print to standard output the g-point combination that minimized error\n",
    "    print('For iteration {0:03d}, '.format(iMain), end='')\n",
    "    print('combining g-points {:03d} '.format(gpt_list[winner][0]), end='')\n",
    "    print('and {:03d} '.format(gpt_list[winner][1]), end='')\n",
    "    print('in band {:02d}'.format(bandID[g1out-1]))\n",
    "    print()\n",
    "\n",
    "    # summarize values that were optimized\n",
    "    for iVar, var in enumerate(varsCF):\n",
    "        print('{:7s}: {:9.8f}'.format(var, cfn_list[winner][iVar].values))\n",
    "\n",
    "    print('{:10s}: {:9.8f}'.format(\n",
    "        'Total Cost', CF.total_cost(cfn_list[winner])))\n",
    "    print('New coefficient file: {}'.format(coeffPrev))\n",
    "\n",
    "    # For the next iteration, modify the weights and the array that contains\n",
    "    # the number of G-points in each band. Next iteration will be over nGpts-1\n",
    "    wt[g1out-1] = wt[g1out-1] + wt[g2out-1]\n",
    "    wt = np.delete(wt, g2out-1)\n",
    "    bandID = np.delete(bandID, g2out-1)\n",
    "    nGpt = nGpt-1\n",
    "\n",
    "    # write a netCDF for this iteration\n",
    "    writeCostNC(iMain, cfn_list, gpt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Menno version\n",
    "\n",
    "[Menno's Optimizer](https://github.com/MennoVeerman/k-distribution-opt/blob/master/optimizer.py) and Ben Hillman's (Ben separates into [LW](https://github.com/RobertPincus/k-distribution-opt/blob/brhillman/dev/optimizeLW.py) and [SW](https://github.com/RobertPincus/k-distribution-opt/blob/brhillman/dev/optimizeSW.py) optimizers) are pretty similar. Menno experiments with many more cost functions and plots intermediate results more often, but there seems to be some inconsistencies between the input files and perhaps executables that are used. For example, Menno uses `ncecat` to add a `record` dimension to the netCDF files, but Robert's and Ben's `rrtmgp_garand_atmos` expects it at runtime. Since we used `rrtmgp_garand_atmos`, we will use Ben's approach to optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
