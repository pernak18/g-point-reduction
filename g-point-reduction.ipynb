{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Menno Veerman's g-Point Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard modules\n",
    "import os, sys, shutil, subprocess, time, multiprocessing\n",
    "\n",
    "# pip installs\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "\n",
    "# local modules\n",
    "HOME = '/global/homes/p/pernak18'\n",
    "GPTHOME = '{}/RRTMGP/g-point-reduction'.format(HOME)\n",
    "LIBPATHS = ['{}/k-distribution-opt'.format(GPTHOME), \n",
    "            '{}/.local/'.format(HOME) + \\\n",
    "            'cori/3.7-anaconda-2019.10/lib/python3.7/site-packages']\n",
    "for path in LIBPATHS: sys.path.append(path)\n",
    "from combine_gpoints_fn import combine_gpoints_fn\n",
    "from prepare_cpp_input import prepare_input\n",
    "import cost_function as CF\n",
    "import ref_values as RV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, there are 8 different cost functions that can be minimized. The default is 5, but other options for `icost` (type `int`) are:\n",
    "  1. \n",
    "  2. \n",
    "  3. \n",
    "  4. \n",
    "  5. \n",
    "  6. \n",
    "  7. \n",
    "  8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables in cost function: sfc_flux\n"
     ]
    }
   ],
   "source": [
    "# Global variable definition of the cost function type\n",
    "ICOST = 5\n",
    "\n",
    "if ICOST == 1: \n",
    "    names = ['dn_bnd_lwr', 'up_bnd_lwr', 'nt_bnd_lw', 'dn_tot_lwr', 'up_tot_lwr', 'nt_tot_lwr', 'heat_lwr', \n",
    "             'dn_bnd_upr', 'up_bnd_upr', 'nt_bnd_up', 'dn_tot_upr', 'up_tot_upr', 'nt_tot_upr', 'heat_upr']\n",
    "elif ICOST == 2:\n",
    "    names = ['nt_bnd_lw', 'nt_tot_lwr', 'heat_lwr', 'nt_bnd_up', 'nt_tot_upr', 'heat_upr']\n",
    "elif ICOST == 3:\n",
    "    names = ['nt_bnd_lwr', 'nt_tot_lwr', 'heat_lwr']\n",
    "elif ICOST == 4:\n",
    "    names = ['nt_bnd_upr', 'nt_tot_upr', 'heat_upr']\n",
    "elif ICOST == 5:\n",
    "    names = ['sfc_flux']\n",
    "elif ICOST == 6:\n",
    "    names = ['heat_lwr', 'heat_upr', 'sfc_flux']\n",
    "elif ICOST == 7:\n",
    "    names = ['sfc_flux_dn', 'trp_flx_dn', 'trp_flx_up', 'toa_flx_up']\n",
    "elif ICOST == 8:\n",
    "    names = ['heat_thermo']\n",
    "else:\n",
    "    print('INVALID COST FUNCTION')\n",
    "    \n",
    "print('Variables in cost function: {}'.format(', '.join(names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Global Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define what kind of normalization `f_errtype` (type `int`) will be applied to the cost function:\n",
    "\n",
    "  0. absolute error (RMSE)\n",
    "  1. change in RMSE with respect to RMSE at iteration 0\n",
    "  2. error w.r.t. LBLRTM (normalized rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERRTYPE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize the longware _k_-distribution (`f_thermal`, type `bool`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "THERMAL = True\n",
    "FORCING = False\n",
    "FRANGE = range(1+6*(THERMAL and FORCING))\n",
    "DOMAIN = 'lw' if THERMAL else 'sw'\n",
    "DOMAINL = 'longwave' if THERMAL else 'shortwave'\n",
    "EXE = '{}/obsolete/pincus_k-distribution-opt/rrtmgp_garand_atmos'.format(\n",
    "    LIBPATHS[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "kDistOptPath = LIBPATHS[0] # path of k-distribution directory (originally `bpath`)\n",
    "assert os.path.exists(kDistOptPath), 'Could not find {}'.format(kDistOptPath)\n",
    "\n",
    "# where to save coeff and temporary flux files (originally `dpath`)\n",
    "outDatPath = '{}/intermediate_files'.format(GPTHOME)\n",
    "if not os.path.isdir(outDatPath): os.makedirs(outDatPath)\n",
    "\n",
    "file_LBLRTM = '{}/lbl_reference_{}.nc'.format(kDistOptPath, DOMAINL)\n",
    "\n",
    "# RRTMGP coefficient file\n",
    "file_coeffORG = 'rrtmgp-data-lw-g256-2018-12-04.nc' if THERMAL else \\\n",
    "    'rrtmgp-data-sw-g224-2018-12-04.nc'\n",
    "file_coeffORG_dir = '{}/rte-rrtmgp-cpp/rte-rrtmgp/rrtmgp/data/'.format(\n",
    "    GPTHOME)\n",
    "assert os.path.exists(file_coeffORG_dir), 'Could not find {}'.format(\n",
    "    kDistOptPath)\n",
    "\n",
    "# Directory where new fluxes and coefficient files are stored.\n",
    "dirOut  = '{}/outputs_bnd2'.format(outDatPath)\n",
    "dirRes  = \"{}/results_bnd2/{}.cost{:02d}.norm{:01d}/\".format(\n",
    "    outDatPath, DOMAIN, ICOST, ERRTYPE)\n",
    "dirData = \"{}/data_bnd2/{}.cost{:02d}.norm{:01d}/\".format(\n",
    "    outDatPath, DOMAIN, ICOST, ERRTYPE)\n",
    "PATHS = [dirOut, dirRes, dirData]\n",
    "for path in PATHS:\n",
    "    if not os.path.isdir(path): os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathCheck(path):\n",
    "    \"\"\"\n",
    "    Determine if file exists. If not, throw an Assertion Exception\n",
    "    \"\"\"\n",
    "\n",
    "    assert os.path.exists(path), 'Could not find {}'.format(path)\n",
    "    \n",
    "def link_rrtmgp(rrtmgpPath=\"{}/rte-rrtmgp-cpp\".format(GPTHOME), \n",
    "                exe=EXE, \n",
    "                coeffSW='rrtmgp-data-sw-g224-2018-12-04.nc', \n",
    "                coeffLW='rrtmgp-data-lw-g256-2018-12-04.nc', \n",
    "                cloudSW='rrtmgp-cloud-optics-coeffs-sw.nc', \n",
    "                cloudLW='rrtmgp-cloud-optics-coeffs-lw.nc'):\n",
    "\n",
    "    \"\"\"\n",
    "    File staging for RRTMGP\n",
    "    \n",
    "    Call\n",
    "        \n",
    "    Inputs\n",
    "        fThermal -- int, optimize LW k-distribution\n",
    "    \n",
    "    Outputs\n",
    "        None\n",
    "\n",
    "    Keywords\n",
    "        rrtmgpPath -- string, top-level directory with RRTMGP code\n",
    "        exe -- string, \n",
    "            absolete path to RRTMGP LW/SW solver (flux calulation) executable\n",
    "        coeffSW -- string, \n",
    "            basename of file with SW absorption coefficients for clear skies\n",
    "        coeffLW -- string, \n",
    "            basename of file with LW absorption coefficients for clear skies\n",
    "        cloudSW -- string, \n",
    "            basename of file with SW absorption coefficients with clouds\n",
    "        cloudLW -- string,\n",
    "            basename of file with LW absorption coefficients with clouds\n",
    "    \"\"\"\n",
    "    \n",
    "    #buildDir = '{}/build'.format(rrtmgpPath)\n",
    "    coeffDir = '{}/rte-rrtmgp/rrtmgp/data'.format(rrtmgpPath)\n",
    "    cloudDir = '{}/rte-rrtmgp/extensions/cloud_optics'.format(rrtmgpPath)\n",
    "\n",
    "    paths = [exe, coeffDir, cloudDir, \n",
    "             '{}/{}'.format(coeffDir, coeffSW), \n",
    "             '{}/{}'.format(coeffDir, coeffLW), \n",
    "             '{}/{}'.format(cloudDir, cloudSW), \n",
    "             '{}/{}'.format(cloudDir, cloudLW)]\n",
    "    for path in paths: pathCheck(path)\n",
    "\n",
    "    exeBase = os.path.basename(exe)\n",
    "    if not os.path.exists(exeBase): os.symlink(exe, exeBase)\n",
    "\n",
    "    swTarget = 'coefficients_sw.nc'\n",
    "    # Pernak: reverse the logic here? done\n",
    "    if not os.path.exists(swTarget) and not THERMAL:\n",
    "        os.symlink('{}/{}'.format(coeffDir, coeffSW), swTarget)\n",
    "\n",
    "    lwTarget = 'coefficients_lw.nc'\n",
    "    # Pernak: reverse the logic here? done\n",
    "    if not os.path.exists(lwTarget) and THERMAL: \n",
    "        os.symlink('{}/{}'.format(coeffDir, coeffLW), lwTarget)\n",
    "\n",
    "    swTarget = 'cloud_coefficients_sw.nc'\n",
    "    if not os.path.exists(swTarget):\n",
    "        os.symlink('{}/{}'.format(cloudDir, cloudSW), swTarget)\n",
    "\n",
    "    lwTarget = 'cloud_coefficients_lw.nc'\n",
    "    if not os.path.exists(lwTarget):\n",
    "        os.symlink('{}/{}'.format(cloudDir, cloudLW), lwTarget)\n",
    "\n",
    "def process_costs(components):\n",
    "    totCost = CF.total_cost(components)\n",
    "    print(\"Total cost: {}\".format(totCost))\n",
    "    return np.append(components, totCost)\n",
    "\n",
    "def append_errors(idx, errorDict, errWin, errOld):\n",
    "    data = [errorDict[idx][0] + errWin[0] - errOld[0], \n",
    "            errorDict[idx][1] + errWin[1] - errOld[1]]\n",
    "    errorDict[idx] = list(data)\n",
    "    return([0]) \n",
    "\n",
    "def modify_wt_gpt(gOut, wt, bandID, nGpt, gptArr):\n",
    "    wt[gOut-1] = wt[gOut-1]+wt[gOut]\n",
    "    wt = np.delete(wt, gOut)\n",
    "    bandID = np.delete(bandID, gOut)\n",
    "    return wt, bandID, nGpt-1, gptArr.copy()\n",
    "\n",
    "def remove_temp_files(dirRes):\n",
    "    for d in ['{}/coeffs'.format(dirRes), '{}/fluxes'.format(dirRes)]:\n",
    "        for f in os.listdir(d): \n",
    "            if not f.startswith(\"temp\"):\n",
    "                os.remove(os.path.join(d, f))\n",
    "\n",
    "def write_cost_nc(dirOut, allBands, allGpts, allCosts, names, \n",
    "                  icost=ICOST, f_thermal=THERMAL, f_errtype=ERRTYPE):\n",
    "\n",
    "    ncFile = \"{}/optimisation_output.{}.cost{:02d}.norm{:01d}.bnd{:02d}.nc\".format(\n",
    "        dirOut, 'lw' if f_thermal else 'sw', icost, f_errtype, bands[0])\n",
    "    os.makedirs(os.path.dirname(ncFile), exist_ok=True)\n",
    "    dataOut = nc.Dataset(ncFile, 'w')\n",
    "    \n",
    "    dataOut.createDimension(\"n_name\", len(names))\n",
    "    dataOut.createDimension(\"pair\", 2)\n",
    "    dataOut.createDimension(\"n_iter\", allGpts.shape[1])\n",
    "    dataOut.createDimension(\"t_iter\", allGpts.shape[1]+1)\n",
    "\n",
    "    gptsOut  = data_out.createVariable(\n",
    "        \"combined_gpt_pair\", \"f4\", (\"pair\", \"n_iter\"))\n",
    "    bandOut  = data_out.createVariable(\n",
    "        \"combined_band\", \"f4\", (\"n_iter\"))\n",
    "    costOut  = data_out.createVariable(\n",
    "        \"cost_components\", \"f4\", (\"n_name\", \"t_iter\"))\n",
    "    ctotOut  = data_out.createVariable(\n",
    "        \"total_cost\", \"f4\", (\"t_iter\"))\n",
    "    nameOut  = data_out.createVariable(\n",
    "        \"names\", str, (\"n_name\"))\n",
    "    \n",
    "    gptsOut[:] = all_gpts\n",
    "    bandOut[:] = all_bands\n",
    "    costOut[:] = all_costs[:-1]\n",
    "    ctotOut[:] = all_costs[-1]\n",
    "    for i in range(len(names)): nameOut[i] = names[i]\n",
    "    \n",
    "    dataOut.close()\n",
    "\n",
    "def make_name_variant(iterNum, gpts):\n",
    "    # Return string of form iterNNN.GGG.GGG,\n",
    "    #   iterNum is a scalar int, gpts is list of ints of length 2\n",
    "    return('iter{0:03d}.{1[0]:03d}.{1[1]:03d}'.format(iterNum, gpts))\n",
    "\n",
    "def trial_cost_function(iterNum, dirRes, dirData, \n",
    "                        start_kdist_file, gpts, wts, \n",
    "                        ref_flux_file, cf_norm, flux_data, \n",
    "                        f_thermal=THERMAL, f_forcing=FORCING):\n",
    "\n",
    "    # Return the terms in the cost function for a proposed \n",
    "    # combination of two gpoints from an initial set\n",
    "    trial_kdist_file = '{}/coeffs/coefficients_{}.nc'.format(\n",
    "        dirRes, make_name_variant(iterNum, gpts))\n",
    "    trial_flux_file  = '{}/fluxes/fluxes.all.{}.nc'.format(\n",
    "        dirRes, make_name_variant(iterNum, gpts))\n",
    "    \n",
    "    # Make sure directories exist\n",
    "    os.makedirs(os.path.dirname(trial_kdist_file), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(trial_flux_file), exist_ok=True)\n",
    "\n",
    "    # Combine the pair of g-points specified in gpts(2) with weights wts(2)\n",
    "    combine_gpoints_fn(start_kdist_file, trial_kdist_file, gpts, wts)\n",
    "    \n",
    "    # create and go to temporary dir\n",
    "    output_path = '{}/fluxes/temp_{}/'.format(\n",
    "        dirRes, make_name_variant(iterNum, gpts))\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    os.chdir(output_path)\n",
    "\n",
    "    # stage trial coefficient files\n",
    "    domain = 'lw' if f_thermal else 'sw'\n",
    "    link_rrtmgp()\n",
    "    file_rrtmgp_output = \"rte_rrtmgp_output_{}.nc\".format(domain)\n",
    "    file_rrtmgp_input = \"{}/input/rte_rrtmgp_input_{}.nc\".format(\n",
    "        dirData, domain)\n",
    "    shutil.copy2(trial_kdist_file, \"coefficients_{}.nc\".format(domain))\n",
    "\n",
    "    # link input files\n",
    "    for icase in FRANGE: shutil.copy2(file_rrtmgp_input.format(icase), './')\n",
    "    \n",
    "    # run and compbine fluxes\n",
    "    subprocess.run([\"./test_garand\", \n",
    "                    \"--no-{}\".format('shortwave' if f_thermal else 'longwave'), \n",
    "                    \"--output-bnd-fluxes\"] + \\\n",
    "                   (['--forcing'] if f_forcing else []))\n",
    "\n",
    "    subprocess.run(['/global/common/sw/cray/cnl7/haswell/nco/' + \\\n",
    "                    '4.7.9/gcc/8.3.0/bz3muff/bin/ncecat'] + \\\n",
    "                   [file_rrtmgp_output.format(i) for i in fRange] + \\\n",
    "                   [\"-u\", \"record\", \"-O\", trial_flux_file])\n",
    "\n",
    "    os.chdir(kDistOptPath)\n",
    "    shutil.rmtree(output_path)\n",
    "    \n",
    "    # Return the cost function components normalized by error at iteration 0\n",
    "    flux_data[gpts[0]] = cf.flux_heat_errors(trial_flux_file, ref_flux_file)\n",
    "    return([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Information from LBLRTM Reference Results\n",
    "\n",
    "We will use the pressures that were input into LBLRTM. `p_lev` is a (1 x 43 x 42) array, so we are extracting the entire pressure profile of the first Garand atmosphere (in descending order, so surface-to-TOA).\n",
    "\n",
    "The number of _g_-points can be extracted from the LBL netCDF as well. The weights associated with each _g_-point are the same for each band, so we effectively produce an `nGpt`x`nBnds` array, then flatten it to a 1-D vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pressures (1D)\n",
    "p_lev = nc.Dataset(file_LBLRTM).variables['p_lev'][0,:,0]\n",
    "\n",
    "# Initial settings.\n",
    "# Todo: generalize, read values from coefficient file\n",
    "# Number of bands\n",
    "nBnds = len(nc.Dataset(file_LBLRTM).variables['band'][:])\n",
    "\n",
    "# Number of G-points in each band.\n",
    "nGptsPerBandOrg = 16\n",
    "\n",
    "# Number of G-points\n",
    "nGpt = nBnds * nGptsPerBandOrg\n",
    "\n",
    "# Band ID for each G-point\n",
    "bandID = range(1, nBnds+1)\n",
    "bandID = np.repeat(bandID, nGptsPerBandOrg)\n",
    "\n",
    "# G-point weights (same for all bands)\n",
    "# expand weights for one band to the rest of the bands with np.tile\n",
    "# so weights are an (nGpt x nBnds)-element vector\n",
    "# a \n",
    "wtORG = [0.1527534276, 0.1491729617, 0.1420961469, 0.1316886544, \n",
    "         0.1181945205, 0.1019300893, 0.0832767040, 0.0626720116, \n",
    "         0.0424925000, 0.0046269894, 0.0038279891, 0.0030260086, \n",
    "         0.0022199750, 0.0014140010, 0.0005330000, 0.0000750000]\n",
    "wt = np.tile(wtORG, nBnds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RRTMGP File Staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/global/homes/p/pernak18/RRTMGP/g-point-reduction/intermediate_files/data_bnd2/lw.cost05.norm2//rrtmgp-data-lw-g256-2018-12-04.nc'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare input file\n",
    "file_rrtmgp_input = \"{}/input/rte_rrtmgp_input_{}.nc\".format(\n",
    "    dirData, DOMAIN)\n",
    "os.makedirs(os.path.dirname(file_rrtmgp_input), exist_ok=True)\n",
    "prepare_input(file_LBLRTM, file_rrtmgp_input)\n",
    "\n",
    "# Create output directory\n",
    "file_rrtmgp_output = \"{}/fluxes/rte_rrtmgp_output_{}.nc\".format(\n",
    "    dirData, DOMAIN)\n",
    "os.makedirs(os.path.dirname(file_rrtmgp_output), exist_ok=True)\n",
    "\n",
    "# copy original k-dist file\n",
    "shutil.copy2('{}/{}'.format(file_coeffORG_dir, file_coeffORG), \n",
    "             '{}/{}'.format(dirData, file_coeffORG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial RRTMGP Fluxes (With Original _k_-distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/homes/p/pernak18/RRTMGP/g-point-reduction/intermediate_files/results_bnd2/lw.cost05.norm2/ /global/u1/p/pernak18/RRTMGP/g-point-reduction/intermediate_files/results_bnd2/lw.cost05.norm2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./test_garand', '--no-longwave', '--output-bnd-fluxes'], returncode=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(dirRes)\n",
    "link_rrtmgp()\n",
    "\n",
    "shutil.copy2('{}/{}'.format(dirData, file_coeffORG), \n",
    "             \"coefficients_{}.nc\".format(DOMAIN))\n",
    "\n",
    "for icase in FRANGE: \n",
    "    shutil.copy2(file_rrtmgp_input, './rte_rrtmgp_input_{}.nc'.format(icase))\n",
    "\n",
    "shutil.copy2(file_rrtmgp_input, './')\n",
    "subprocess.run([\"./test_garand\", \"--no-{}\".format(DOMAINL), \\\n",
    "                \"--output-bnd-fluxes\"]+(['--forcing'] if FORCING else []))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_rrtmgp_ref = dirRes + \"fluxes/reference_kdist_fluxes.nc\"\n",
    "\n",
    "# location of `ncecat` NCO (netCDF Operators) executable on \n",
    "# NERSC machines (module load nco)\n",
    "subprocess.run(['/global/common/sw/cray/cnl7/haswell/nco/' + \\\n",
    "                '4.7.9/gcc/8.3.0/bz3muff/bin/ncecat'] + \\\n",
    "               ['rte_rrtmgp_output_{}.nc'.format(i) for i in FRANGE] + \\\n",
    "               ['-u', 'record', '-O', file_rrtmgp_ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/global/homes/p/pernak18/RRTMGP/g-point-reduction/intermediate_files/results_bnd2/sw.cost05.norm2/fluxes/reference_kdist_fluxes.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-c003b1b0fff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         RV.get_fluxes(file_LBLRTM), p_lev, ICOST)\n\u001b[1;32m     16\u001b[0m     cf_frst = CF.cost_function_from_error(\n\u001b[0;32m---> 17\u001b[0;31m         CF.flux_heat_errors(file_rrtmgp_ref, file_LBLRTM), p_lev, ICOST)\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mcf_norm_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalized_costs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcf_frst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcf_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mERRTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mwinner_err_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflux_heat_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_rrtmgp_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_LBLRTM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RRTMGP/g-point-reduction/k-distribution-opt/cost_function.py\u001b[0m in \u001b[0;36mflux_heat_errors\u001b[0;34m(tst_file, ref_file, levs)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# calculate errors of radiative fluxes and derivaed quantities (tst_file-ref_file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m###############\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/global/homes/p/pernak18/RRTMGP/g-point-reduction/intermediate_files/results_bnd2/sw.cost05.norm2/fluxes/reference_kdist_fluxes.nc'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "for icase in FRANGE:\n",
    "    #os.remove('rte_rrtmgp_output_{}.nc'.format(icase))\n",
    "    #os.remove('rte_rrtmgp_input_{}.nc'.format(icase))\n",
    "    os.remove('rte_rrtmgp_input_{}.nc'.format(DOMAIN))\n",
    "'''\n",
    "os.chdir(kDistOptPath)\n",
    "\n",
    "if ERRTYPE == 1:\n",
    "    cf_norm = CF.cost_function_from_error(\n",
    "        CF.flux_heat_errors(file_rrtmgp_ref, file_LBLRTM), p_lev, ICOST)\n",
    "    cf_norm_norm = CF.normalized_costs(cf_norm, cf_norm, ERRTYPE)\n",
    "elif ERRTYPE == 2 or ERRTYPE == 0:\n",
    "    cf_norm = RV.reference_values(\n",
    "        RV.get_fluxes(file_LBLRTM), p_lev, ICOST)\n",
    "    cf_frst = CF.cost_function_from_error(\n",
    "        CF.flux_heat_errors(file_rrtmgp_ref, file_LBLRTM), p_lev, ICOST)\n",
    "    cf_norm_norm = CF.normalized_costs(cf_frst, cf_norm, ERRTYPE)\n",
    "winner_err_old = CF.flux_heat_errors(file_rrtmgp_ref, file_LBLRTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy Optimization of Cost Function\n",
    "\n",
    "Lots of things going on here, maybe break it up into more sections\n",
    "\n",
    "Also need to make the calculations more transparent for Eli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization iterations\n",
    "nOptIt = 210\n",
    "print(f'Combining g-point pairs {nOptIt} times...'); sys.stdout.flush()\n",
    "\n",
    "# Store cost of reference (original k-distribution)\n",
    "all_costs = np.zeros((len(names)+1, nOptIt+1))\n",
    "all_bands = np.zeros((nOptIt))\n",
    "all_gpts  = np.zeros((2,nOptIt))\n",
    "print('For iteration 000, combined nothing yet')\n",
    "all_costs[:, 0] = process_costs(cf_norm_norm)\n",
    "\n",
    "############################################\n",
    "# First iteration: outside main loop\n",
    "############################################\n",
    "gpt_list = [[x,x+1] for x in range(1, nGpt) if bandID[x-1] == bandID[x]][:]\n",
    "wgt_list = [(wt[gpt_pair[0]-1], wt[gpt_pair[1]-1]) for gpt_pair in gpt_list][:]\n",
    "gpt_arr = np.array(gpt_list)[:,0]\n",
    "\n",
    "file_coeffFromPreviousIteration = file_coeffORG\n",
    "file_coeff = dirData + file_coeffFromPreviousIteration\n",
    "\n",
    "# Compute and store error terms for each combination of adjacent g-points pairs\n",
    "# call `trial_cost_function` multiple times in parallel (\"pool\" the processes)\n",
    "error_dict = multiprocessing.Manager().dict()\n",
    "with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n",
    "    # separate processes, each with their own arguments\n",
    "    res = [pool.apply_async(trial_cost_function, \n",
    "           args = (1, dirRes, dirData, file_coeff, \n",
    "                  gpt_pair, wgt_pair, file_LBLRTM, \n",
    "                  cf_norm, error_dict, THERMAL, FORCING)) \\\n",
    "           for gpt_pair, wgt_pair in zip(gpt_list, wgt_list)]\n",
    "    temp  = [r.get() for r in res]\n",
    "\n",
    "# Greedy optimization: which g-point combination has the smallest error?\n",
    "cost_list = [cf.normalized_costs(cf.cost_function_from_error(\n",
    "    error_dict[i], p_lev, ICOST), cf_norm, ERRTYPE) for i in gpt_arr]\n",
    "winner_idx = np.argmin([cf.total_cost(i) for i in cost_list])\n",
    "winner_err = error_dict[gpt_list[winner_idx][0]]\n",
    "\n",
    "# Set the new coefficent file for the next iteration.\n",
    "file_coeffFromPreviousIteration = 'coefficients_{0}.nc'.format(\n",
    "    make_name_variant(1, gpt_list[winner_idx]))\n",
    "shutil.copy2('{}/coeffs/{}'.format(dirRes, file_coeffFromPreviousIteration), \n",
    "             '{}/{}'.format(dirData, file_coeffFromPreviousIteration))\n",
    "\n",
    "# Remove temporary files\n",
    "remove_temp_files(dirRes)\n",
    "\n",
    "#process costs\n",
    "g_out = int(gpt_list[winner_idx][0])\n",
    "all_bands[0]   = bandID[g_out]\n",
    "all_gpts [:,0] = gpt_list[winner_idx]\n",
    "all_costs[:,1] = process_costs(cost_list[winner_idx])\n",
    "\n",
    "# Modify the weights the g-point arrays\n",
    "wt, bandID, nGpt, gpt_arr_old = modify_wt_gpt(g_out, wt, bandID, nGpt, gpt_arr)\n",
    "print('For iteration 001, ', end='')\n",
    "print('combining g-points {0[0]:03d} and {0[1]:03d} in band {1:02d}'.format(\n",
    "    gpt_list[winner_idx], bandID[g_out-1]))\n",
    "print(\"New coefficient file: \", file_coeffFromPreviousIteration)\n",
    "\n",
    "# now perform the rest of the iterations\n",
    "for iiter in range(nOptIt-1):\n",
    "    iMain = iiter + 2\n",
    "\n",
    "    # Which coefficient file to use? On first iteration, this is original \n",
    "    # coefficient file\n",
    "    file_coeff = '{}/{}'.format(dirData, file_coeffFromPreviousIteration)\n",
    "    \n",
    "    # Create list of all adjacent g-point pairs in each band\n",
    "    gpt_list = [[x,x+1] for x in range(1,nGpt) if \\\n",
    "                bandID[x-1] == bandID[x]][:]\n",
    "    wgt_list = [(wt[gpt_pair[0]-1],wt[gpt_pair[1]-1]) for \\\n",
    "                gpt_pair in gpt_list][:]\n",
    "    gpt_arr = np.array(gpt_list)[:,0]\n",
    "    gpt_win = gpt_arr[winner_idx-1:winner_idx+1]\n",
    "    los_arr = np.delete(\n",
    "        gpt_arr, [winner_idx-1] + [winner_idx] * (winner_idx<len(gpt_arr)))\n",
    "\n",
    "    #rearrange error dict\n",
    "    error_dict.pop(g_out)\n",
    "    for igpt in range(winner_idx,len(gpt_arr)):\n",
    "        error_dict[gpt_arr[igpt]] = error_dict.pop(gpt_arr_old[igpt+1])\n",
    "    \n",
    "    ### Compute error terms for each combination of adjacent g-points pairs\n",
    "    # recompute with rte+rrtmgp\n",
    "    with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n",
    "        res = [pool.apply_async(trial_cost_function, \n",
    "               args = (iMain, dirRes, dirData, file_coeff, \n",
    "                      gpt_pair, wgt_pair, file_LBLRTM, \n",
    "                      cf_norm, error_dict, THERMAL, FORCING)) \\\n",
    "               for gpt_pair, wgt_pair in zip(\n",
    "                      gpt_list[winner_idx-1:winner_idx+1], \n",
    "                      wgt_list[winner_idx-1:winner_idx+1])]\n",
    "        temp  = [r.get() for r in res]\n",
    "\n",
    "    # Add errors from previous iteration\n",
    "    with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n",
    "        res = [pool.apply_async(append_errors, args = \\\n",
    "              (idx, error_dict, winner_err, winner_err_old)) for idx in los_arr]\n",
    "        temp  = [r.get() for r in res]\n",
    "    cost_list = [cf.normalized_costs(cf.cost_function_from_error(\n",
    "        error_dict[i], p_lev, ICOST), cf_norm, ERRTYPE) for i in gpt_arr]\n",
    "    \n",
    "    # Greedy optimization: which g-point combination has the smallest error?\n",
    "    winner_idx = np.argmin([cf.total_cost(i) for i in cost_list])\n",
    "\n",
    "    # New reference errors\n",
    "    winner_err_old = winner_err\n",
    "    winner_err = error_dict[gpt_list[winner_idx][0]]\n",
    "    \n",
    "    # Set the new coefficent file for the next iteration.\n",
    "    file_coeff_new = 'coefficients_{0}.nc'.format(\n",
    "        make_name_variant(iMain, gpt_list[winner_idx]))\n",
    "    if gpt_list[winner_idx][0] not in gpt_win: \n",
    "        combine_gpoints_fn(file_coeff, '{}/coeffs/{}'.format(\n",
    "            dirRes, file_coeff_new, gpt_list[winner_idx], wgt_list[winner_idx])\n",
    "        \n",
    "    file_coeffFromPreviousIteration = file_coeff_new\n",
    "    shutil.copy2('{}/coeffs/{}'.format(dirRes, file_coeffFromPreviousIteration), \n",
    "                 '{}/{}'.format(dirData, file_coeffFromPreviousIteration))\n",
    "    \n",
    "    # Remove temporary files\n",
    "    remove_temp_files(dirRes)\n",
    "\n",
    "    # Process costs\n",
    "    g_out = int(gpt_list[winner_idx][0])\n",
    "    all_bands[iMain-1] = bandID[g_out]\n",
    "    all_gpts [:,iMain-1] = gpt_list[winner_idx]\n",
    "    all_costs[:,iMain] = process_costs(cost_list[winner_idx])\n",
    "    \n",
    "    # Modify the weights the g-point arrays\n",
    "    wt, bandID, nGpt, gpt_arr_old = \\\n",
    "        modify_wt_gpt(g_out, wt, bandID, nGpt, gpt_arr)\n",
    "    print('For iteration {0:03d}, '.format(iMain), end='')\n",
    "    print('combining g-points {0[0]:03d} and {0[1]:03d} in band {1:02d}'.format(\n",
    "        iMain, gpt_list[winner_idx], bandID[g_out-1]))\n",
    "    print('New coefficient file: {}'.format(file_coeffFromPreviousIteration))\n",
    "    \n",
    "write_cost_nc(all_bands, all_gpts, all_costs, names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
