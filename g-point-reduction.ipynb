{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RRTMGP _g_-Point Reduction With Cost Function Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard modules\n",
    "import os, sys, shutil, subprocess, time, multiprocessing\n",
    "\n",
    "# pip installs\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "\n",
    "# local module paths\n",
    "HOME = '/global/homes/p/pernak18'\n",
    "GPTHOME = '{}/RRTMGP/g-point-reduction'.format(HOME)\n",
    "PINCUSPATH = '{}/obsolete/pincus_k-distribution-opt'.format(GPTHOME)\n",
    "LIBPATHS = [PINCUSPATH, \n",
    "            '{}/k-distribution-opt'.format(GPTHOME), \n",
    "            '{}/.local/'.format(HOME) + \\\n",
    "            'cori/3.7-anaconda-2019.10/lib/python3.7/site-packages']\n",
    "for path in LIBPATHS: sys.path.append(path)\n",
    "\n",
    "# local modules\n",
    "from combine_gpoints_fn import combine_gpoints_fn\n",
    "#from prepare_cpp_input import prepare_input\n",
    "import cost_function as CF\n",
    "import ref_values as RV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathCheck(path):\n",
    "    \"\"\"\n",
    "    Determine if file exists. If not, throw an Assertion Exception\n",
    "    \"\"\"\n",
    "\n",
    "    assert os.path.exists(path), 'Could not find {}'.format(path)\n",
    "    \n",
    "def link_rrtmgp(rrtmgpPath=\"{}/rte-rrtmgp-cpp\".format(GPTHOME), \n",
    "                exe='./test_garand', \n",
    "                coeffSW='rrtmgp-data-sw-g224-2018-12-04.nc', \n",
    "                coeffLW='rrtmgp-data-lw-g256-2018-12-04.nc', \n",
    "                cloudSW='rrtmgp-cloud-optics-coeffs-sw.nc', \n",
    "                cloudLW='rrtmgp-cloud-optics-coeffs-lw.nc'):\n",
    "\n",
    "    \"\"\"\n",
    "    File staging for RRTMGP\n",
    "    \n",
    "    Call\n",
    "        \n",
    "    Inputs\n",
    "        fThermal -- int, optimize LW k-distribution\n",
    "    \n",
    "    Outputs\n",
    "        None\n",
    "\n",
    "    Keywords\n",
    "        rrtmgpPath -- string, top-level directory with RRTMGP code\n",
    "        exe -- string, \n",
    "            absolete path to RRTMGP LW/SW solver (flux calulation) executable\n",
    "        coeffSW -- string, \n",
    "            basename of file with SW absorption coefficients for clear skies\n",
    "        coeffLW -- string, \n",
    "            basename of file with LW absorption coefficients for clear skies\n",
    "        cloudSW -- string, \n",
    "            basename of file with SW absorption coefficients with clouds\n",
    "        cloudLW -- string,\n",
    "            basename of file with LW absorption coefficients with clouds\n",
    "    \"\"\"\n",
    "    \n",
    "    #buildDir = '{}/build'.format(rrtmgpPath)\n",
    "    coeffDir = '{}/rte-rrtmgp/rrtmgp/data'.format(rrtmgpPath)\n",
    "    cloudDir = '{}/rte-rrtmgp/extensions/cloud_optics'.format(rrtmgpPath)\n",
    "\n",
    "    paths = [exe, coeffDir, cloudDir, \n",
    "             '{}/{}'.format(coeffDir, coeffSW), \n",
    "             '{}/{}'.format(coeffDir, coeffLW), \n",
    "             '{}/{}'.format(cloudDir, cloudSW), \n",
    "             '{}/{}'.format(cloudDir, cloudLW)]\n",
    "    for path in paths: pathCheck(path)\n",
    "\n",
    "    exeBase = os.path.basename(exe)\n",
    "    if not os.path.exists(exeBase): os.symlink(exe, exeBase)\n",
    "\n",
    "    swTarget = 'coefficients_sw.nc'\n",
    "    # Pernak: reverse the logic here? done\n",
    "    if not os.path.exists(swTarget) and not THERMAL:\n",
    "        os.symlink('{}/{}'.format(coeffDir, coeffSW), swTarget)\n",
    "\n",
    "    lwTarget = 'coefficients_lw.nc'\n",
    "    # Pernak: reverse the logic here? done\n",
    "    if not os.path.exists(lwTarget) and THERMAL: \n",
    "        os.symlink('{}/{}'.format(coeffDir, coeffLW), lwTarget)\n",
    "\n",
    "    swTarget = 'cloud_coefficients_sw.nc'\n",
    "    if not os.path.exists(swTarget):\n",
    "        os.symlink('{}/{}'.format(cloudDir, cloudSW), swTarget)\n",
    "\n",
    "    lwTarget = 'cloud_coefficients_lw.nc'\n",
    "    if not os.path.exists(lwTarget):\n",
    "        os.symlink('{}/{}'.format(cloudDir, cloudLW), lwTarget)\n",
    "\n",
    "def process_costs(components):\n",
    "    totCost = CF.total_cost(components)\n",
    "    print(\"Total cost: {}\".format(totCost))\n",
    "    return np.append(components, totCost)\n",
    "\n",
    "def append_errors(idx, errorDict, errWin, errOld):\n",
    "    data = [errorDict[idx][0] + errWin[0] - errOld[0], \n",
    "            errorDict[idx][1] + errWin[1] - errOld[1]]\n",
    "    errorDict[idx] = list(data)\n",
    "    return([0]) \n",
    "\n",
    "def modify_wt_gpt(gOut, wt, bandID, nGpt, gptArr):\n",
    "    wt[gOut-1] = wt[gOut-1]+wt[gOut]\n",
    "    wt = np.delete(wt, gOut)\n",
    "    bandID = np.delete(bandID, gOut)\n",
    "    return wt, bandID, nGpt-1, gptArr.copy()\n",
    "\n",
    "def remove_temp_files(dirRes):\n",
    "    for d in ['{}/coeffs'.format(dirRes), '{}/fluxes'.format(dirRes)]:\n",
    "        for f in os.listdir(d): \n",
    "            if not f.startswith(\"temp\"):\n",
    "                os.remove(os.path.join(d, f))\n",
    "\n",
    "def write_cost_nc(dirOut, allBands, allGpts, allCosts, names, \n",
    "                  icost=2, f_thermal=False, f_errtype=5):\n",
    "\n",
    "    ncFile = \"{}/optimisation_output.{}.cost{:02d}.norm{:01d}.bnd{:02d}.nc\".format(\n",
    "        dirOut, 'lw' if f_thermal else 'sw', icost, f_errtype, bands[0])\n",
    "    os.makedirs(os.path.dirname(ncFile), exist_ok=True)\n",
    "    dataOut = nc.Dataset(ncFile, 'w')\n",
    "    \n",
    "    dataOut.createDimension(\"n_name\", len(names))\n",
    "    dataOut.createDimension(\"pair\", 2)\n",
    "    dataOut.createDimension(\"n_iter\", allGpts.shape[1])\n",
    "    dataOut.createDimension(\"t_iter\", allGpts.shape[1]+1)\n",
    "\n",
    "    gptsOut  = data_out.createVariable(\n",
    "        \"combined_gpt_pair\", \"f4\", (\"pair\", \"n_iter\"))\n",
    "    bandOut  = data_out.createVariable(\n",
    "        \"combined_band\", \"f4\", (\"n_iter\"))\n",
    "    costOut  = data_out.createVariable(\n",
    "        \"cost_components\", \"f4\", (\"n_name\", \"t_iter\"))\n",
    "    ctotOut  = data_out.createVariable(\n",
    "        \"total_cost\", \"f4\", (\"t_iter\"))\n",
    "    nameOut  = data_out.createVariable(\n",
    "        \"names\", str, (\"n_name\"))\n",
    "    \n",
    "    gptsOut[:] = all_gpts\n",
    "    bandOut[:] = all_bands\n",
    "    costOut[:] = all_costs[:-1]\n",
    "    ctotOut[:] = all_costs[-1]\n",
    "    for i in range(len(names)): nameOut[i] = names[i]\n",
    "    \n",
    "    dataOut.close()\n",
    "\n",
    "def make_name_variant(iterNum, gpts):\n",
    "    # Return string of form iterNNN.GGG.GGG,\n",
    "    #   iterNum is a scalar int, gpts is list of ints of length 2\n",
    "    return('iter{0:03d}.{1[0]:03d}.{1[1]:03d}'.format(iterNum, gpts))\n",
    "\n",
    "def trial_cost_function(iterNum, dirRes, dirData, \n",
    "                        start_kdist_file, gpts, wts, \n",
    "                        ref_flux_file, cf_norm, flux_data, \n",
    "                        f_thermal=False, f_forcing=False, \n",
    "                        exe='./rrtmgp_garand_atmos'):\n",
    "\n",
    "    # Return the terms in the cost function for a proposed \n",
    "    # combination of two gpoints from an initial set\n",
    "    trial_kdist_file = '{}/coeffs/coefficients_{}.nc'.format(\n",
    "        dirRes, make_name_variant(iterNum, gpts))\n",
    "    trial_flux_file  = '{}/fluxes/fluxes.all.{}.nc'.format(\n",
    "        dirRes, make_name_variant(iterNum, gpts))\n",
    "    \n",
    "    # Make sure directories exist\n",
    "    os.makedirs(os.path.dirname(trial_kdist_file), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(trial_flux_file), exist_ok=True)\n",
    "\n",
    "    # Combine the pair of g-points specified in gpts(2) with weights wts(2)\n",
    "    combine_gpoints_fn(start_kdist_file, trial_kdist_file, gpts, wts)\n",
    "    \n",
    "    # create and go to temporary dir\n",
    "    output_path = '{}/fluxes/temp_{}/'.format(\n",
    "        dirRes, make_name_variant(iterNum, gpts))\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    os.chdir(output_path)\n",
    "\n",
    "    # stage trial coefficient files\n",
    "    domain = 'lw' if f_thermal else 'sw'\n",
    "    link_rrtmgp(exe=EXE)\n",
    "    file_rrtmgp_output = \"rte_rrtmgp_output_{}.nc\".format(domain)\n",
    "    file_rrtmgp_input = \"{}/input/rte_rrtmgp_input_{}.nc\".format(\n",
    "        dirData, domain)\n",
    "    coeffStage = \"coefficients_{}.nc\".format(domain)\n",
    "    shutil.copy2(trial_kdist_file, coeffStage)\n",
    "\n",
    "    # link input files\n",
    "    for icase in FRANGE: shutil.copy2(file_rrtmgp_input.format(icase), './')\n",
    "    \n",
    "    # run and combine fluxes\n",
    "    subprocess.run([exe, file_rrtmgp_input, coeffStage])\n",
    "    os.rename(file_rrtmgp_input, trial_flux_file)\n",
    "    \"\"\"\n",
    "    subprocess.run([\"./test_garand\", \n",
    "                    \"--no-{}\".format('shortwave' if f_thermal else 'longwave'), \n",
    "                    \"--output-bnd-fluxes\"] + \\\n",
    "                   (['--forcing'] if f_forcing else []))\n",
    "\n",
    "    subprocess.run(['/global/common/sw/cray/cnl7/haswell/nco/' + \\\n",
    "                    '4.7.9/gcc/8.3.0/bz3muff/bin/ncecat'] + \\\n",
    "                   [file_rrtmgp_output.format(i) for i in fRange] + \\\n",
    "                   [\"-u\", \"record\", \"-O\", trial_flux_file])\n",
    "    \"\"\"\n",
    "\n",
    "    os.chdir(kDistOptPath)\n",
    "    shutil.rmtree(output_path)\n",
    "    \n",
    "    # Return the cost function components normalized by error at iteration 0\n",
    "    flux_data[gpts[0]] = CF.cost_function_components(trial_flux_file, ref_flux_file)\n",
    "    return([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, there are 8 different cost functions that can be minimized. The default is 5, but other options for `icost` (type `int`) are:\n",
    "  1. \n",
    "  2. \n",
    "  3. \n",
    "  4. \n",
    "  5. \n",
    "  6. \n",
    "  7. \n",
    "  8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables in cost function: sfc_flux\n"
     ]
    }
   ],
   "source": [
    "# Global variable definition of the cost function type\n",
    "ICOST = 5\n",
    "\n",
    "if ICOST == 1: \n",
    "    names = ['dn_bnd_lwr', 'up_bnd_lwr', 'nt_bnd_lw', 'dn_tot_lwr', 'up_tot_lwr', 'nt_tot_lwr', 'heat_lwr', \n",
    "             'dn_bnd_upr', 'up_bnd_upr', 'nt_bnd_up', 'dn_tot_upr', 'up_tot_upr', 'nt_tot_upr', 'heat_upr']\n",
    "elif ICOST == 2:\n",
    "    names = ['nt_bnd_lw', 'nt_tot_lwr', 'heat_lwr', 'nt_bnd_up', 'nt_tot_upr', 'heat_upr']\n",
    "elif ICOST == 3:\n",
    "    names = ['nt_bnd_lwr', 'nt_tot_lwr', 'heat_lwr']\n",
    "elif ICOST == 4:\n",
    "    names = ['nt_bnd_upr', 'nt_tot_upr', 'heat_upr']\n",
    "elif ICOST == 5:\n",
    "    names = ['sfc_flux']\n",
    "elif ICOST == 6:\n",
    "    names = ['heat_lwr', 'heat_upr', 'sfc_flux']\n",
    "elif ICOST == 7:\n",
    "    names = ['sfc_flux_dn', 'trp_flx_dn', 'trp_flx_up', 'toa_flx_up']\n",
    "elif ICOST == 8:\n",
    "    names = ['heat_thermo']\n",
    "else:\n",
    "    print('INVALID COST FUNCTION')\n",
    "    \n",
    "print('Variables in cost function: {}'.format(', '.join(names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Global Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define what kind of normalization `f_errtype` (type `int`) will be applied to the cost function:\n",
    "\n",
    "  0. absolute error (RMSE)\n",
    "  1. change in RMSE with respect to RMSE at iteration 0\n",
    "  2. error w.r.t. LBLRTM (normalized rmse)\n",
    "\n",
    "Whether the _k_-distribution optimization is done in the longwave or shortwave domain is specified with `f_thermal` (type `bool`). This is important for filename specifications. Forcing has not been implemented in this notebook, so it should **always** be set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERRTYPE = 2\n",
    "THERMAL = True\n",
    "FORCING = False\n",
    "FRANGE = range(1+6*(THERMAL and FORCING))\n",
    "DOMAIN = 'lw' if THERMAL else 'sw'\n",
    "DOMAINL = 'longwave' if THERMAL else 'shortwave'\n",
    "EXE = '{}/rrtmgp_garand_atmos'.format(PINCUSPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the executable is the [FORTRAN-based](https://github.com/RobertPincus/k-distribution-opt/blob/brhillman/dev/rrtmgp_garand_atmos.F90) `rrtmgp_garand_atmos` rather than the [C++-based](https://github.com/MennoVeerman/k-distribution-opt/blob/master/test_garand.cpp) `test_garand`. The latter was yielding `Segmentation Faults` at runtime on the NERSC `cori` machine and thus was not producing the results that were needed for the rest of the optimization. Because of these errors, we pursue the \"Hillman\" method in the rest of this notebook, while attempting to fold in the enhancements from Menno, which include cost function flexibility and diagnostics plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "kDistOptPath = LIBPATHS[0] # path of k-distribution directory (originally `bpath`)\n",
    "pathCheck(kDistOptPath)\n",
    "\n",
    "# where to save coeff and temporary flux files (originally `dpath`)\n",
    "outDatPath = '{}/intermediate_files'.format(GPTHOME)\n",
    "if not os.path.isdir(outDatPath): os.makedirs(outDatPath)\n",
    "\n",
    "#file_LBLRTM = '{}/lbl_reference_{}.nc'.format(kDistOptPath, DOMAINL)\n",
    "# newest reference file provided by Robert (with `record` dimension)\n",
    "projectDir = '/project/projectdirs/e3sm/pernak18/inputs/g-point-reduce'\n",
    "file_LBLRTM = '{}/lblrtm-{}-flux-inputs-outputs-garandANDpreind.nc'.format(\n",
    "    projectDir, DOMAIN)\n",
    "\n",
    "# RRTMGP coefficient file\n",
    "file_coeffORG = 'rrtmgp-data-lw-g256-2018-12-04.nc' if THERMAL else \\\n",
    "    'rrtmgp-data-sw-g224-2018-12-04.nc'\n",
    "file_coeffORG_dir = '{}/obsolete/rte-rrtmgp/rrtmgp/data/'.format(\n",
    "    GPTHOME)\n",
    "pathCheck(file_coeffORG_dir)\n",
    "\n",
    "# Directory where new fluxes and coefficient files are stored.\n",
    "dirOut  = '{}/outputs_bnd2'.format(outDatPath)\n",
    "dirRes  = \"{}/results_bnd2/{}.cost{:02d}.norm{:01d}/\".format(\n",
    "    outDatPath, DOMAIN, ICOST, ERRTYPE)\n",
    "dirData = \"{}/data_bnd2/{}.cost{:02d}.norm{:01d}/\".format(\n",
    "    outDatPath, DOMAIN, ICOST, ERRTYPE)\n",
    "PATHS = [dirOut, dirRes, dirData]\n",
    "for path in PATHS:\n",
    "    if not os.path.isdir(path): os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime Variables Definition, Extract Information from LBLRTM Reference Results\n",
    "\n",
    "We will use the pressures that were input into LBLRTM. `p_lev` is a (1 x 43 x 42) array, so we are extracting the entire pressure profile of the first Garand atmosphere (in descending order, so surface-to-TOA).\n",
    "\n",
    "The number of _g_-points can be extracted from the LBL netCDF as well. The weights associated with each _g_-point are the same for each band, so we effectively produce an `nGpt`x`nBnds` array, then flatten it to a 1-D vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pressures (1D)\n",
    "p_lev = nc.Dataset(file_LBLRTM).variables['p_lev'][0,:,0]\n",
    "\n",
    "# Initial settings.\n",
    "# Todo: generalize, read values from coefficient file\n",
    "# Number of bands\n",
    "nBnds = len(nc.Dataset(file_LBLRTM).variables['band'][:])\n",
    "\n",
    "# Number of G-points in each band.\n",
    "nGptsPerBandOrg = 16\n",
    "\n",
    "# Number of G-points\n",
    "nGpt = nBnds * nGptsPerBandOrg\n",
    "\n",
    "# optimization iterations\n",
    "nOptIt = 210\n",
    "\n",
    "# Band ID for each G-point\n",
    "bandID = range(1, nBnds+1)\n",
    "bandID = np.repeat(bandID, nGptsPerBandOrg)\n",
    "\n",
    "# G-point weights (same for all bands)\n",
    "# expand weights for one band to the rest of the bands with np.tile\n",
    "# so weights are an (nGpt x nBnds)-element vector\n",
    "# a \n",
    "wtORG = [0.1527534276, 0.1491729617, 0.1420961469, 0.1316886544, \n",
    "         0.1181945205, 0.1019300893, 0.0832767040, 0.0626720116, \n",
    "         0.0424925000, 0.0046269894, 0.0038279891, 0.0030260086, \n",
    "         0.0022199750, 0.0014140010, 0.0005330000, 0.0000750000]\n",
    "wt = np.tile(wtORG, nBnds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RRTMGP File Staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/global/homes/p/pernak18/RRTMGP/g-point-reduction/intermediate_files/data_bnd2/lw.cost05.norm2//rrtmgp-data-lw-g256-2018-12-04.nc'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare input file\n",
    "file_rrtmgp_input = \"{}/input/rte_rrtmgp_input_{}.nc\".format(\n",
    "    dirData, DOMAIN)\n",
    "os.makedirs(os.path.dirname(file_rrtmgp_input), exist_ok=True)\n",
    "#prepare_input(file_LBLRTM, file_rrtmgp_input)\n",
    "\n",
    "# Create output directory\n",
    "file_rrtmgp_output = \"{}/fluxes/rte_rrtmgp_output_{}.nc\".format(\n",
    "    dirData, DOMAIN)\n",
    "os.makedirs(os.path.dirname(file_rrtmgp_output), exist_ok=True)\n",
    "\n",
    "# copy original k-dist file\n",
    "shutil.copy2('{}/{}'.format(file_coeffORG_dir, file_coeffORG), \n",
    "             '{}/{}'.format(dirData, file_coeffORG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial RRTMGP Fluxes (With Original _k_-distribution)/Reference Fluxes\n",
    "\n",
    "Stage some more files into a working directory (where the model is run over many iterations), then perform an initial run of RRTMGP over all Garand atmospheres. `returncode` of 0 means success. Be leery of other return codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/global/homes/p/pernak18/RRTMGP/g-point-reduction/obsolete/pincus_k-distribution-opt/rrtmgp_garand_atmos', 'rte_rrtmgp_input-output_0.nc', 'coefficients_lw.nc'], returncode=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(dirRes)\n",
    "\n",
    "# copy k-distribution and profile information files to working dir\n",
    "# we are using Robert's LBL reference file for the latter\n",
    "# https://github.com/RobertPincus/k-distribution-opt/blob/master/lblrtm-lw-flux-inputs-outputs-garandANDpreind.nc\n",
    "coeffNC = 'coefficients_{}.nc'.format(DOMAIN)\n",
    "shutil.copy2('{}/{}'.format(dirData, file_coeffORG), coeffNC)\n",
    "inNC = 'rte_rrtmgp_input-output_0.nc'\n",
    "shutil.copy2(file_LBLRTM, './{}'.format(inNC))\n",
    "\n",
    "# run Robert's version of `test_garand`\n",
    "subprocess.run([EXE, inNC, coeffNC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('{}/fluxes'.format(dirRes)):\n",
    "    os.makedirs('{}/fluxes'.format(dirRes))\n",
    "\n",
    "file_rrtmgp_ref = dirRes + \"fluxes/reference_kdist_fluxes.nc\"\n",
    "os.rename(inNC, file_rrtmgp_ref)\n",
    "\n",
    "# location of `ncecat` NCO (netCDF Operators) executable on \n",
    "# NERSC machines (module load nco)\n",
    "# Robert's LBLRTM reference file already has a `record` dimension, \n",
    "# so this `ncecat` does not need to be done\n",
    "# subprocess.run(['/global/common/sw/cray/cnl7/haswell/nco/' + \\\n",
    "#                 '4.7.9/gcc/8.3.0/bz3muff/bin/ncecat'] + \\\n",
    "#                ['rte_rrtmgp_output_{}.nc'.format(i) for i in FRANGE] + \\\n",
    "#                ['-u', 'record', '-O', file_rrtmgp_ref])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(kDistOptPath)\n",
    "# think about a way to incorporate Robert's \n",
    "# https://github.com/RobertPincus/k-distribution-opt/blob/master/cost_function_2.py\n",
    "\"\"\"\n",
    "if ERRTYPE == 1:\n",
    "    cf_norm = CF.cost_function_from_error(\n",
    "        CF.flux_heat_errors(file_rrtmgp_ref, file_LBLRTM), p_lev, ICOST)\n",
    "    cf_norm_norm = CF.normalized_costs(cf_norm, cf_norm, ERRTYPE)\n",
    "elif ERRTYPE == 2 or ERRTYPE == 0:\n",
    "    cf_norm = RV.reference_values(\n",
    "        RV.get_fluxes(file_LBLRTM), p_lev, ICOST)\n",
    "    cf_frst = CF.cost_function_from_error(\n",
    "        CF.flux_heat_errors(file_rrtmgp_ref, file_LBLRTM), p_lev, ICOST)\n",
    "    cf_norm_norm = CF.normalized_costs(cf_frst, cf_norm, ERRTYPE)\n",
    "winner_err_old = CF.flux_heat_errors(file_rrtmgp_ref, file_LBLRTM)\n",
    "\"\"\"\n",
    "cf_norm = CF.cost_function_components(file_rrtmgp_ref, file_LBLRTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Initialization for Greedy Optimization of Cost Function\n",
    "\n",
    "Need to make the calculations more transparent for Eli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hillman Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-51-7c022bc00483>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-51-7c022bc00483>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    cf_norm, error_dict, THERMAL, FORCING, exe=EXE)) \\\u001b[0m\n\u001b[0m                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# On first iteration, coefficients file is the original one\n",
    "shutil.copy2('{}/{}'.format(file_coeffORG_dir, file_coeffORG), \n",
    "             'data/{}'.format(file_coeffORG))\n",
    "file_coeffFromPreviousIteration = str(file_coeffORG)\n",
    "\n",
    "print(f'Combining g-point pairs {nOptIt} times...'); sys.stdout.flush()\n",
    "\n",
    "error_dict = multiprocessing.Manager().dict()\n",
    "for iMain in range(1,nOptIt):\n",
    "    # Which coefficient file to use? \n",
    "    file_coeff = 'data/'+file_coeffFromPreviousIteration\n",
    "    pathCheck(file_coeff)\n",
    "\n",
    "    # Create list of all adjacent g-point pairs in each band\n",
    "    gpt_list = [[x,x+1] for x in range(1,nGpt) if bandID[x-1] == bandID[x]]\n",
    "    wgt_list = [(wt[gpt_pair[0]-1],wt[gpt_pair[1]-1]) for gpt_pair in gpt_list]\n",
    "\n",
    "    # Compute error terms for each combination of adjacent g-points pairs\n",
    "    with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n",
    "        # separate processes, each with their own arguments\n",
    "        res = [pool.apply_async(trial_cost_function, \n",
    "           args = (iMain, dirRes, dirData, file_coeff, \n",
    "                  gpt_pair, wgt_pair, file_LBLRTM, \n",
    "                  cf_norm, error_dict, THERMAL, FORCING, exe=EXE)) \\\n",
    "           for gpt_pair, wgt_pair in zip(gpt_list, wgt_list)]\n",
    "        temp  = [r.get() for r in res]\n",
    "        #results = [pool.apply_async(trial_cost_function, \n",
    "        #                            args=(iMain, file_coeff, gpt_pair, wgt_pair, file_LBLRTM, cf_norm))\n",
    "        #            for gpt_pair, wgt_pair in zip(gpt_list, wgt_list)]\n",
    "        #cfn_list = [r.get() for r in results]\n",
    "        break\n",
    "\n",
    "    ##########################################################################################\n",
    "    #\n",
    "    # Greedy optimization\n",
    "    # Of all the g-point combinations in this iteration, which had the smallest error?\n",
    "    #\n",
    "    winner = np.argmin([cf.total_cost(x) for x in cfn_list])\n",
    "    #\n",
    "    # Set the new coefficent file for the next iteration.\n",
    "    #\n",
    "    file_coeffFromPreviousIteration = 'coefficients_{0}.nc'.format(make_name_variant(iMain, gpt_list[winner]))\n",
    "    shutil.copy2('results/coeffs/'+file_coeffFromPreviousIteration, 'data/'+file_coeffFromPreviousIteration)\n",
    "    #\n",
    "    # Remove temporary files\n",
    "    #\n",
    "    for d in ['results/coeffs', 'results/fluxes']:\n",
    "        for f in os.listdir(d): os.remove(os.path.join(d, f))\n",
    "\n",
    "    g1out = int(gpt_list[winner][0])\n",
    "    g2out = int(gpt_list[winner][1])\n",
    "    print(\"For iteration {0:03d},combining g-points {1[0]:03d} and {1[1]:03d} in band {2:02d}\".format(iMain, gpt_list[winner], bandID[g1out-1]))\n",
    "    print(\"   F_:  \",cfn_list[winner][0].values)\n",
    "    print(\"   H_:  \",cfn_list[winner][1].values)\n",
    "    print(\"   FO_: \",cfn_list[winner][2].values)\n",
    "    print(\"   S_:  \",cfn_list[winner][3].values)\n",
    "    print(\"   tot: \",cf.total_cost(cfn_list[winner]))\n",
    "    print(\"   New coefficient file: \",file_coeffFromPreviousIteration)\n",
    "\n",
    "    # For the next iteration, modify the weights and the array that contains the\n",
    "    # number of G-points in each band.\n",
    "    # Next iteration will be over nGpts-1\n",
    "    wt[g1out-1] = wt[g1out-1]+wt[g2out-1]\n",
    "    wt     = np.delete(wt,     g2out-1)\n",
    "    bandID = np.delete(bandID, g2out-1)\n",
    "    nGpt = nGpt-1\n",
    "    ##########################################################################################\n",
    "    #\n",
    "    # Save terms of the cost function for every possible g-point combination\n",
    "    #\n",
    "    dataOUT = netCDF4.Dataset(\"data/cost_function_terms.lw.iter\"+str(iMain).zfill(3)+\".nc\",'w')\n",
    "    dataOUT.createDimension(\"Gpt_combination\",2)\n",
    "    dataOUT.createDimension(\"Case\",len(gpt_list))\n",
    "    H_norm  = dataOUT.createVariable(\"H_norm\",        \"f4\", (\"Case\"))\n",
    "    F_norm  = dataOUT.createVariable(\"F_norm\",        \"f4\", (\"Case\"))\n",
    "    FO_norm = dataOUT.createVariable(\"FO_norm\",       \"f4\", (\"Case\"))\n",
    "    S_norm  = dataOUT.createVariable(\"S_norm\",        \"f4\", (\"Case\"))\n",
    "    gPtsOut = dataOUT.createVariable(\"Gpt_pair\",      \"f4\", (\"Case\",\"Gpt_combination\"))\n",
    "    cstfnc  = dataOUT.createVariable(\"cost_function\", \"f4\", (\"Case\"))\n",
    "\n",
    "    for i in np.arange(len(gpt_list)):\n",
    "        # Store data\n",
    "        F_norm [i]  = cfn_list[i][0]\n",
    "        H_norm [i]  = cfn_list[i][1]\n",
    "        FO_norm[i]  = cfn_list[i][2]\n",
    "        S_norm [i]  = cfn_list[i][3]\n",
    "        gPtsOut[i,:] = gpt_list[i]\n",
    "        cstfnc[i]    = cf.total_cost(cfn_list[i])\n",
    "\n",
    "    # Close output file\n",
    "    dataOUT.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Menno version\n",
    "\n",
    "[Menno's Optimizer](https://github.com/MennoVeerman/k-distribution-opt/blob/master/optimizer.py) and Ben Hillman's (Ben separates into [LW](https://github.com/RobertPincus/k-distribution-opt/blob/brhillman/dev/optimizeLW.py) and [SW](https://github.com/RobertPincus/k-distribution-opt/blob/brhillman/dev/optimizeSW.py) optimizers) are pretty similar. Menno experiments with many more cost functions and plots intermediate results more often, but there seems to be some inconsistencies between the input files and perhaps executables that are used. For example, Menno uses `ncecat` to add a `record` dimension to the netCDF files, but Robert's and Ben's `rrtmgp_garand_atmos` expects it at runtime. Since we used `rrtmgp_garand_atmos`, we will use Ben's approach to optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(42,)\n",
      "(6, 3)\n",
      "(3, 16)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Store cost of reference (original k-distribution)\n",
    "all_costs = np.zeros((len(names)+1, nOptIt+1))\n",
    "all_bands = np.zeros((nOptIt))\n",
    "all_gpts  = np.zeros((2, nOptIt))\n",
    "for c in cf_norm: print(c.shape)\n",
    "sys.exit()\n",
    "\n",
    "print('For iteration 000, combined nothing yet')\n",
    "all_costs[:, 0] = process_costs(cf_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Combining g-point pairs {nOptIt} times...'); sys.stdout.flush()\n",
    "\n",
    "############################################\n",
    "# First iteration: outside main loop\n",
    "############################################\n",
    "gpt_list = [[x,x+1] for x in range(1, nGpt) if bandID[x-1] == bandID[x]][:]\n",
    "wgt_list = [(wt[gpt_pair[0]-1], wt[gpt_pair[1]-1]) for gpt_pair in gpt_list][:]\n",
    "gpt_arr = np.array(gpt_list)[:,0]\n",
    "\n",
    "file_coeffFromPreviousIteration = file_coeffORG\n",
    "file_coeff = dirData + file_coeffFromPreviousIteration\n",
    "\n",
    "# Compute and store error terms for each combination of adjacent g-points pairs\n",
    "# call `trial_cost_function` multiple times in parallel (\"pool\" the processes)\n",
    "error_dict = multiprocessing.Manager().dict()\n",
    "with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n",
    "    # separate processes, each with their own arguments\n",
    "    res = [pool.apply_async(trial_cost_function, \n",
    "           args = (1, dirRes, dirData, file_coeff, \n",
    "                  gpt_pair, wgt_pair, file_LBLRTM, \n",
    "                  cf_norm, error_dict, THERMAL, FORCING)) \\\n",
    "           for gpt_pair, wgt_pair in zip(gpt_list, wgt_list)]\n",
    "    temp  = [r.get() for r in res]\n",
    "\n",
    "# Greedy optimization: which g-point combination has the smallest error?\n",
    "cost_list = [cf.normalized_costs(cf.cost_function_from_error(\n",
    "    error_dict[i], p_lev, ICOST), cf_norm, ERRTYPE) for i in gpt_arr]\n",
    "winner_idx = np.argmin([cf.total_cost(i) for i in cost_list])\n",
    "winner_err = error_dict[gpt_list[winner_idx][0]]\n",
    "\n",
    "# Set the new coefficent file for the next iteration.\n",
    "file_coeffFromPreviousIteration = 'coefficients_{0}.nc'.format(\n",
    "    make_name_variant(1, gpt_list[winner_idx]))\n",
    "shutil.copy2('{}/coeffs/{}'.format(dirRes, file_coeffFromPreviousIteration), \n",
    "             '{}/{}'.format(dirData, file_coeffFromPreviousIteration))\n",
    "\n",
    "# Remove temporary files\n",
    "remove_temp_files(dirRes)\n",
    "\n",
    "#process costs\n",
    "g_out = int(gpt_list[winner_idx][0])\n",
    "all_bands[0]   = bandID[g_out]\n",
    "all_gpts [:,0] = gpt_list[winner_idx]\n",
    "all_costs[:,1] = process_costs(cost_list[winner_idx])\n",
    "\n",
    "# Modify the weights the g-point arrays\n",
    "wt, bandID, nGpt, gpt_arr_old = modify_wt_gpt(g_out, wt, bandID, nGpt, gpt_arr)\n",
    "print('For iteration 001, ', end='')\n",
    "print('combining g-points {0[0]:03d} and {0[1]:03d} in band {1:02d}'.format(\n",
    "    gpt_list[winner_idx], bandID[g_out-1]))\n",
    "print(\"New coefficient file: \", file_coeffFromPreviousIteration)\n",
    "\n",
    "# now perform the rest of the iterations\n",
    "for iiter in range(nOptIt-1):\n",
    "    iMain = iiter + 2\n",
    "\n",
    "    # Which coefficient file to use? On first iteration, this is original \n",
    "    # coefficient file\n",
    "    file_coeff = '{}/{}'.format(dirData, file_coeffFromPreviousIteration)\n",
    "    \n",
    "    # Create list of all adjacent g-point pairs in each band\n",
    "    gpt_list = [[x,x+1] for x in range(1,nGpt) if \\\n",
    "                bandID[x-1] == bandID[x]][:]\n",
    "    wgt_list = [(wt[gpt_pair[0]-1],wt[gpt_pair[1]-1]) for \\\n",
    "                gpt_pair in gpt_list][:]\n",
    "    gpt_arr = np.array(gpt_list)[:,0]\n",
    "    gpt_win = gpt_arr[winner_idx-1:winner_idx+1]\n",
    "    los_arr = np.delete(\n",
    "        gpt_arr, [winner_idx-1] + [winner_idx] * (winner_idx<len(gpt_arr)))\n",
    "\n",
    "    #rearrange error dict\n",
    "    error_dict.pop(g_out)\n",
    "    for igpt in range(winner_idx,len(gpt_arr)):\n",
    "        error_dict[gpt_arr[igpt]] = error_dict.pop(gpt_arr_old[igpt+1])\n",
    "    \n",
    "    ### Compute error terms for each combination of adjacent g-points pairs\n",
    "    # recompute with rte+rrtmgp\n",
    "    with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n",
    "        res = [pool.apply_async(trial_cost_function, \n",
    "               args = (iMain, dirRes, dirData, file_coeff, \n",
    "                      gpt_pair, wgt_pair, file_LBLRTM, \n",
    "                      cf_norm, error_dict, THERMAL, FORCING)) \\\n",
    "               for gpt_pair, wgt_pair in zip(\n",
    "                      gpt_list[winner_idx-1:winner_idx+1], \n",
    "                      wgt_list[winner_idx-1:winner_idx+1])]\n",
    "        temp  = [r.get() for r in res]\n",
    "\n",
    "    # Add errors from previous iteration\n",
    "    with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n",
    "        res = [pool.apply_async(append_errors, args = \\\n",
    "              (idx, error_dict, winner_err, winner_err_old)) for idx in los_arr]\n",
    "        temp  = [r.get() for r in res]\n",
    "    cost_list = [cf.normalized_costs(cf.cost_function_from_error(\n",
    "        error_dict[i], p_lev, ICOST), cf_norm, ERRTYPE) for i in gpt_arr]\n",
    "    \n",
    "    # Greedy optimization: which g-point combination has the smallest error?\n",
    "    winner_idx = np.argmin([cf.total_cost(i) for i in cost_list])\n",
    "\n",
    "    # New reference errors\n",
    "    winner_err_old = winner_err\n",
    "    winner_err = error_dict[gpt_list[winner_idx][0]]\n",
    "    \n",
    "    # Set the new coefficent file for the next iteration.\n",
    "    file_coeff_new = 'coefficients_{0}.nc'.format(\n",
    "        make_name_variant(iMain, gpt_list[winner_idx]))\n",
    "    if gpt_list[winner_idx][0] not in gpt_win: \n",
    "        combine_gpoints_fn(file_coeff, '{}/coeffs/{}'.format(\n",
    "            dirRes, file_coeff_new, gpt_list[winner_idx], wgt_list[winner_idx])\n",
    "        \n",
    "    file_coeffFromPreviousIteration = file_coeff_new\n",
    "    shutil.copy2('{}/coeffs/{}'.format(dirRes, file_coeffFromPreviousIteration), \n",
    "                 '{}/{}'.format(dirData, file_coeffFromPreviousIteration))\n",
    "    \n",
    "    # Remove temporary files\n",
    "    remove_temp_files(dirRes)\n",
    "\n",
    "    # Process costs\n",
    "    g_out = int(gpt_list[winner_idx][0])\n",
    "    all_bands[iMain-1] = bandID[g_out]\n",
    "    all_gpts [:,iMain-1] = gpt_list[winner_idx]\n",
    "    all_costs[:,iMain] = process_costs(cost_list[winner_idx])\n",
    "    \n",
    "    # Modify the weights the g-point arrays\n",
    "    wt, bandID, nGpt, gpt_arr_old = \\\n",
    "        modify_wt_gpt(g_out, wt, bandID, nGpt, gpt_arr)\n",
    "    print('For iteration {0:03d}, '.format(iMain), end='')\n",
    "    print('combining g-points {0[0]:03d} and {0[1]:03d} in band {1:02d}'.format(\n",
    "        iMain, gpt_list[winner_idx], bandID[g_out-1]))\n",
    "    print('New coefficient file: {}'.format(file_coeffFromPreviousIteration))\n",
    "    \n",
    "write_cost_nc(all_bands, all_gpts, all_costs, names, \n",
    "             icost=ICOST, f_thermal=THERMAL, f_errtype=ERRTYPE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
