{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By-band _k_-Distribution Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "`numpy` is installed in the Python environment at NERSC (`module load python`), but `xarray` is not, so the user must install the package on their own. `PIPPATH` is the assumed location. This notebook depends heavily on `xarray`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "# \"standard\" install\n",
    "import numpy as np\n",
    "\n",
    "# directory in which libraries installed with conda are saved\n",
    "PIPPATH = '{}/.local/'.format(os.path.expanduser('~')) + \\\n",
    "    'cori/3.7-anaconda-2019.10/lib/python3.7/site-packages'\n",
    "PATHS = ['common', PIPPATH]\n",
    "for path in PATHS: sys.path.append(path)\n",
    "\n",
    "# user must do `pip install xarray` on cori (or other NERSC machines)\n",
    "import xarray as XA\n",
    "\n",
    "# common submodule\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths\n",
    "\n",
    "`kFileNC` can point to any netCDF file that contains absorption coefficients for all _g_-points. Initially, we start with the reference _k_-distribution file from 4-Dec-2018, available in the [RTE-RRTMGP GitHub repository](https://github.com/earth-system-radiation/rte-rrtmgp/blob/master/rrtmgp/data/rrtmgp-data-lw-g256-2018-12-04.nc). This was placed in the E3SM project space at NERSC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = '/global/project/projectdirs/e3sm/pernak18/inputs/g-point-reduce'\n",
    "kFileNC = '{}/rrtmgp-data-lw-g256-2018-12-04.nc'.format(PROJECT)\n",
    "utils.file_check(kFileNC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandsplitting\n",
    "\n",
    "1. Open the netCDF with the entire _k_-distribution in it\n",
    "2. Loop over all bands and determine what _g_-point indices correspond to it\n",
    "3. Loop over all netCDF variables and determine which ones have the `gpt` dimension, which is the only dimension that is modified\n",
    "4. \"Slice\" the variables with the `gpt` dimensions so they only contain the portions of the _k_-distribution corresponding to a given band\n",
    "5. Write modified **and** unmodified variables to a new output netCDF that specifies the band number\n",
    "\n",
    "The end result is a netCDF for each band that contains only the parts of the variables that depend on _g_-points the correspond to the given band.\n",
    "\n",
    "**Note**: if files of the same name for a given band exist. This is so we do not append newer data to older files. If the files exist and the user wants to retain them, it is recommended that the files be moved to a subdirectory or somewhere else on the disk.\n",
    "\n",
    "We also want to store the weights for each _g_-point in these files. I am not sure where these originated, but I got them from Menno's optimization code. The weights are the same for each band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\n",
    "    0.1527534276, 0.1491729617, 0.1420961469, 0.1316886544, \n",
    "    0.1181945205, 0.1019300893, 0.0832767040, 0.0626720116, \n",
    "    0.0424925000, 0.0046269894, 0.0038279891, 0.0030260086, \n",
    "    0.0022199750, 0.0014140010, 0.0005330000, 0.0000750000\n",
    "]\n",
    "xaWeights = XA.DataArray(\n",
    "    weights, dims={'gpt': range(len(weights))}, name='gpt_weights')\n",
    "\n",
    "with XA.open_dataset(kFileNC) as kAllObj:\n",
    "    gLims = kAllObj.bnd_limits_gpt\n",
    "    ncVars = list(kAllObj.keys())\n",
    "    dimStr = 'gpt'\n",
    "\n",
    "    for iBand in kAllObj.bnd.values:\n",
    "        # make a separate netCDF for each band\n",
    "        outNC = 'coefficients_lw_band{:02d}.nc'.format(iBand+1)\n",
    "\n",
    "        # make sure we don't keep appending to an older file\n",
    "        if os.path.exists(outNC): os.remove(outNC)\n",
    "\n",
    "        # determine which variables need to be parsed\n",
    "        for ncVar in ncVars:\n",
    "            # append to netCDF if it already exists, start the file if not\n",
    "            modeNC = 'a' if os.path.exists(outNC) else 'w'\n",
    "\n",
    "            ncDat = kAllObj[ncVar]\n",
    "\n",
    "            if dimStr in kAllObj[ncVar].dims:\n",
    "                # grab only the g-point information for this band\n",
    "                # and convert to zero-offset\n",
    "                i1, i2 = gLims[iBand].values-1\n",
    "                ncDat = ncDat.isel(gpt=slice(i1, i2+1))\n",
    "            # endif\n",
    "\n",
    "            # write variable to output file\n",
    "            ncDat.to_netcdf(outNC, mode=modeNC)\n",
    "        # end ncVar loop\n",
    "\n",
    "        # write weights to output file\n",
    "        xaWeights.to_netcdf(outNC, mode='a')\n",
    "\n",
    "        print('Completed {}'.format(outNC))\n",
    "    # end band loop\n",
    "# endwith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "Check if `outNC` files for each band do what they are supposed to do and compare with original arrays. We are deliberately using a different technique for extracting data (heavier usage of `numpy` rather than `xarray` machinery). To validate, we apply a simple difference (error) calculation and print the range of the differences rather than any kind of plotting because some of the arrays have a number of dimensions that would make comprehensive plotting difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "bandFiles = sorted(glob.glob('coefficients_lw_band??.nc'))\n",
    "gptVars = ['kmajor', 'plank_fraction']\n",
    "\n",
    "for iBand, bFile in enumerate(bandFiles):\n",
    "    print(os.path.basename(bFile))\n",
    "\n",
    "    with XA.open_dataset(kFileNC) as broad, XA.open_dataset(bFile) as band:\n",
    "        for gVar in gptVars:\n",
    "            i1, i2 = np.array(broad.bnd_limits_gpt)[iBand]-1\n",
    "            kBroad = np.array(broad[gVar][:,:,:,i1:i2+1])\n",
    "            kBand = np.array(band[gVar])\n",
    "\n",
    "            # diff won't work if arrays do not have consistent dimensions\n",
    "            diff = kBand-kBroad\n",
    "\n",
    "            # print min and max of diff\n",
    "            dMin, dMax = utils.pmm(diff)\n",
    "            print('{} difference range: ({}, {})'.format(\n",
    "                gVar, dMin, dMax))\n",
    "    # end with\n",
    "    print()\n",
    "# end band loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
